<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Stephen Barrie">
<meta name="dcterms.date" content="2023-04-03">

<title>Into the Unknown - Data Engineering Zoomcamp - Week 5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Into the Unknown</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">Stephen Barrie</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Stephen137" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com/in/sjbarrie" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Data Engineering Zoomcamp - Week 5</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Spark</div>
                <div class="quarto-category">Dataproc</div>
                <div class="quarto-category">BigQuery</div>
                <div class="quarto-category">DataTalksClub</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Stephen Barrie </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 3, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#what-well-be-covering-this-week" id="toc-what-well-be-covering-this-week" class="nav-link active" data-scroll-target="#what-well-be-covering-this-week">5.0 What we’ll be covering this week</a></li>
  <li><a href="#introduction-to-batch-processing" id="toc-introduction-to-batch-processing" class="nav-link" data-scroll-target="#introduction-to-batch-processing">5.1 Introduction to Batch Processing</a></li>
  <li><a href="#introduction-to-spark" id="toc-introduction-to-spark" class="nav-link" data-scroll-target="#introduction-to-spark">5.1.2 Introduction to Spark</a></li>
  <li><a href="#installing-spark---linux-ubuntu-20.04" id="toc-installing-spark---linux-ubuntu-20.04" class="nav-link" data-scroll-target="#installing-spark---linux-ubuntu-20.04">5.2 Installing Spark - Linux (Ubuntu 20.04)</a></li>
  <li><a href="#running-pyspark-in-jupyter" id="toc-running-pyspark-in-jupyter" class="nav-link" data-scroll-target="#running-pyspark-in-jupyter">5.2.1 Running PySpark in Jupyter</a></li>
  <li><a href="#first-look-at-sparkpyspark" id="toc-first-look-at-sparkpyspark" class="nav-link" data-scroll-target="#first-look-at-sparkpyspark">5.3.1 First Look at Spark/PySpark</a></li>
  <li><a href="#spark-dataframes" id="toc-spark-dataframes" class="nav-link" data-scroll-target="#spark-dataframes">5.3.2 Spark DataFrames</a></li>
  <li><a href="#preparing-yellow-and-green-taxi-data" id="toc-preparing-yellow-and-green-taxi-data" class="nav-link" data-scroll-target="#preparing-yellow-and-green-taxi-data">5.3.3 Preparing Yellow and Green Taxi Data</a></li>
  <li><a href="#sql-with-spark" id="toc-sql-with-spark" class="nav-link" data-scroll-target="#sql-with-spark">5.3.4 SQL with Spark</a></li>
  <li><a href="#anatomy-of-a-spark-cluster" id="toc-anatomy-of-a-spark-cluster" class="nav-link" data-scroll-target="#anatomy-of-a-spark-cluster">5.4.1 Anatomy of a Spark Cluster</a></li>
  <li><a href="#groupby-in-spark" id="toc-groupby-in-spark" class="nav-link" data-scroll-target="#groupby-in-spark">5.4.2 GroupBy in Spark</a></li>
  <li><a href="#joins-in-spark" id="toc-joins-in-spark" class="nav-link" data-scroll-target="#joins-in-spark">5.4.3 Joins in Spark</a></li>
  <li><a href="#connecting-to-google-cloud-storage" id="toc-connecting-to-google-cloud-storage" class="nav-link" data-scroll-target="#connecting-to-google-cloud-storage">5.6.1 Connecting to Google Cloud Storage</a></li>
  <li><a href="#creating-a-local-clark-cluster" id="toc-creating-a-local-clark-cluster" class="nav-link" data-scroll-target="#creating-a-local-clark-cluster">5.6.2 Creating a Local Clark Cluster</a></li>
  <li><a href="#setting-up-a-dataproc-cluster" id="toc-setting-up-a-dataproc-cluster" class="nav-link" data-scroll-target="#setting-up-a-dataproc-cluster">5.6.3 Setting up a Dataproc Cluster</a></li>
  <li><a href="#connecting-spark-to-bigquery" id="toc-connecting-spark-to-bigquery" class="nav-link" data-scroll-target="#connecting-spark-to-bigquery">5.6.4 Connecting Spark to BigQuery</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Computerized batch processing is a method of running software programs called jobs in batches automatically. While users are required to submit the jobs, no other interaction by the user is required to process the batch. Batches may automatically be run at scheduled times as well as being run contingent on the availability of computer resources.</p>
<section id="what-well-be-covering-this-week" class="level3">
<h3 class="anchored" data-anchor-id="what-well-be-covering-this-week">5.0 What we’ll be covering this week</h3>
<p>This week we’ll cover:</p>
<ul>
<li>Spark, Spark DataFrames, and Spark SQL</li>
<li>Joins in Spark</li>
<li>Spark internals</li>
<li>Running Spark in the Cloud</li>
<li>Connecting Spark to a Data Warehouse, BigQuery</li>
</ul>
</section>
<section id="introduction-to-batch-processing" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-batch-processing">5.1 Introduction to Batch Processing</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/54ebe24a-e02d-4a70-881d-0d2325ca7870-1-27e80a16-ccdc-4402-8ab1-483de6d99577.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">batch_processing.PNG</figcaption>
</figure>
</div>
<p>There are typically two different ways of processing data :</p>
<p><code>Batch processing</code></p>
<p>Batch systems process large volumes of data and requests in sequential order.</p>
<p><code>Streaming (week 6)</code></p>
<p>Stream processing monitors real-time data and continually passes it on in the network.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/c9653a73-6ea7-4742-baae-7cd57f34e280-1-9882afbc-6183-459c-b7cc-fa8c9622af14.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">streaming.PNG</figcaption>
</figure>
</div>
<p>Given their complementary capabilities, some enterprises have implemented a hybrid system that includes batch processing and stream processing in their daily operations.</p>
<section id="what-is-batch-processing" class="level4">
<h4 class="anchored" data-anchor-id="what-is-batch-processing">What is Batch Processing ?</h4>
<p>Batch processing is the method computers use to periodically complete high-volume, repetitive data jobs. Certain data processing tasks, such as backups, filtering, and sorting, can be compute intensive and inefficient to run on individual data transactions. Instead, data systems process such tasks in batches, often in off-peak times when computing resources are more commonly available, such as at the end of the day or overnight. For example, consider an ecommerce system that receives orders throughout the day. Instead of processing every order as it occurs, the system might collect all orders at the end of each day and share them in one batch with the order fulfillment team.</p>
</section>
<section id="why-is-batch-processing-important" class="level4">
<h4 class="anchored" data-anchor-id="why-is-batch-processing-important">Why is batch processing important?</h4>
<p>Organizations use batch processing because it requires minimal human interaction and makes repetitive tasks more efficient to run. You can set up batches of jobs composed of millions of records to be worked through together when compute power is most readily available, putting less stress on your systems. Modern batch processing also requires minimal human supervision or management. If there is an issue, the system automatically notifies the concerned team to solve it. Managers take a hands-off approach, trusting their batch processing software to do its job. More benefits of batch processing follow.</p>
</section>
<section id="use-cases-of-batch-processing-systems" class="level4">
<h4 class="anchored" data-anchor-id="use-cases-of-batch-processing-systems">Use cases of batch processing systems</h4>
<p><code>Financial services</code></p>
<p>Financial services organizations, from agile financial technologies to legacy enterprises, have been using batch processing in areas such as high performance computing for risk management, end-of-day transaction processing, and fraud surveillance. They use batch processing to minimize human error, increase speed and accuracy, and reduce costs with automation.</p>
<p><code>Software as a service</code></p>
<p>Enterprises that deliver software as a service (SaaS) applications often run into issues when it comes to scalability. Using batch processing, you can scale customer demand while automating job scheduling. Creating containerized application environments to scale demand for high-volume processing is a project that can take months or even years to complete, but batch processing systems help you achieve the same result in a much shorter timeframe.</p>
<p><code>Medical research</code></p>
<p>Analysis of large amounts of data—or big data—is a common requirement in the field of research. You can apply batch processing in data analytics applications such as computational chemistry, clinical modeling, molecular dynamics, and genomic sequencing testing and analysis. For example, scientists use batch processing to capture better data to begin drug design and gain a deeper understanding of the role of a particular biochemical process.</p>
<p><code>Digital media</code></p>
<p>Media and entertainment enterprises require highly scalable batch processing systems to automatically process data—such as files, graphics, and visual effects—for high-resolution video content. You can use batch processing to accelerate content creation, dynamically scale media packaging, and automate media workload.</p>
</section>
<section id="orchestration" class="level4">
<h4 class="anchored" data-anchor-id="orchestration">Orchestration</h4>
<p>A batch job is a job (a unit of work) that will process data in batches.</p>
<p>Batch jobs may be scheduled in many ways:</p>
<ul>
<li>weekly</li>
<li>daily</li>
<li>hourly</li>
<li>three times per hour</li>
<li>every 5 minutes</li>
</ul>
<p>and are commonly orchestrated with tools such as <a href="https://www.getdbt.com/"><code>dbt</code></a> or <a href="https://airflow.apache.org/"><code>Airflow</code></a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/b551f5e7-f596-4ab4-be0a-4f01f7e1d771-1-34bd93cf-8330-40b2-85d2-674c7896079d.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">batch_workflow.PNG</figcaption>
</figure>
</div>
</section>
<section id="pros-and-cons" class="level4">
<h4 class="anchored" data-anchor-id="pros-and-cons">Pros and cons</h4>
<p><code>Advantages</code></p>
<ul>
<li>makes repetitive tasks more efficient to run, with minimal human interaction</li>
<li>re-executable. Jobs can be parameterized and easily retried if they fail</li>
<li>as we are not working in real time, we can set up batches of jobs composed of millions of records to be worked through together when compute power is most readily available, which puts less stress on your systems</li>
<li>scalability. Scripts can be executed on higher spec machines; Spark can be run in bigger clusters, etc</li>
</ul>
<p><code>Drawbacks</code></p>
<ul>
<li>there is an inherent delay in obtaining the processes data. The example workflow in the earlier graphic shows a 20 minute workflow to process an hour of data, and so the initial data is almost one hour and a half out of date before we can get our hands on it.</li>
</ul>
</section>
</section>
<section id="introduction-to-spark" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-spark">5.1.2 Introduction to Spark</h3>
<p>Apache Spark is a unified analytics engine for large-scale data processing.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/b67ecf89-ff06-4f2a-8bbd-3fe4aefffcf8-1-00f076ca-feac-41d4-b8a2-1d6ba17a57ff.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">apache_spark.PNG</figcaption>
</figure>
</div>
<p>It is a multi-language engine, which provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including:</p>
<ul>
<li><a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL for SQL</a> and structured data processing</li>
<li><a href="https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_ps.html">pandas API on Spark</a> for pandas workloads</li>
<li><a href="https://spark.apache.org/docs/latest/ml-guide.html">MLlib for machine learning</a></li>
<li><a href="https://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX for graph processing</a></li>
<li><a href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html">Structured Streaming</a> for incremental computation and stream processing</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/b67ecf89-ff06-4f2a-8bbd-3fe4aefffcf8-2-50857d50-5504-4eee-aae6-171f0808b8f4.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">when_spark.PNG</figcaption>
</figure>
</div>
<p>A typical workflow might look something like this :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/b67ecf89-ff06-4f2a-8bbd-3fe4aefffcf8-3-5944e3b4-0910-4ff4-8ade-46d2f7f1c19f.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_workflow.PNG</figcaption>
</figure>
</div>
</section>
<section id="installing-spark---linux-ubuntu-20.04" class="level3">
<h3 class="anchored" data-anchor-id="installing-spark---linux-ubuntu-20.04">5.2 Installing Spark - Linux (Ubuntu 20.04)</h3>
<section id="install-java" class="level4">
<h4 class="anchored" data-anchor-id="install-java">Install Java</h4>
<p>Here we’ll see how to install Spark 3.3.2 for Linux. It should also work for other Linux distros.</p>
<p>Download and unpack <a href="https://jdk.java.net/archive/">OpenJDK 11</a> (it’s important that the version is 11 - spark requires 8 or 11) from the command line :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>wget https:<span class="op">//</span>download.java.net<span class="op">/</span>java<span class="op">/</span>GA<span class="op">/</span>jdk11<span class="op">/</span><span class="dv">9</span><span class="op">/</span>GPL<span class="op">/</span>openjdk<span class="op">-</span><span class="fl">11.0.2</span><span class="er">_linux</span><span class="op">-</span>x64_bin.tar.gz</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>tar xzfv openjdk<span class="op">-</span><span class="fl">11.0.2</span><span class="er">_linux</span><span class="op">-</span>x64_bin.tar.gz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/edc4e77a-4513-4231-ba02-6aa9be50afa1-1-7b8e5c06-814a-4ec9-9d7d-0d8ffd95b687.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">java.PNG</figcaption>
</figure>
</div>
<p>Alternatively we can download <a href="https://www.oracle.com/pl/java/technologies/javase/jdk11-archive-downloads.html">Oracle JDK 11</a>.</p>
<p>Define <code>JAVA_HOME</code> and add it to <code>PATH</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>export JAVA_HOME<span class="op">=</span><span class="st">"$</span><span class="sc">{HOME}</span><span class="st">/Spark/jdk-11.0.2"</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>export PATH<span class="op">=</span><span class="st">"$</span><span class="sc">{JAVA_HOME}</span><span class="st">/bin:$</span><span class="sc">{PATH}</span><span class="st">"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Check that it works:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>java <span class="op">--</span>version</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/0889e9b8-6e08-48aa-a33e-c83fd68ea543-1-81bef254-e8b5-46c4-92a2-eddd11587ad1.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">java_version.PNG</figcaption>
</figure>
</div>
<p>Remove the archive :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>rm openjdk<span class="op">-</span><span class="fl">11.0.2</span><span class="er">_linux</span><span class="op">-</span>x64_bin.tar.gz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="install-spark" class="level4">
<h4 class="anchored" data-anchor-id="install-spark">Install Spark</h4>
<p>Download and unpack Spark (version 3.3.2) from the command line:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>wget https:<span class="op">//</span>dlcdn.apache.org<span class="op">/</span>spark<span class="op">/</span>spark<span class="op">-</span><span class="fl">3.3.2</span><span class="op">/</span>spark<span class="op">-</span><span class="fl">3.3.2</span><span class="op">-</span><span class="bu">bin</span><span class="op">-</span>hadoop3.tgz</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>tar xzfv spark<span class="op">-</span><span class="fl">3.3.2</span><span class="op">-</span><span class="bu">bin</span><span class="op">-</span>hadoop3.tgz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Define <code>SPARK_HOME</code> and add it to <code>PATH</code> :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>export SPARK_HOME<span class="op">=</span><span class="st">"$</span><span class="sc">{HOME}</span><span class="st">/Spark/spark-3.3.2-bin-hadoop3"</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>export PATH<span class="op">=</span><span class="st">"$</span><span class="sc">{SPARK_HOME}</span><span class="st">/bin:$</span><span class="sc">{PATH}</span><span class="st">"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Check that it works by executing <code>spark-shell</code> and run the following :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>val data <span class="op">=</span> <span class="dv">1</span> to <span class="dv">10000</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>val distData <span class="op">=</span> sc.parallelize(data)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>distData.<span class="bu">filter</span>(_ <span class="op">&lt;</span> <span class="dv">10</span>).collect():</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/2f5a438d-17f5-4668-9acb-25b22b0d12c4-1-865bdaf1-dd79-4610-a693-5df5fcfc1fc9.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_test.PNG</figcaption>
</figure>
</div>
<p>Remove the archive :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>rm spark<span class="op">-</span><span class="fl">3.3.2</span><span class="op">-</span><span class="bu">bin</span><span class="op">-</span>hadoop3.tgz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Add these lines to the bottom of the <code>.bashrc</code> file using <code>nano .bashrc</code> :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>export JAVA_HOME<span class="op">=</span><span class="st">"$</span><span class="sc">{HOME}</span><span class="st">/Spark/jdk-11.0.2"</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>export PATH<span class="op">=</span><span class="st">"$</span><span class="sc">{JAVA_HOME}</span><span class="st">/bin:$</span><span class="sc">{PATH}</span><span class="st">"</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>export SPARK_HOME<span class="op">=</span><span class="st">"$</span><span class="sc">{HOME}</span><span class="st">/Spark/spark-3.3.2-bin-hadoop3"</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>export PATH<span class="op">=</span><span class="st">"$</span><span class="sc">{SPARK_HOME}</span><span class="st">/bin:$</span><span class="sc">{PATH}</span><span class="st">"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Press <code>CTRL + O</code> to save the file, type the file name, and hit ENTER. To exit nano, all you need to do is to press <code>CTRL + X</code></p>
</section>
</section>
<section id="running-pyspark-in-jupyter" class="level3">
<h3 class="anchored" data-anchor-id="running-pyspark-in-jupyter">5.2.1 Running PySpark in Jupyter</h3>
<p>This document assumes you already have python. To run PySpark, we first need to add it to <code>PYTHONPATH</code> and run this from the command line :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>export PYTHONPATH<span class="op">=</span><span class="st">"$</span><span class="sc">{SPARK_HOME}</span><span class="st">/python/:$PYTHONPATH"</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>export PYTHONPATH<span class="op">=</span><span class="st">"$</span><span class="sc">{SPARK_HOME}</span><span class="st">/python/lib/py4j-0.10.9-src.zip:$PYTHONPATH"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Make sure that the version under <code>${SPARK_HOME}/python/lib/</code> matches the filename of py4j or you will encounter <code>ModuleNotFoundError: No module named 'py4j'</code> while executing <code>import pyspark</code>.</p>
<p>For example, if the file under <code>${SPARK_HOME}/python/lib/</code> is <code>py4j-0.10.9.3-src.zip</code>, then the <code>export PYTHONPATH</code> statement above should be changed to :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>export PYTHONPATH<span class="op">=</span><span class="st">"$</span><span class="sc">{SPARK_HOME}</span><span class="st">/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can run Jupyter or IPython to test if things work. Go to some other directory, e.g.&nbsp;<code>~/tmp</code>. Download a CSV file that we’ll use for testing:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>wget https:<span class="op">//</span>s3.amazonaws.com<span class="op">/</span>nyc<span class="op">-</span>tlc<span class="op">/</span>misc<span class="op">/</span>taxi<span class="op">+</span>_zone_lookup.csv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s run <code>ipython</code> or <code>jupyter notebook</code> and execute:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder <span class="op">\</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    .master(<span class="st">"local[*]"</span>) <span class="op">\</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    .appName(<span class="st">'test'</span>) <span class="op">\</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.read <span class="op">\</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    .option(<span class="st">"header"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    .csv(<span class="st">'taxi+_zone_lookup.csv'</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>df.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>23/03/29 11:36:13 WARN Utils: Your hostname, DESKTOP-1UDJOCI resolves to a loopback address: 127.0.1.1; using 172.24.9.22 instead (on interface eth0)
23/03/29 11:36:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/03/29 11:36:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/03/29 11:36:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
+----------+-------------+--------------------+------------+
|LocationID|      Borough|                Zone|service_zone|
+----------+-------------+--------------------+------------+
|         1|          EWR|      Newark Airport|         EWR|
|         2|       Queens|         Jamaica Bay|   Boro Zone|
|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|
|         4|    Manhattan|       Alphabet City| Yellow Zone|
|         5|Staten Island|       Arden Heights|   Boro Zone|
|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|
|         7|       Queens|             Astoria|   Boro Zone|
|         8|       Queens|        Astoria Park|   Boro Zone|
|         9|       Queens|          Auburndale|   Boro Zone|
|        10|       Queens|        Baisley Park|   Boro Zone|
|        11|     Brooklyn|          Bath Beach|   Boro Zone|
|        12|    Manhattan|        Battery Park| Yellow Zone|
|        13|    Manhattan|   Battery Park City| Yellow Zone|
|        14|     Brooklyn|           Bay Ridge|   Boro Zone|
|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|
|        16|       Queens|             Bayside|   Boro Zone|
|        17|     Brooklyn|             Bedford|   Boro Zone|
|        18|        Bronx|        Bedford Park|   Boro Zone|
|        19|       Queens|           Bellerose|   Boro Zone|
|        20|        Bronx|             Belmont|   Boro Zone|
+----------+-------------+--------------------+------------+
only showing top 20 rows
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</code></pre>
</div>
</div>
<p>Test that writing works as well:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>df.write.parquet(<span class="st">'zones'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/21b65674-6fc3-46ce-932d-f2bf54da8850-1-3965f8fd-c955-4ffb-be66-9ab60bd14122.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">pyspark_test.PNG</figcaption>
</figure>
</div>
</section>
<section id="first-look-at-sparkpyspark" class="level3">
<h3 class="anchored" data-anchor-id="first-look-at-sparkpyspark">5.3.1 First Look at Spark/PySpark</h3>
<p>Let’s grab our required dataset which is in <code>csv.gz</code> format from <a href="https://github.com/DataTalksClub/nyc-tlc-data/releases/tag/fhvhv">here</a> and unzip by running the following from the command line:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>wget https:<span class="op">//</span>github.com<span class="op">/</span>DataTalksClub<span class="op">/</span>nyc<span class="op">-</span>tlc<span class="op">-</span>data<span class="op">/</span>releases<span class="op">/</span>download<span class="op">/</span>fhvhv<span class="op">/</span>fhvhv_tripdata_2021<span class="op">-</span><span class="fl">01.</span><span class="er">csv</span>.gz</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>gzip <span class="op">-</span>dk fhvhv_tripdata_2021<span class="op">-</span><span class="fl">01.</span><span class="er">csv</span>.gz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s see how many rows our dataset has :</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wc <span class="op">-</span>l Data<span class="op">/</span>fhvhv_tripdata_2021<span class="op">-</span><span class="fl">01.</span><span class="er">csv</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>11908469 Data/fhvhv_tripdata_2021-01.csv</code></pre>
</div>
</div>
<p>So, almost 12 million records - not insignificant. Let’s now take a look at Spark.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import required packages</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Our entry point to Spark</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>spark</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>23/03/30 09:32:56 WARN Utils: Your hostname, DESKTOP-1UDJOCI resolves to a loopback address: 127.0.1.1; using 172.24.7.86 instead (on interface eth0)
23/03/30 09:32:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/03/30 09:32:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="2">

            <div>
                <p><b>SparkSession - in-memory</b></p>
                
        <div>
            <p><b>SparkContext</b></p>

            <p><a href="http://172.24.7.86:4040">Spark UI</a></p>

            <dl>
              <dt>Version</dt>
                <dd><code>v3.3.2</code></dd>
              <dt>Master</dt>
                <dd><code>local[*]</code></dd>
              <dt>AppName</dt>
                <dd><code>pyspark-shell</code></dd>
            </dl>
        </div>
        
            </div>
        
</div>
</div>
<p>We can access the Spark Web UI locally at <code>port :4040</code> from the link above :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/ebe2649e-2fad-43ae-8e30-555434f96952-1-3f6f5db2-8c5c-4f2a-b89b-4be58fd75f4b.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_shell.PNG</figcaption>
</figure>
</div>
<p>Let’s read our data to Spark :</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.read <span class="op">\</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    .option(<span class="st">"header"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    .csv(<span class="st">'Data/fhvhv_tripdata_2021-01.csv'</span>)   </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>df.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+
|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|
+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+
|           HV0003|              B02682|2021-01-01 00:33:44|2021-01-01 00:49:07|         230|         166|   null|
|           HV0003|              B02682|2021-01-01 00:55:19|2021-01-01 01:18:21|         152|         167|   null|
|           HV0003|              B02764|2021-01-01 00:23:56|2021-01-01 00:38:05|         233|         142|   null|
|           HV0003|              B02764|2021-01-01 00:42:51|2021-01-01 00:45:50|         142|         143|   null|
|           HV0003|              B02764|2021-01-01 00:48:14|2021-01-01 01:08:42|         143|          78|   null|
|           HV0005|              B02510|2021-01-01 00:06:59|2021-01-01 00:43:01|          88|          42|   null|
|           HV0005|              B02510|2021-01-01 00:50:00|2021-01-01 01:04:57|          42|         151|   null|
|           HV0003|              B02764|2021-01-01 00:14:30|2021-01-01 00:50:27|          71|         226|   null|
|           HV0003|              B02875|2021-01-01 00:22:54|2021-01-01 00:30:20|         112|         255|   null|
|           HV0003|              B02875|2021-01-01 00:40:12|2021-01-01 00:53:31|         255|         232|   null|
|           HV0003|              B02875|2021-01-01 00:56:45|2021-01-01 01:17:42|         232|         198|   null|
|           HV0003|              B02835|2021-01-01 00:29:04|2021-01-01 00:36:27|         113|          48|   null|
|           HV0003|              B02835|2021-01-01 00:48:56|2021-01-01 00:59:12|         239|          75|   null|
|           HV0004|              B02800|2021-01-01 00:15:24|2021-01-01 00:38:31|         181|         237|   null|
|           HV0004|              B02800|2021-01-01 00:45:00|2021-01-01 01:06:45|         236|          68|   null|
|           HV0003|              B02682|2021-01-01 00:11:53|2021-01-01 00:18:06|         256|         148|   null|
|           HV0003|              B02682|2021-01-01 00:28:31|2021-01-01 00:41:40|          79|          80|   null|
|           HV0003|              B02682|2021-01-01 00:50:49|2021-01-01 00:55:59|          17|         217|   null|
|           HV0005|              B02510|2021-01-01 00:08:40|2021-01-01 00:39:39|          62|          29|   null|
|           HV0003|              B02836|2021-01-01 00:53:48|2021-01-01 01:11:40|          22|          22|   null|
+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+
only showing top 20 rows
</code></pre>
</div>
</div>
<p>Every time we execute something it is reflected in the Spark Web UI :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/127ae41e-54f9-4433-a123-2792b7be1683-1-73ba77a8-6132-4681-8d9d-40cfab8bec2a.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_web_ui.PNG</figcaption>
</figure>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's look at the first 5 records</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>df.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime='2021-01-01 00:33:44', dropoff_datetime='2021-01-01 00:49:07', PULocationID='230', DOLocationID='166', SR_Flag=None),
 Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime='2021-01-01 00:55:19', dropoff_datetime='2021-01-01 01:18:21', PULocationID='152', DOLocationID='167', SR_Flag=None),
 Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime='2021-01-01 00:23:56', dropoff_datetime='2021-01-01 00:38:05', PULocationID='233', DOLocationID='142', SR_Flag=None),
 Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime='2021-01-01 00:42:51', dropoff_datetime='2021-01-01 00:45:50', PULocationID='142', DOLocationID='143', SR_Flag=None),
 Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime='2021-01-01 00:48:14', dropoff_datetime='2021-01-01 01:08:42', PULocationID='143', DOLocationID='78', SR_Flag=None)]</code></pre>
</div>
</div>
<p>Note that Spark (unlike pandas) does not try to infer datatypes - instead everything is treated as a <code>string</code>. We can see this more explicitly by looking at the schema :</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>df.schema</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', StringType(), True), StructField('DOLocationID', StringType(), True), StructField('SR_Flag', StringType(), True)])</code></pre>
</div>
</div>
<p>Let’s now create a new csv file comprising of just 100 rows from our <code>fhvhv_tripdata_2021-01.csv</code> file by running the following from the command line :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>head <span class="op">-</span>n <span class="dv">101</span> Data<span class="op">/</span>fhvhv_tripdata_2021<span class="op">-</span><span class="fl">01.</span><span class="er">csv</span> <span class="op">&gt;</span> head.csv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>df_pandas <span class="op">=</span> pd.read_csv(<span class="st">'Data/head.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>df_pandas.dtypes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>hvfhs_license_num        object
dispatching_base_num     object
pickup_datetime          object
dropoff_datetime         object
PULocationID              int64
DOLocationID              int64
SR_Flag                 float64
dtype: object</code></pre>
</div>
</div>
<p>We can see that <code>pandas</code> does a better job at figuring out datatypes but <code>pickup_datetime</code> and <code>dropoff_datetime</code> still require to be converted to a timestamp. We can use Spark to create a Spark DataFrame from a pandas DataFrame :</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>spark.createDataFrame(df_pandas).schema</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('SR_Flag', DoubleType(), True)])</code></pre>
</div>
</div>
<p>The above <code>StructType</code> comes from <code>Scala</code> and we can see that the <code>PULocationID</code> and <code>DOLocationID</code> are <code>LongType</code> which is a less memory-efficient format (8 bytes) than integer (4 bytes). So let’s convert the datatypes using Python:</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> types</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># convert datatypes of our Spark DataFrame</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>schema <span class="op">=</span> types.StructType([</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">'hvfhs_license_num'</span>, types.StringType(), <span class="va">True</span>), <span class="co"># True argument means can be NULL</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">'dispatching_base_num'</span>, types.StringType(), <span class="va">True</span>),</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">'pickup_datetime'</span>, types.TimestampType(), <span class="va">True</span>),</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">'dropoff_datetime'</span>, types.TimestampType(), <span class="va">True</span>),</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">'PULocationID'</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">'DOLocationID'</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">'SR_Flag'</span>, types.StringType(), <span class="va">True</span>)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load our Spark DataFrame with converted datatypes from above</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.read <span class="op">\</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    .option(<span class="st">"header"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    .schema(schema) <span class="op">\</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    .csv(<span class="st">'Data/fhvhv_tripdata_2021-01.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>df.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 33, 44), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 49, 7), PULocationID=230, DOLocationID=166, SR_Flag=None),
 Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 55, 19), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 18, 21), PULocationID=152, DOLocationID=167, SR_Flag=None),
 Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 23, 56), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 38, 5), PULocationID=233, DOLocationID=142, SR_Flag=None),
 Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 42, 51), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 45, 50), PULocationID=142, DOLocationID=143, SR_Flag=None),
 Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 48, 14), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 8, 42), PULocationID=143, DOLocationID=78, SR_Flag=None)]</code></pre>
</div>
</div>
<p>We can see that the our <code>pickup_datetime</code> and <code>dropoff_datetime</code> have been properly parsed.</p>
<p>At the moment we have one large csv file (718MB) :</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>du <span class="op">-</span>h Data<span class="op">/</span>fhvhv_tripdata_2021<span class="op">-</span><span class="fl">01.</span><span class="er">csv</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>718M    Data/fhvhv_tripdata_2021-01.csv</code></pre>
</div>
</div>
<p>That means that only one of our Spark cluster executors will be able to access the file - the remaining clusters will be idle :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/a7b11a2c-5e0f-4a20-b0a1-e5a19492bfc1-1-6e141084-75dd-44db-9767-c7eabbb8df49.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">csv_internals.PNG</figcaption>
</figure>
</div>
<p>A more efficient way to store our data is a bunch of smaller files, known as <code>partitions</code> :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/e01866cd-6faa-45cd-b267-18690496fa0c-1-5bce1802-322b-4223-a5b8-0c99e4a5d4ab.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">partitiion_structure.PNG</figcaption>
</figure>
</div>
<p>We can achieve partitioning using <code>.repartition</code> :</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># break down our csv into multiple partitions</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.repartition(<span class="dv">24</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that this is a <em>lazy</em> command - nothing has actually been executed yet. Only when we action something, for example write to parquet, will something happen :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>df.write.parquet(<span class="st">'Data/fhvhv/2021/01/'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/80312cf8-410b-4a2c-8119-5650e8a8a4ff-1-a7da97a3-3c02-48c0-9fef-d048f18d06e9.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">parquet_DAG.PNG</figcaption>
</figure>
</div>
<p>Let’s check to see if we have our parquet files :</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls <span class="op">-</span>lh Data<span class="op">/</span>fhvhv<span class="op">/</span><span class="dv">2021</span><span class="op">/</span><span class="dv">0</span><span class="er">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>total 136M
-rw-r--r-- 1 stephen137 stephen137    0 Mar 30 10:13 _SUCCESS
-rw-r--r-- 1 stephen137 stephen137 8.5M Mar 30 10:13 part-00000-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 9.3M Mar 30 10:13 part-00001-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.8M Mar 30 10:13 part-00002-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.5M Mar 30 10:13 part-00003-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.4M Mar 30 10:13 part-00004-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.8M Mar 30 10:13 part-00005-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.6M Mar 30 10:13 part-00006-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.3M Mar 30 10:13 part-00007-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.8M Mar 30 10:13 part-00008-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.8M Mar 30 10:13 part-00009-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.6M Mar 30 10:13 part-00010-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.1M Mar 30 10:13 part-00011-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.7M Mar 30 10:13 part-00012-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 8.6M Mar 30 10:13 part-00013-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 7.9M Mar 30 10:13 part-00014-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet
-rw-r--r-- 1 stephen137 stephen137 7.2M Mar 30 10:13 part-00015-9e5b1ddb-b845-47c8-828f-c2733b793edb-c000.snappy.parquet</code></pre>
</div>
</div>
<p>We can see that we have 16 parquet files (not sure why there aren’t 24 as specified in <code>.repartition</code>) and compression has been performed, reducing the size from 718MB to 136MB. This is more efficient and makes better use of our Spark clusters.</p>
</section>
<section id="spark-dataframes" class="level3">
<h3 class="anchored" data-anchor-id="spark-dataframes">5.3.2 Spark DataFrames</h3>
<p>Let’s now create a Spark DataFrame from our parquet file :</p>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.read.parquet(<span class="st">'Data/fhvhv/2021/01/'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Parquet files include the schema and so we don’t have to specify this :</p>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>df.printSchema()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>root
 |-- hvfhs_license_num: string (nullable = true)
 |-- dispatching_base_num: string (nullable = true)
 |-- pickup_datetime: timestamp (nullable = true)
 |-- dropoff_datetime: timestamp (nullable = true)
 |-- PULocationID: integer (nullable = true)
 |-- DOLocationID: integer (nullable = true)
 |-- SR_Flag: string (nullable = true)
</code></pre>
</div>
</div>
<p>We can do the usual stuff that we do with a <code>pandas</code> DataFrame, for example <code>.select</code> and <code>.filter</code> :</p>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>df.select(<span class="st">'pickup_datetime'</span>, <span class="st">'dropoff_datetime'</span>, <span class="st">'PULocationID'</span>, <span class="st">'DOLocationID'</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>DataFrame[pickup_datetime: timestamp, dropoff_datetime: timestamp, PULocationID: int, DOLocationID: int]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>df.select(<span class="st">'pickup_datetime'</span>, <span class="st">'dropoff_datetime'</span>, <span class="st">'PULocationID'</span>, <span class="st">'DOLocationID'</span>) <span class="op">\</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>.<span class="bu">filter</span>(df.hvfhs_license_num <span class="op">==</span> <span class="st">'HV0003'</span>) <span class="op">\</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------------+-------------------+------------+------------+
|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|
+-------------------+-------------------+------------+------------+
|2021-01-03 00:29:29|2021-01-03 00:46:37|         197|          82|
|2021-01-03 00:50:22|2021-01-03 00:52:52|          56|          56|
|2021-01-03 00:05:27|2021-01-03 00:15:20|         243|         244|
|2021-01-03 00:24:41|2021-01-03 00:30:47|         243|         127|
|2021-01-03 00:48:14|2021-01-03 01:00:10|         235|          18|
|2021-01-03 00:19:02|2021-01-03 00:28:57|         151|         116|
|2021-01-03 00:09:51|2021-01-03 00:19:16|         121|          28|
|2021-01-03 00:30:20|2021-01-03 00:45:24|          28|         160|
|2021-01-03 00:47:31|2021-01-03 00:56:37|         160|         157|
|2021-01-03 00:26:17|2021-01-03 00:50:36|         236|         265|
|2021-01-03 00:10:04|2021-01-03 00:14:38|           3|          32|
|2021-01-03 00:41:48|2021-01-03 00:48:48|         169|         136|
|2021-01-03 00:54:32|2021-01-03 01:00:54|         235|         169|
|2021-01-03 00:14:38|2021-01-03 00:25:55|         229|         262|
|2021-01-03 00:13:02|2021-01-03 00:39:15|          82|         163|
|2021-01-03 00:48:54|2021-01-03 00:53:13|         164|         186|
|2021-01-03 00:00:50|2021-01-03 00:03:27|          21|          21|
|2021-01-03 00:53:06|2021-01-03 01:14:24|          50|         126|
|2021-01-03 00:17:07|2021-01-03 00:25:03|          89|          71|
|2021-01-03 00:43:17|2021-01-03 00:57:45|         188|          17|
+-------------------+-------------------+------------+------------+
only showing top 20 rows
</code></pre>
</div>
</div>
<section id="actions-vs-transformations" class="level4">
<h4 class="anchored" data-anchor-id="actions-vs-transformations">Actions vs Transformations</h4>
<p>In Spark there is a distinction between :</p>
<ul>
<li>things that are executed right away (Actions)</li>
<li>things that are NOT executed right away (Transformations)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/fc7a6aea-12ca-433e-9e03-ba3b9f484aa6-2-bf4b5739-85fd-42dd-b6ee-31128913a098.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">actions_vs_transforms.PNG</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/fc7a6aea-12ca-433e-9e03-ba3b9f484aa6-1-0f21704d-eac8-4f15-bab9-175d6f23291a.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">transformation_action.PNG</figcaption>
</figure>
</div>
</section>
<section id="user-defined-functions" class="level4">
<h4 class="anchored" data-anchor-id="user-defined-functions">User defined functions</h4>
<p>Spark like pandas already has a number of <a href="https://spark.apache.org/docs/latest/api/sql/index.html">in-built functions</a>. We can access these from within Jupyter Notebook by hitting <code>Tab</code> after <code>F.</code> :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/c4529f7b-1364-4127-97fe-7880a1375603-1-377784c1-0aea-4395-bc3a-b86e1fb249c2.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">F.PNG</figcaption>
</figure>
</div>
<p>For example we can convert datetime datatype to date using :</p>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">\</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'pickup_date'</span>, F.to_date(df.pickup_datetime)) <span class="op">\</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'dropoff_date'</span>, F.to_date(df.dropoff_datetime)) <span class="op">\</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    .select(<span class="st">'pickup_date'</span>, <span class="st">'dropoff_date'</span>, <span class="st">'PULocationID'</span>, <span class="st">'DOLocationID'</span>) <span class="op">\</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>    .show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-----------+------------+------------+------------+
|pickup_date|dropoff_date|PULocationID|DOLocationID|
+-----------+------------+------------+------------+
| 2021-01-03|  2021-01-03|         197|          82|
| 2021-01-03|  2021-01-03|          56|          56|
| 2021-01-03|  2021-01-03|          76|          51|
| 2021-01-03|  2021-01-03|         208|         208|
| 2021-01-03|  2021-01-03|         183|         208|
| 2021-01-03|  2021-01-03|         243|         244|
| 2021-01-03|  2021-01-03|         243|         127|
| 2021-01-03|  2021-01-03|         235|          18|
| 2021-01-03|  2021-01-03|          68|          49|
| 2021-01-03|  2021-01-03|         151|         116|
| 2021-01-03|  2021-01-03|         121|          28|
| 2021-01-03|  2021-01-03|          28|         160|
| 2021-01-03|  2021-01-03|         160|         157|
| 2021-01-03|  2021-01-03|         236|         265|
| 2021-01-03|  2021-01-03|          32|         169|
| 2021-01-03|  2021-01-03|           3|          32|
| 2021-01-03|  2021-01-03|         169|         136|
| 2021-01-03|  2021-01-03|         235|         169|
| 2021-01-03|  2021-01-03|         229|         262|
| 2021-01-03|  2021-01-03|          82|         163|
+-----------+------------+------------+------------+
only showing top 20 rows
</code></pre>
</div>
</div>
<p>However, Spark is more flexible than pandas as it allows us to create and store our own <code>user-defined-functions</code> as illustrated below :</p>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> functions <span class="im">as</span> F</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crazy_stuff(base_num):</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    num <span class="op">=</span> <span class="bu">int</span>(base_num[<span class="dv">1</span>:])</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> num <span class="op">%</span> <span class="dv">7</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f's/</span><span class="sc">{</span>num<span class="sc">:03x}</span><span class="ss">'</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> num <span class="op">%</span> <span class="dv">3</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f'a/</span><span class="sc">{</span>num<span class="sc">:03x}</span><span class="ss">'</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f'e/</span><span class="sc">{</span>num<span class="sc">:03x}</span><span class="ss">'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>crazy_stuff(<span class="st">'B02884'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>'s/b44'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>crazy_stuff_udf <span class="op">=</span> F.udf(crazy_stuff, returnType<span class="op">=</span>types.StringType())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>df<br>
.withColumn(‘pickup_date’, F.to_date(df.pickup_datetime))<br>
.withColumn(‘dropoff_date’, F.to_date(df.dropoff_datetime))<br>
.withColumn(‘base_id’, crazy_stuff_udf(df.dispatching_base_num))<br>
.select(‘base_id’, ‘pickup_date’, ‘dropoff_date’, ‘PULocationID’, ‘DOLocationID’)<br>
.show()</p>
</section>
</section>
<section id="preparing-yellow-and-green-taxi-data" class="level3">
<h3 class="anchored" data-anchor-id="preparing-yellow-and-green-taxi-data">5.3.3 Preparing Yellow and Green Taxi Data</h3>
<p>We can download the required datasets by using the following bash script :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span> <span class="op">-</span>e</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>URL_PREFIX<span class="op">=</span><span class="st">"https://github.com/DataTalksClub/nyc-tlc-data/releases/download"</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> TAXI_TYPE <span class="kw">in</span> <span class="st">"yellow"</span> <span class="st">"green"</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>do</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> YEAR <span class="kw">in</span> <span class="dv">2020</span> <span class="dv">2021</span></span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>    do</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> MONTH <span class="kw">in</span> {<span class="fl">1..12</span>}</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>        do</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> [ $YEAR <span class="op">==</span> <span class="dv">2020</span> ] <span class="op">||</span> [ $MONTH <span class="op">-</span>lt <span class="dv">8</span> ]</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>        then</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>            FMONTH<span class="op">=</span>`printf <span class="st">"</span><span class="sc">%02d</span><span class="st">"</span> ${MONTH}`</span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a>            URL<span class="op">=</span><span class="st">"$</span><span class="sc">{URL_PREFIX}</span><span class="st">/$</span><span class="sc">{TAXI_TYPE}</span><span class="st">/$</span><span class="sc">{TAXI_TYPE}</span><span class="st">_tripdata_$</span><span class="sc">{YEAR}</span><span class="st">-$</span><span class="sc">{FMONTH}</span><span class="st">.csv.gz"</span></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>            LOCAL_PREFIX<span class="op">=</span><span class="st">"data/raw/$</span><span class="sc">{TAXI_TYPE}</span><span class="st">/$</span><span class="sc">{YEAR}</span><span class="st">/$</span><span class="sc">{FMONTH}</span><span class="st">"</span></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>            LOCAL_FILE<span class="op">=</span><span class="st">"$</span><span class="sc">{TAXI_TYPE}</span><span class="st">_tripdata_$</span><span class="sc">{YEAR}</span><span class="st">_$</span><span class="sc">{FMONTH}</span><span class="st">.csv.gz"</span></span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>            LOCAL_PATH<span class="op">=</span><span class="st">"$</span><span class="sc">{LOCAL_PREFIX}</span><span class="st">/$</span><span class="sc">{LOCAL_FILE}</span><span class="st">"</span></span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a>            echo <span class="st">"downloading $</span><span class="sc">{URL}</span><span class="st"> to $</span><span class="sc">{LOCAL_PATH}</span><span class="st">"</span></span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a>            mkdir <span class="op">-</span>p ${LOCAL_PREFIX}</span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a>            wget ${URL} <span class="op">-</span>O ${LOCAL_PATH}</span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a>        fi</span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a>        done</span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a>    done</span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a>done</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And running the script from the command lines for yellow and green for years 2020 and 2021 :</p>
<pre><code>./download_data.sh yellow 2020
./download_data.sh yellow 2021
./download_data.sh green 2020
./download_data.sh green 2021</code></pre>
<p>Then we need to configure the schema :</p>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>green_schema <span class="op">=</span> types.StructType([</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"VendorID"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"lpep_pickup_datetime"</span>, types.TimestampType(), <span class="va">True</span>),</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"lpep_dropoff_datetime"</span>, types.TimestampType(), <span class="va">True</span>),</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"store_and_fwd_flag"</span>, types.StringType(), <span class="va">True</span>),</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"RatecodeID"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"PULocationID"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"DOLocationID"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"passenger_count"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"trip_distance"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"fare_amount"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"extra"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"mta_tax"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"tip_amount"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"tolls_amount"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"ehail_fee"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"improvement_surcharge"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"total_amount"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"payment_type"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"trip_type"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"congestion_surcharge"</span>, types.DoubleType(), <span class="va">True</span>)</span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a>yellow_schema <span class="op">=</span> types.StructType([</span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"VendorID"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"tpep_pickup_datetime"</span>, types.TimestampType(), <span class="va">True</span>),</span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"tpep_dropoff_datetime"</span>, types.TimestampType(), <span class="va">True</span>),</span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"passenger_count"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"trip_distance"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"RatecodeID"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"store_and_fwd_flag"</span>, types.StringType(), <span class="va">True</span>),</span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"PULocationID"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-33"><a href="#cb65-33" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"DOLocationID"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-34"><a href="#cb65-34" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"payment_type"</span>, types.IntegerType(), <span class="va">True</span>),</span>
<span id="cb65-35"><a href="#cb65-35" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"fare_amount"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-36"><a href="#cb65-36" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"extra"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-37"><a href="#cb65-37" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"mta_tax"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-38"><a href="#cb65-38" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"tip_amount"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-39"><a href="#cb65-39" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"tolls_amount"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-40"><a href="#cb65-40" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"improvement_surcharge"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-41"><a href="#cb65-41" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"total_amount"</span>, types.DoubleType(), <span class="va">True</span>),</span>
<span id="cb65-42"><a href="#cb65-42" aria-hidden="true" tabindex="-1"></a>    types.StructField(<span class="st">"congestion_surcharge"</span>, types.DoubleType(), <span class="va">True</span>)</span>
<span id="cb65-43"><a href="#cb65-43" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And then convert from csv to parquet :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>year <span class="op">=</span> <span class="dv">2020</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> month <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">13</span>):</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'processing data for </span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>    input_path <span class="op">=</span> <span class="ss">f'data/raw/green/</span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">:02d}</span><span class="ss">/'</span></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>    output_path <span class="op">=</span> <span class="ss">f'data/pq/green/</span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">:02d}</span><span class="ss">/'</span></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>    df_green <span class="op">=</span> spark.read <span class="op">\</span></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>        .option(<span class="st">"header"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>        .schema(green_schema) <span class="op">\</span></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>        .csv(input_path)</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a>    df_green <span class="op">\</span></span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>        .repartition(<span class="dv">4</span>) <span class="op">\</span></span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>        .write.parquet(output_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>year <span class="op">=</span> <span class="dv">2021</span> </span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> month <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">13</span>):</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'processing data for </span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>    input_path <span class="op">=</span> <span class="ss">f'data/raw/green/</span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">:02d}</span><span class="ss">/'</span></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>    output_path <span class="op">=</span> <span class="ss">f'data/pq/green/</span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">:02d}</span><span class="ss">/'</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>    df_green <span class="op">=</span> spark.read <span class="op">\</span></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>        .option(<span class="st">"header"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>        .schema(green_schema) <span class="op">\</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>        .csv(input_path)</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>    df_green <span class="op">\</span></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>        .repartition(<span class="dv">4</span>) <span class="op">\</span></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>        .write.parquet(output_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>year <span class="op">=</span> <span class="dv">2020</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> month <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">13</span>):</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'processing data for </span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>    input_path <span class="op">=</span> <span class="ss">f'data/raw/yellow/</span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">:02d}</span><span class="ss">/'</span></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>    output_path <span class="op">=</span> <span class="ss">f'data/pq/yellow/</span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">:02d}</span><span class="ss">/'</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>    df_yellow <span class="op">=</span> spark.read <span class="op">\</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>        .option(<span class="st">"header"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>        .schema(yellow_schema) <span class="op">\</span></span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>        .csv(input_path)</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a>    df_yellow <span class="op">\</span></span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>        .repartition(<span class="dv">4</span>) <span class="op">\</span></span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a>        .write.parquet(output_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>year <span class="op">=</span> <span class="dv">2021</span> </span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> month <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">13</span>):</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'processing data for </span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>    input_path <span class="op">=</span> <span class="ss">f'data/raw/yellow/</span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">:02d}</span><span class="ss">/'</span></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>    output_path <span class="op">=</span> <span class="ss">f'data/pq/yellow/</span><span class="sc">{</span>year<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>month<span class="sc">:02d}</span><span class="ss">/'</span></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>    df_green <span class="op">=</span> spark.read <span class="op">\</span></span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>        .option(<span class="st">"header"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>        .schema(yellow_schema) <span class="op">\</span></span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>        .csv(input_path)</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>    df_green <span class="op">\</span></span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>        .repartition(<span class="dv">4</span>) <span class="op">\</span></span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>        .write.parquet(output_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see the structure of our downloaded parquet files using <code>tree</code> :</p>
<div class="cell" data-execution_count="225">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>tree data<span class="op">/</span>pq<span class="op">/</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data/pq/
├── green
│&nbsp;&nbsp; ├── 2020
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 01
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-8b01f98f-81fe-4596-89a1-b39326a4fc89-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-8b01f98f-81fe-4596-89a1-b39326a4fc89-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-8b01f98f-81fe-4596-89a1-b39326a4fc89-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-8b01f98f-81fe-4596-89a1-b39326a4fc89-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 02
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-3c243630-2ac8-4a06-979b-1e8a398df62a-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-3c243630-2ac8-4a06-979b-1e8a398df62a-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-3c243630-2ac8-4a06-979b-1e8a398df62a-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-3c243630-2ac8-4a06-979b-1e8a398df62a-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 03
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-be46dfd7-b4d2-4802-a124-99b9d191daf8-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-be46dfd7-b4d2-4802-a124-99b9d191daf8-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-be46dfd7-b4d2-4802-a124-99b9d191daf8-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-be46dfd7-b4d2-4802-a124-99b9d191daf8-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 04
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-cbb6d825-747e-42d8-8237-400f4cf188ee-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-cbb6d825-747e-42d8-8237-400f4cf188ee-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-cbb6d825-747e-42d8-8237-400f4cf188ee-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-cbb6d825-747e-42d8-8237-400f4cf188ee-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 05
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-199c0d3a-f772-495a-b4bd-de3261c10a84-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-199c0d3a-f772-495a-b4bd-de3261c10a84-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-199c0d3a-f772-495a-b4bd-de3261c10a84-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-199c0d3a-f772-495a-b4bd-de3261c10a84-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 06
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-6ba25688-0e78-45b5-ae85-3460a5c5e921-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-6ba25688-0e78-45b5-ae85-3460a5c5e921-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-6ba25688-0e78-45b5-ae85-3460a5c5e921-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-6ba25688-0e78-45b5-ae85-3460a5c5e921-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 07
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-626c45ff-38e2-4bdf-8add-f61defd0c946-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-626c45ff-38e2-4bdf-8add-f61defd0c946-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-626c45ff-38e2-4bdf-8add-f61defd0c946-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-626c45ff-38e2-4bdf-8add-f61defd0c946-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 08
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-70a42578-baa5-4d7b-8350-3c8b54451443-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-70a42578-baa5-4d7b-8350-3c8b54451443-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-70a42578-baa5-4d7b-8350-3c8b54451443-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-70a42578-baa5-4d7b-8350-3c8b54451443-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 09
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-7bf574b0-dfbd-461a-8ce5-f65bd261d528-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-7bf574b0-dfbd-461a-8ce5-f65bd261d528-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-7bf574b0-dfbd-461a-8ce5-f65bd261d528-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-7bf574b0-dfbd-461a-8ce5-f65bd261d528-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 10
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-030469d0-906b-477c-accd-57a0d179dd2d-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-030469d0-906b-477c-accd-57a0d179dd2d-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-030469d0-906b-477c-accd-57a0d179dd2d-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-030469d0-906b-477c-accd-57a0d179dd2d-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── 11
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-4136ae51-88ac-4aa9-9d3c-d8ee0363f9cf-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-4136ae51-88ac-4aa9-9d3c-d8ee0363f9cf-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-4136ae51-88ac-4aa9-9d3c-d8ee0363f9cf-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-4136ae51-88ac-4aa9-9d3c-d8ee0363f9cf-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp; └── 12
│&nbsp;&nbsp; │&nbsp;&nbsp;     ├── _SUCCESS
│&nbsp;&nbsp; │&nbsp;&nbsp;     ├── part-00000-5e4ac23a-9ea2-4d39-a974-72fa35bed604-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp;     ├── part-00001-5e4ac23a-9ea2-4d39-a974-72fa35bed604-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp;     ├── part-00002-5e4ac23a-9ea2-4d39-a974-72fa35bed604-c000.snappy.parquet
│&nbsp;&nbsp; │&nbsp;&nbsp;     └── part-00003-5e4ac23a-9ea2-4d39-a974-72fa35bed604-c000.snappy.parquet
│&nbsp;&nbsp; └── 2021
│&nbsp;&nbsp;     ├── 01
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00000-a9d9b6cb-a441-4c75-ad83-e0dabbe67945-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00001-a9d9b6cb-a441-4c75-ad83-e0dabbe67945-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00002-a9d9b6cb-a441-4c75-ad83-e0dabbe67945-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; └── part-00003-a9d9b6cb-a441-4c75-ad83-e0dabbe67945-c000.snappy.parquet
│&nbsp;&nbsp;     ├── 02
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00000-125ad13e-4d67-4cb1-8ae1-2fe33966fee4-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00001-125ad13e-4d67-4cb1-8ae1-2fe33966fee4-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00002-125ad13e-4d67-4cb1-8ae1-2fe33966fee4-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; └── part-00003-125ad13e-4d67-4cb1-8ae1-2fe33966fee4-c000.snappy.parquet
│&nbsp;&nbsp;     ├── 03
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00000-1bc79775-8fc3-4709-854c-3351661cd6c4-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00001-1bc79775-8fc3-4709-854c-3351661cd6c4-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00002-1bc79775-8fc3-4709-854c-3351661cd6c4-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; └── part-00003-1bc79775-8fc3-4709-854c-3351661cd6c4-c000.snappy.parquet
│&nbsp;&nbsp;     ├── 04
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00000-ceb35fd7-2ce7-4b84-83a3-cf31e6123391-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00001-ceb35fd7-2ce7-4b84-83a3-cf31e6123391-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00002-ceb35fd7-2ce7-4b84-83a3-cf31e6123391-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; └── part-00003-ceb35fd7-2ce7-4b84-83a3-cf31e6123391-c000.snappy.parquet
│&nbsp;&nbsp;     ├── 05
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00000-0f4cffc3-22ef-4558-9ceb-40c78fd0a048-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00001-0f4cffc3-22ef-4558-9ceb-40c78fd0a048-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00002-0f4cffc3-22ef-4558-9ceb-40c78fd0a048-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; └── part-00003-0f4cffc3-22ef-4558-9ceb-40c78fd0a048-c000.snappy.parquet
│&nbsp;&nbsp;     ├── 06
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── _SUCCESS
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00000-5ad0ef6e-9c3b-488a-85a0-b34a4c364eb0-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00001-5ad0ef6e-9c3b-488a-85a0-b34a4c364eb0-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── part-00002-5ad0ef6e-9c3b-488a-85a0-b34a4c364eb0-c000.snappy.parquet
│&nbsp;&nbsp;     │&nbsp;&nbsp; └── part-00003-5ad0ef6e-9c3b-488a-85a0-b34a4c364eb0-c000.snappy.parquet
│&nbsp;&nbsp;     └── 07
│&nbsp;&nbsp;         ├── _SUCCESS
│&nbsp;&nbsp;         ├── part-00000-4283b1a5-f5da-4219-97b2-2bd986599afd-c000.snappy.parquet
│&nbsp;&nbsp;         ├── part-00001-4283b1a5-f5da-4219-97b2-2bd986599afd-c000.snappy.parquet
│&nbsp;&nbsp;         ├── part-00002-4283b1a5-f5da-4219-97b2-2bd986599afd-c000.snappy.parquet
│&nbsp;&nbsp;         └── part-00003-4283b1a5-f5da-4219-97b2-2bd986599afd-c000.snappy.parquet
└── yellow
    ├── 2020
    │&nbsp;&nbsp; ├── 01
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-13e18553-247c-48af-af4e-b64c5f6024ed-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-13e18553-247c-48af-af4e-b64c5f6024ed-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-13e18553-247c-48af-af4e-b64c5f6024ed-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-13e18553-247c-48af-af4e-b64c5f6024ed-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 02
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-2bc461f8-6484-43c8-8757-97e638e454ae-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-2bc461f8-6484-43c8-8757-97e638e454ae-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-2bc461f8-6484-43c8-8757-97e638e454ae-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-2bc461f8-6484-43c8-8757-97e638e454ae-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 03
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-3c79e29b-b3fb-4f4c-9ce2-6eb6341de80c-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-3c79e29b-b3fb-4f4c-9ce2-6eb6341de80c-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-3c79e29b-b3fb-4f4c-9ce2-6eb6341de80c-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-3c79e29b-b3fb-4f4c-9ce2-6eb6341de80c-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 04
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-c7ea0f14-9b83-40d7-bc3b-168d552efe6f-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-c7ea0f14-9b83-40d7-bc3b-168d552efe6f-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-c7ea0f14-9b83-40d7-bc3b-168d552efe6f-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-c7ea0f14-9b83-40d7-bc3b-168d552efe6f-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 05
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-c966cece-74cf-4fb9-962e-9c818a4f1964-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-c966cece-74cf-4fb9-962e-9c818a4f1964-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-c966cece-74cf-4fb9-962e-9c818a4f1964-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-c966cece-74cf-4fb9-962e-9c818a4f1964-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 06
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-9fb65628-ffb1-49b4-9682-0c71b2099651-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-9fb65628-ffb1-49b4-9682-0c71b2099651-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-9fb65628-ffb1-49b4-9682-0c71b2099651-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-9fb65628-ffb1-49b4-9682-0c71b2099651-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 07
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-71ac3c30-7e37-438e-873d-1de2448ef2b6-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-71ac3c30-7e37-438e-873d-1de2448ef2b6-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-71ac3c30-7e37-438e-873d-1de2448ef2b6-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-71ac3c30-7e37-438e-873d-1de2448ef2b6-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 08
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-5f4e316f-cefd-4aa3-a5cb-b1aefe474182-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-5f4e316f-cefd-4aa3-a5cb-b1aefe474182-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-5f4e316f-cefd-4aa3-a5cb-b1aefe474182-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-5f4e316f-cefd-4aa3-a5cb-b1aefe474182-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 09
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-9cf0d56f-f5bc-42f4-9e3c-4472f1fef599-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-9cf0d56f-f5bc-42f4-9e3c-4472f1fef599-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-9cf0d56f-f5bc-42f4-9e3c-4472f1fef599-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-9cf0d56f-f5bc-42f4-9e3c-4472f1fef599-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 10
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-79c26c54-874e-4a96-9ad6-b38b1b938766-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-79c26c54-874e-4a96-9ad6-b38b1b938766-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-79c26c54-874e-4a96-9ad6-b38b1b938766-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-79c26c54-874e-4a96-9ad6-b38b1b938766-c000.snappy.parquet
    │&nbsp;&nbsp; ├── 11
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── _SUCCESS
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00000-b3646277-b1f2-495f-a225-12cae19dc1ff-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00001-b3646277-b1f2-495f-a225-12cae19dc1ff-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; ├── part-00002-b3646277-b1f2-495f-a225-12cae19dc1ff-c000.snappy.parquet
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── part-00003-b3646277-b1f2-495f-a225-12cae19dc1ff-c000.snappy.parquet
    │&nbsp;&nbsp; └── 12
    │&nbsp;&nbsp;     ├── _SUCCESS
    │&nbsp;&nbsp;     ├── part-00000-ab762734-8696-4d42-8f9d-d5b924d4fb29-c000.snappy.parquet
    │&nbsp;&nbsp;     ├── part-00001-ab762734-8696-4d42-8f9d-d5b924d4fb29-c000.snappy.parquet
    │&nbsp;&nbsp;     ├── part-00002-ab762734-8696-4d42-8f9d-d5b924d4fb29-c000.snappy.parquet
    │&nbsp;&nbsp;     └── part-00003-ab762734-8696-4d42-8f9d-d5b924d4fb29-c000.snappy.parquet
    └── 2021
        ├── 01
        │&nbsp;&nbsp; ├── _SUCCESS
        │&nbsp;&nbsp; ├── part-00000-1d24a28b-80bb-4115-9650-456962d66d59-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00001-1d24a28b-80bb-4115-9650-456962d66d59-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00002-1d24a28b-80bb-4115-9650-456962d66d59-c000.snappy.parquet
        │&nbsp;&nbsp; └── part-00003-1d24a28b-80bb-4115-9650-456962d66d59-c000.snappy.parquet
        ├── 02
        │&nbsp;&nbsp; ├── _SUCCESS
        │&nbsp;&nbsp; ├── part-00000-79399355-08a8-44fd-9a60-1cb83a19454e-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00001-79399355-08a8-44fd-9a60-1cb83a19454e-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00002-79399355-08a8-44fd-9a60-1cb83a19454e-c000.snappy.parquet
        │&nbsp;&nbsp; └── part-00003-79399355-08a8-44fd-9a60-1cb83a19454e-c000.snappy.parquet
        ├── 03
        │&nbsp;&nbsp; ├── _SUCCESS
        │&nbsp;&nbsp; ├── part-00000-b1231c11-d032-4088-b387-24cc04eaff40-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00001-b1231c11-d032-4088-b387-24cc04eaff40-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00002-b1231c11-d032-4088-b387-24cc04eaff40-c000.snappy.parquet
        │&nbsp;&nbsp; └── part-00003-b1231c11-d032-4088-b387-24cc04eaff40-c000.snappy.parquet
        ├── 04
        │&nbsp;&nbsp; ├── _SUCCESS
        │&nbsp;&nbsp; ├── part-00000-828ae8bb-c582-4e3e-a25b-8ffac100299e-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00001-828ae8bb-c582-4e3e-a25b-8ffac100299e-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00002-828ae8bb-c582-4e3e-a25b-8ffac100299e-c000.snappy.parquet
        │&nbsp;&nbsp; └── part-00003-828ae8bb-c582-4e3e-a25b-8ffac100299e-c000.snappy.parquet
        ├── 05
        │&nbsp;&nbsp; ├── _SUCCESS
        │&nbsp;&nbsp; ├── part-00000-a06be6df-4c6a-4a9c-994b-2e579cd79fd5-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00001-a06be6df-4c6a-4a9c-994b-2e579cd79fd5-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00002-a06be6df-4c6a-4a9c-994b-2e579cd79fd5-c000.snappy.parquet
        │&nbsp;&nbsp; └── part-00003-a06be6df-4c6a-4a9c-994b-2e579cd79fd5-c000.snappy.parquet
        ├── 06
        │&nbsp;&nbsp; ├── _SUCCESS
        │&nbsp;&nbsp; ├── part-00000-1d9a9dc9-eda5-44c8-b21d-2d8c3d6d0e62-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00001-1d9a9dc9-eda5-44c8-b21d-2d8c3d6d0e62-c000.snappy.parquet
        │&nbsp;&nbsp; ├── part-00002-1d9a9dc9-eda5-44c8-b21d-2d8c3d6d0e62-c000.snappy.parquet
        │&nbsp;&nbsp; └── part-00003-1d9a9dc9-eda5-44c8-b21d-2d8c3d6d0e62-c000.snappy.parquet
        └── 07
            ├── _SUCCESS
            ├── part-00000-98a78c13-da79-4520-b66e-f7ba8384138e-c000.snappy.parquet
            ├── part-00001-98a78c13-da79-4520-b66e-f7ba8384138e-c000.snappy.parquet
            ├── part-00002-98a78c13-da79-4520-b66e-f7ba8384138e-c000.snappy.parquet
            └── part-00003-98a78c13-da79-4520-b66e-f7ba8384138e-c000.snappy.parquet

44 directories, 190 files</code></pre>
</div>
</div>
</section>
<section id="sql-with-spark" class="level3">
<h3 class="anchored" data-anchor-id="sql-with-spark">5.3.4 SQL with Spark</h3>
<p>We are going to recreate the <code>monthly_zone_revenue</code> model that we created previously in Week 4 using <code>dbt</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>{{ config(materialized<span class="op">=</span><span class="st">'table'</span>) }}</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> trips_data <span class="im">as</span> (</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>    select <span class="op">*</span> <span class="im">from</span> {{ ref(<span class="st">'fact_trips'</span>) }}</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>    select </span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span> Reveneue grouping </span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>    pickup_zone <span class="im">as</span> revenue_zone,</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>    date_trunc(<span class="st">'month'</span>, pickup_datetime) <span class="im">as</span> revenue_month, </span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>Note: For BQ use instead: date_trunc(pickup_datetime, month) <span class="im">as</span> revenue_month, </span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>    service_type, </span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span> Revenue calculation </span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(fare_amount) <span class="im">as</span> revenue_monthly_fare,</span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(extra) <span class="im">as</span> revenue_monthly_extra,</span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(mta_tax) <span class="im">as</span> revenue_monthly_mta_tax,</span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(tip_amount) <span class="im">as</span> revenue_monthly_tip_amount,</span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(tolls_amount) <span class="im">as</span> revenue_monthly_tolls_amount,</span>
<span id="cb72-20"><a href="#cb72-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(ehail_fee) <span class="im">as</span> revenue_monthly_ehail_fee,</span>
<span id="cb72-21"><a href="#cb72-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(improvement_surcharge) <span class="im">as</span> revenue_monthly_improvement_surcharge,</span>
<span id="cb72-22"><a href="#cb72-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(total_amount) <span class="im">as</span> revenue_monthly_total_amount,</span>
<span id="cb72-23"><a href="#cb72-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(congestion_surcharge) <span class="im">as</span> revenue_monthly_congestion_surcharge,</span>
<span id="cb72-24"><a href="#cb72-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-25"><a href="#cb72-25" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span> Additional calculations</span>
<span id="cb72-26"><a href="#cb72-26" aria-hidden="true" tabindex="-1"></a>    count(tripid) <span class="im">as</span> total_monthly_trips,</span>
<span id="cb72-27"><a href="#cb72-27" aria-hidden="true" tabindex="-1"></a>    avg(passenger_count) <span class="im">as</span> avg_montly_passenger_count,</span>
<span id="cb72-28"><a href="#cb72-28" aria-hidden="true" tabindex="-1"></a>    avg(trip_distance) <span class="im">as</span> avg_montly_trip_distance</span>
<span id="cb72-29"><a href="#cb72-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-30"><a href="#cb72-30" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> trips_data</span>
<span id="cb72-31"><a href="#cb72-31" aria-hidden="true" tabindex="-1"></a>    group by <span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>First, let’s replicate the <code>trips_data</code> dataset which was created in Week 4 by combining the yellow and green datasets :</p>
<div class="cell" data-execution_count="226">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> spark.read.parquet(<span class="st">'data/pq/green/*/*'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="227">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>df_green.printSchema()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>root
 |-- VendorID: integer (nullable = true)
 |-- lpep_pickup_datetime: timestamp (nullable = true)
 |-- lpep_dropoff_datetime: timestamp (nullable = true)
 |-- store_and_fwd_flag: string (nullable = true)
 |-- RatecodeID: integer (nullable = true)
 |-- PULocationID: integer (nullable = true)
 |-- DOLocationID: integer (nullable = true)
 |-- passenger_count: integer (nullable = true)
 |-- trip_distance: double (nullable = true)
 |-- fare_amount: double (nullable = true)
 |-- extra: double (nullable = true)
 |-- mta_tax: double (nullable = true)
 |-- tip_amount: double (nullable = true)
 |-- tolls_amount: double (nullable = true)
 |-- ehail_fee: double (nullable = true)
 |-- improvement_surcharge: double (nullable = true)
 |-- total_amount: double (nullable = true)
 |-- payment_type: integer (nullable = true)
 |-- trip_type: integer (nullable = true)
 |-- congestion_surcharge: double (nullable = true)
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="228">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> spark.read.parquet(<span class="st">'data/pq/yellow/*/*'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="229">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>df_yellow.printSchema()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>root
 |-- VendorID: integer (nullable = true)
 |-- tpep_pickup_datetime: timestamp (nullable = true)
 |-- tpep_dropoff_datetime: timestamp (nullable = true)
 |-- passenger_count: integer (nullable = true)
 |-- trip_distance: double (nullable = true)
 |-- RatecodeID: integer (nullable = true)
 |-- store_and_fwd_flag: string (nullable = true)
 |-- PULocationID: integer (nullable = true)
 |-- DOLocationID: integer (nullable = true)
 |-- payment_type: integer (nullable = true)
 |-- fare_amount: double (nullable = true)
 |-- extra: double (nullable = true)
 |-- mta_tax: double (nullable = true)
 |-- tip_amount: double (nullable = true)
 |-- tolls_amount: double (nullable = true)
 |-- improvement_surcharge: double (nullable = true)
 |-- total_amount: double (nullable = true)
 |-- congestion_surcharge: double (nullable = true)
</code></pre>
</div>
</div>
<p>The pick up and drop off fields have a different naming convention, Let’s correct for that using <code>.withColumnRenamed</code>:</p>
<div class="cell" data-execution_count="230">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> df_green <span class="op">\</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>) <span class="op">\</span></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="231">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> df_yellow <span class="op">\</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>) <span class="op">\</span></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We only want to combine on common columns, but there is still some inconsistency between the two datasets, for example green has <code>ehail_fee</code> whereas yellow does not. We can use Python’s <a href="https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset">set</a> object to help with this :</p>
<div class="cell" data-execution_count="232">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>common_columns <span class="op">=</span> []</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>yellow_columns <span class="op">=</span> <span class="bu">set</span>(df_yellow.columns)</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> df_green.columns:</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> col <span class="kw">in</span> yellow_columns:</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>        common_columns.append(col)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="233">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>common_columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="233">
<pre><code>['VendorID',
 'pickup_datetime',
 'dropoff_datetime',
 'store_and_fwd_flag',
 'RatecodeID',
 'PULocationID',
 'DOLocationID',
 'passenger_count',
 'trip_distance',
 'fare_amount',
 'extra',
 'mta_tax',
 'tip_amount',
 'tolls_amount',
 'improvement_surcharge',
 'total_amount',
 'payment_type',
 'congestion_surcharge']</code></pre>
</div>
</div>
<p>We want to be able to distinguish between the yellow and green taxi services in our combined data set. To do this, prior to combining, we should add a new column to our green and yellow datasets named <code>service_type</code>. To add a new column to a PySpark DataFrame we can use the <a href="https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.functions.lit.html">.lit() function</a>.</p>
<div class="cell" data-execution_count="234">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> functions <span class="im">as</span> F</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="235">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">\</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>    .select(common_columns) <span class="op">\</span></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'green'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="235">
<pre><code>DataFrame[VendorID: int, pickup_datetime: timestamp, dropoff_datetime: timestamp, store_and_fwd_flag: string, RatecodeID: int, PULocationID: int, DOLocationID: int, passenger_count: int, trip_distance: double, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, payment_type: int, congestion_surcharge: double, service_type: string]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="236">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">\</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>    .select(common_columns) <span class="op">\</span></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'yellow'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="236">
<pre><code>DataFrame[VendorID: int, pickup_datetime: timestamp, dropoff_datetime: timestamp, store_and_fwd_flag: string, RatecodeID: int, PULocationID: int, DOLocationID: int, passenger_count: int, trip_distance: double, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, payment_type: int, congestion_surcharge: double, service_type: string]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="237">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>df_green_sel <span class="op">=</span> df_green <span class="op">\</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>    .select(common_columns) <span class="op">\</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'green'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="238">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>df_yellow_sel <span class="op">=</span> df_yellow <span class="op">\</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>    .select(common_columns) <span class="op">\</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'yellow'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To merge our green and yellow datasets we can once again make use of one of Python’s <code>set</code>functions <code>.unionALL</code>:</p>
<div class="cell" data-execution_count="239">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>df_green_sel.unionAll(df_yellow_sel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="239">
<pre><code>DataFrame[VendorID: int, pickup_datetime: timestamp, dropoff_datetime: timestamp, store_and_fwd_flag: string, RatecodeID: int, PULocationID: int, DOLocationID: int, passenger_count: int, trip_distance: double, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, payment_type: int, congestion_surcharge: double, service_type: string]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="240">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>df_trips_data <span class="op">=</span> df_green_sel.unionAll(df_yellow_sel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And we can use <code>.groupBy</code> to show the distribution by service type :</p>
<div class="cell" data-execution_count="241">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>df_trips_data.groupBy(<span class="st">'service_type'</span>).count().show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[Stage 341:===================================&gt;                  (24 + 13) / 37]                                                                                </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+--------+
|service_type|   count|
+------------+--------+
|       green| 2304517|
|      yellow|39649199|
+------------+--------+
</code></pre>
</div>
</div>
<section id="querying-the-data-with-sql" class="level4">
<h4 class="anchored" data-anchor-id="querying-the-data-with-sql">Querying the data with SQL</h4>
<p>First, let’s register a temporary table :</p>
<div class="cell" data-execution_count="244">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>df_trips_data.registerTempTable(<span class="st">'trips_data'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/stephen137/mambaforge/lib/python3.10/site-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.
  warnings.warn("Deprecated in 2.0, use createOrReplaceTempView instead.", FutureWarning)</code></pre>
</div>
</div>
<p>We can run SQL queries in Spark using <code>spark.sql</code> :</p>
<div class="cell" data-execution_count="245">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>spark.sql(<span class="st">"""</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT</span></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="st">    service_type,</span></span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a><span class="st">    count(1)</span></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a><span class="st">FROM</span></span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a><span class="st">    trips_data</span></span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY </span></span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a><span class="st">    service_type</span></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>).show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[Stage 344:=====================================&gt;                (26 + 11) / 37]                                                                                </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+--------+
|service_type|count(1)|
+------------+--------+
|       green| 2304517|
|      yellow|39649199|
+------------+--------+
</code></pre>
</div>
</div>
<p>Let’s get all the column names as a list :</p>
<div class="cell" data-execution_count="243">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>df_trips_data.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="243">
<pre><code>['VendorID',
 'pickup_datetime',
 'dropoff_datetime',
 'store_and_fwd_flag',
 'RatecodeID',
 'PULocationID',
 'DOLocationID',
 'passenger_count',
 'trip_distance',
 'fare_amount',
 'extra',
 'mta_tax',
 'tip_amount',
 'tolls_amount',
 'improvement_surcharge',
 'total_amount',
 'payment_type',
 'congestion_surcharge',
 'service_type']</code></pre>
</div>
</div>
<p>Let’s finally replicate the <code>monthly_zone_revenue</code> model created in Week 4 using <code>dbt</code>:</p>
<div class="cell" data-execution_count="246">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>df_result <span class="op">=</span> spark.sql(<span class="st">"""</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT </span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Reveneue grouping </span></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a><span class="st">    PULocationID AS revenue_zone,</span></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a><span class="st">    date_trunc('month', pickup_datetime) AS revenue_month, </span></span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a><span class="st">    service_type, </span></span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Revenue calculation </span></span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(fare_amount) AS revenue_monthly_fare,</span></span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(extra) AS revenue_monthly_extra,</span></span>
<span id="cb104-11"><a href="#cb104-11" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(mta_tax) AS revenue_monthly_mta_tax,</span></span>
<span id="cb104-12"><a href="#cb104-12" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tip_amount) AS revenue_monthly_tip_amount,</span></span>
<span id="cb104-13"><a href="#cb104-13" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tolls_amount) AS revenue_monthly_tolls_amount,</span></span>
<span id="cb104-14"><a href="#cb104-14" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,</span></span>
<span id="cb104-15"><a href="#cb104-15" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(total_amount) AS revenue_monthly_total_amount,</span></span>
<span id="cb104-16"><a href="#cb104-16" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,</span></span>
<span id="cb104-17"><a href="#cb104-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-18"><a href="#cb104-18" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Additional calculations</span></span>
<span id="cb104-19"><a href="#cb104-19" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(passenger_count) AS avg_montly_passenger_count,</span></span>
<span id="cb104-20"><a href="#cb104-20" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(trip_distance) AS avg_montly_trip_distance</span></span>
<span id="cb104-21"><a href="#cb104-21" aria-hidden="true" tabindex="-1"></a><span class="st">FROM</span></span>
<span id="cb104-22"><a href="#cb104-22" aria-hidden="true" tabindex="-1"></a><span class="st">    trips_data</span></span>
<span id="cb104-23"><a href="#cb104-23" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY</span></span>
<span id="cb104-24"><a href="#cb104-24" aria-hidden="true" tabindex="-1"></a><span class="st">    1, 2, 3</span></span>
<span id="cb104-25"><a href="#cb104-25" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="247">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>df_result.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[Stage 347:=====================================================&gt; (36 + 1) / 37]                                                                                </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+--------------------------+------------------------+
|revenue_zone|      revenue_month|service_type|revenue_monthly_fare|revenue_monthly_extra|revenue_monthly_mta_tax|revenue_monthly_tip_amount|revenue_monthly_tolls_amount|revenue_monthly_improvement_surcharge|revenue_monthly_total_amount|revenue_monthly_congestion_surcharge|avg_montly_passenger_count|avg_montly_trip_distance|
+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+--------------------------+------------------------+
|          47|2020-01-01 00:00:00|       green|  16630.150000000023|               1192.0|                  160.0|        42.230000000000004|           523.0000000000002|                   210.90000000000015|          18770.429999999975|                                11.0|         1.177685950413223|       4.645000000000002|
|          53|2020-01-01 00:00:00|       green|   6281.649999999996|               330.25|                   49.0|                     39.22|          102.50000000000001|                    68.39999999999988|           6873.770000000004|                                2.75|        1.2417582417582418|       6.929710743801654|
|         128|2020-01-01 00:00:00|       green|   3261.330000000001|                158.0|                   35.5|                     82.25|          104.03999999999999|                    34.50000000000004|          3714.0200000000004|                                27.5|        1.0169491525423728|       7.023280000000001|
|         150|2020-01-01 00:00:00|       green|             9996.16|                627.5|                   98.0|         97.86999999999998|                      149.14|                   109.49999999999962|          11082.069999999992|                                 0.0|        1.1147540983606556|       5.393588516746414|
|         263|2020-01-01 00:00:00|       green|   8987.339999999998|                561.0|                 124.55|                    315.27|           335.0600000000001|                    127.1999999999995|          10684.170000000004|                              239.25|        1.4293478260869565|       5.264249422632793|
|          19|2020-01-01 00:00:00|       green|   7798.879999999999|                377.0|                   42.0|                      6.66|          174.40000000000003|                     67.4999999999999|           8466.440000000004|                                 0.0|                  1.046875|       7.850781893004114|
|         186|2020-01-01 00:00:00|       green|             1539.23|                85.25|                    6.0|                       0.0|           97.91999999999999|                                 13.8|          1742.1999999999998|                                 0.0|        1.6666666666666667|       9.389565217391304|
|         238|2020-01-01 00:00:00|       green|   5397.990000000001|                403.5|                   20.0|                       0.0|                      124.68|                    61.19999999999993|           6007.370000000001|                                 0.0|                       1.2|       6.460536585365853|
|         126|2020-01-01 00:00:00|       green|   11827.83999999999|               766.75|                  110.5|        101.86999999999999|           458.2800000000002|                   145.19999999999933|          13425.340000000004|                                11.0|                     1.275|       5.187806691449811|
|          96|2020-01-01 00:00:00|       green|   628.8000000000001|                 27.5|                    4.0|                       0.0|                       55.08|                    5.699999999999999|           721.0799999999999|                                 0.0|        1.1428571428571428|      7.0195454545454545|
|         116|2020-01-01 00:00:00|       green|   78706.70999999996|              3319.25|                 2632.5|         5847.950000000004|          1467.9299999999985|                   1756.4999999999027|           96138.29000000306|                              2793.0|         1.212485896953742|       3.068908940397343|
|          90|2020-01-01 00:00:00|       green|             2921.62|                165.0|                   19.0|                       0.0|          190.56000000000006|                   25.800000000000022|          3321.9800000000005|                                 0.0|                       1.2|       8.451627906976745|
|         101|2020-01-01 00:00:00|       green|   8472.769999999997|                460.5|                   38.0|        15.219999999999999|          232.56000000000006|                    70.49999999999986|           9289.550000000001|                                2.75|        1.0512820512820513|       9.081153846153853|
|         227|2020-01-01 00:00:00|       green|  14857.100000000011|               776.75|                   94.5|        21.569999999999997|          271.57000000000005|                   137.09999999999937|          16173.289999999986|                                 0.0|        1.0743801652892562|       7.235522088353416|
|         180|2020-01-01 00:00:00|       green|  4024.4600000000005|               210.75|                   26.0|                     20.24|           84.88999999999999|                    43.20000000000006|           4414.240000000002|                                2.75|        1.3396226415094339|       5.324473684210526|
|         190|2020-01-01 00:00:00|       green|  3786.0199999999995|                175.0|                   76.5|        242.16000000000008|                       24.48|                    62.69999999999993|           4419.360000000001|                               35.75|        1.4244604316546763|      3.5506912442396326|
|         264|2008-12-01 00:00:00|       green|                 0.0|                  0.0|                    0.0|                       0.0|                         0.0|                                  0.0|                         0.0|                                 0.0|                       1.0|                     0.0|
|         119|2020-01-01 00:00:00|       green|  21224.650000000012|               1391.0|                  186.5|                     74.62|           730.0800000000004|                    245.7000000000011|           23870.19999999996|                               13.75|        1.1612903225806452|       5.585108695652177|
|          26|2020-01-01 00:00:00|       green|   27098.79000000005|              1743.25|                  221.5|        121.72999999999999|           551.2800000000002|                   292.50000000000233|           30034.89999999993|                                 0.0|        1.1054852320675106|       4.771315789473685|
|         120|2020-01-01 00:00:00|       green|   692.4300000000001|                 5.25|                    7.0|        21.970000000000002|                       12.24|                    8.399999999999999|           752.7899999999998|                                 5.5|        1.1935483870967742|               4.6365625|
+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+--------------------------+------------------------+
only showing top 20 rows
</code></pre>
</div>
</div>
<p>And save our results :</p>
<div class="cell" data-execution_count="248">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>df_result.coalesce(<span class="dv">1</span>).write.parquet(<span class="st">'data/report/revenue/'</span>, mode<span class="op">=</span><span class="st">'overwrite'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>                                                                                </code></pre>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/c786d060-8518-4664-839c-c779f95d9e5d-1-e5ca3ac6-d4a2-4f72-94cd-00ff16271c24.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">revenue_report.PNG</figcaption>
</figure>
</div>
<p>The <code>coalesce()</code> is used to decrease the number of partitions in an efficient way :</p>
<div class="cell" data-execution_count="253">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls <span class="op">-</span>lh data<span class="op">/</span>report<span class="op">/</span>revenue</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>total 516K
-rw-r--r-- 1 stephen137 stephen137    0 Mar 30 15:37 _SUCCESS
-rw-r--r-- 1 stephen137 stephen137 513K Mar 30 15:37 part-00000-ee412a0e-dd1d-4ab7-a912-c9ebe84034ec-c000.snappy.parquet</code></pre>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/9b86bd5e-e610-42ff-80d1-52ac8a0c8c14-1-5a667343-4161-41e3-a964-555c5135b9d1.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">coalesce.PNG</figcaption>
</figure>
</div>
<p>Note that we haven’t written the results to a data warehouse yet. We are still effectively operating in our data lake, with a bunch of files.</p>
</section>
</section>
<section id="anatomy-of-a-spark-cluster" class="level3">
<h3 class="anchored" data-anchor-id="anatomy-of-a-spark-cluster">5.4.1 Anatomy of a Spark Cluster</h3>
<p>A Spark cluster is a group of computers (also known as <code>nodes</code>) that work together to process and analyze large sets of data. Spark is an open-source, distributed computing system that can be used for big data processing, machine learning, and other data-intensive tasks. The cluster is managed by a master node that coordinates the work of the other nodes, and distributes the data among them. This allows Spark to process and analyze large amounts of data quickly and efficiently.</p>
<p>Spark applications run as independent sets of processes on a <code>cluster</code>, coordinated by the SparkContext object in your main program (called the <code>driver program</code>).</p>
<p>Specifically, to run on a cluster, the SparkContext can connect to several types of <code>cluster managers</code> (either Spark’s own standalone cluster manager, Mesos, YARN or Kubernetes), which allocate resources across applications. Once connected, Spark acquires <code>executors</code> on nodes in the cluster, which are processes that run computations and store data for your application. Next, it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors. Finally, SparkContext sends <code>tasks</code> to the executors to run.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/64249812-520f-47cc-8566-629587f9bd42-1-195e32e0-940d-40c8-9685-85060167ce14.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">cluster_architecture.PNG</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/64249812-520f-47cc-8566-629587f9bd42-2-51130df4-5682-4cd9-9bd3-4ff80d5fe9f4.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_execution.PNG</figcaption>
</figure>
</div>
<p><code>Cluster Manager Types</code> The system currently supports several cluster managers:</p>
<ul>
<li><a href="https://spark.apache.org/docs/3.3.2/spark-standalone.html">Standalone</a> – a simple cluster manager included with Spark that makes it easy to set up a cluster.</li>
<li><a href="https://spark.apache.org/docs/3.3.2/running-on-yarn.html">Hadoop YARN</a> – the resource manager in Hadoop 2 and 3.</li>
<li><a href="https://spark.apache.org/docs/3.3.2/running-on-kubernetes.html">Kubernetes</a> – an open-source system for automating deployment, scaling, and management of containerized applications.</li>
</ul>
<p>For a comprehensive overview take a look at this <a href="https://sparkbyexamples.com/">useful guide</a> with worked examples.</p>
<p><code>Cluster and partitions</code></p>
<p>Spark/PySpark partitioning is a way to split the data into multiple partitions so that you can execute transformations on multiple partitions in parallel which results in faster job completion. You can also write partitioned data into a file system (multiple sub-directories) for faster reads by downstream systems.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/0ef0a979-fed2-406d-94cf-e73df7a982b0-1-c0627bbd-dc5c-446f-8dab-2907910272cf.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_components.PNG</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/0ef0a979-fed2-406d-94cf-e73df7a982b0-2-d8bf9169-fe1c-45f2-b3af-86edb276d280.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_execution_plan.PNG</figcaption>
</figure>
</div>
<p>The following table summarizes terms you’ll see used to refer to cluster concepts:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/32f94295-c321-4395-b250-5adde1d4f7f8-1-7b988b45-2af4-4c9d-9b42-f8f2c09f8eb1.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">cluster_glossary.PNG</figcaption>
</figure>
</div>
</section>
<section id="groupby-in-spark" class="level3">
<h3 class="anchored" data-anchor-id="groupby-in-spark">5.4.2 GroupBy in Spark</h3>
<p>Let’s now look at how Spark implements <code>GroupBy</code> :</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import required packages</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a><span class="co"># our entry point to Spark</span></span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a>spark</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">

            <div>
                <p><b>SparkSession - in-memory</b></p>
                
        <div>
            <p><b>SparkContext</b></p>

            <p><a href="http://172.24.13.131:4040">Spark UI</a></p>

            <dl>
              <dt>Version</dt>
                <dd><code>v3.3.2</code></dd>
              <dt>Master</dt>
                <dd><code>local[*]</code></dd>
              <dt>AppName</dt>
                <dd><code>test</code></dd>
            </dl>
        </div>
        
            </div>
        
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load in green taxi data</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> spark.read.parquet(<span class="st">'data/pq/green/*/*'</span>)</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>df_green.createOrReplaceTempView(<span class="st">"green"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co"># GroupBy query - green taxi</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>df_green_revenue <span class="op">=</span> spark.sql(<span class="st">"""</span></span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT</span></span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="st">    date_trunc('hour', lpep_pickup_datetime) AS hour,</span></span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a><span class="st">    PULocationID AS zone,</span></span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-7"><a href="#cb114-7" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(total_amount) AS amount,</span></span>
<span id="cb114-8"><a href="#cb114-8" aria-hidden="true" tabindex="-1"></a><span class="st">    COUNT(1) AS number_records</span></span>
<span id="cb114-9"><a href="#cb114-9" aria-hidden="true" tabindex="-1"></a><span class="st">FROM</span></span>
<span id="cb114-10"><a href="#cb114-10" aria-hidden="true" tabindex="-1"></a><span class="st">    green</span></span>
<span id="cb114-11"><a href="#cb114-11" aria-hidden="true" tabindex="-1"></a><span class="st">WHERE</span></span>
<span id="cb114-12"><a href="#cb114-12" aria-hidden="true" tabindex="-1"></a><span class="st">    lpep_pickup_datetime &gt;= '2020-01-01 00:00:00'</span></span>
<span id="cb114-13"><a href="#cb114-13" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY</span></span>
<span id="cb114-14"><a href="#cb114-14" aria-hidden="true" tabindex="-1"></a><span class="st">    1, 2</span></span>
<span id="cb114-15"><a href="#cb114-15" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Write our result to parquet</span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>df_green_revenue <span class="op">\</span></span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>    .repartition(<span class="dv">20</span>) <span class="op">\</span></span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a>    .write.parquet(<span class="st">'data/report/revenue/green'</span>, mode<span class="op">=</span><span class="st">'overwrite'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>df_green_revenue.show(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------------+----+------------------+--------------+
|               hour|zone|            amount|number_records|
+-------------------+----+------------------+--------------+
|2020-01-24 09:00:00|  81|             59.49|             2|
|2020-01-04 21:00:00|  25|            513.83|            32|
|2020-01-10 19:00:00|  66| 545.6800000000002|            27|
|2020-01-30 07:00:00|  75| 556.6600000000001|            40|
|2020-01-18 01:00:00| 260|            144.56|            12|
|2020-01-12 08:00:00| 177|31.090000000000003|             2|
|2020-01-20 21:00:00| 166|            133.28|            12|
|2020-01-03 04:00:00|  14|            105.34|             2|
|2020-01-30 20:00:00|  74| 766.4400000000002|            58|
|2020-01-02 16:00:00|  66|             257.0|            12|
+-------------------+----+------------------+--------------+
only showing top 10 rows
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load in yellow  taxi data</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> spark.read.parquet(<span class="st">'data/pq/yellow/*/*'</span>)</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>df_yellow.createOrReplaceTempView(<span class="st">"yellow"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="co"># GroupBy query - yellow taxi</span></span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>df_yellow_revenue <span class="op">=</span> spark.sql(<span class="st">"""</span></span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT</span></span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a><span class="st">    date_trunc('hour', tpep_pickup_datetime) AS hour,</span></span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a><span class="st">    PULocationID AS zone,</span></span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(total_amount) AS amount,</span></span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true" tabindex="-1"></a><span class="st">    COUNT(1) AS number_records</span></span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true" tabindex="-1"></a><span class="st">FROM</span></span>
<span id="cb119-10"><a href="#cb119-10" aria-hidden="true" tabindex="-1"></a><span class="st">    yellow</span></span>
<span id="cb119-11"><a href="#cb119-11" aria-hidden="true" tabindex="-1"></a><span class="st">WHERE</span></span>
<span id="cb119-12"><a href="#cb119-12" aria-hidden="true" tabindex="-1"></a><span class="st">    tpep_pickup_datetime &gt;= '2020-01-01 00:00:00'</span></span>
<span id="cb119-13"><a href="#cb119-13" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY</span></span>
<span id="cb119-14"><a href="#cb119-14" aria-hidden="true" tabindex="-1"></a><span class="st">    1, 2</span></span>
<span id="cb119-15"><a href="#cb119-15" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Write our result to parquet</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>df_yellow_revenue <span class="op">\</span></span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>    .repartition(<span class="dv">20</span>) <span class="op">\</span></span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>    .write.parquet(<span class="st">'data/report/revenue/yellow'</span>, mode<span class="op">=</span><span class="st">'overwrite'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>df_yellow_revenue.show(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[Stage 17:================================================&gt;       (18 + 3) / 21]                                                                                </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------------+----+------------------+--------------+
|               hour|zone|            amount|number_records|
+-------------------+----+------------------+--------------+
|2020-01-03 19:00:00| 142| 6023.089999999995|           403|
|2020-01-26 14:00:00| 239| 6541.649999999994|           437|
|2020-01-09 01:00:00| 100|            653.56|            37|
|2020-01-31 18:00:00| 237|12689.400000000009|           810|
|2020-01-04 03:00:00| 246|2092.5400000000004|           121|
|2020-01-14 09:00:00| 239| 4882.359999999997|           298|
|2020-01-27 16:00:00| 162| 7989.979999999996|           452|
|2020-01-17 20:00:00| 170| 6884.189999999997|           407|
|2020-01-23 15:00:00| 142| 5378.829999999997|           341|
|2020-01-27 06:00:00|  24|            536.49|            23|
+-------------------+----+------------------+--------------+
only showing top 10 rows
</code></pre>
</div>
</div>
<section id="what-exactly-is-spark-doing" class="level4">
<h4 class="anchored" data-anchor-id="what-exactly-is-spark-doing">What exactly is Spark doing ?</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/02b6c901-8cfb-46c5-af4c-b74e14b56b92-1-4278791d-572f-4c34-ac4e-063ae300df4f.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">groupby_stage_1.PNG</figcaption>
</figure>
</div>
<p><code>Shuffling</code></p>
<p><em>Shuffling</em> is a mechanism Spark uses to redistribute the data across different executors and even across machines. Spark shuffling triggers for transformation operations like <code>reducebyKey()</code>, <code>join()</code>, <code>groupBy()</code> etc.</p>
<p>Spark Shuffle is an expensive operation since it involves the following :</p>
<ul>
<li>disk I/O</li>
<li>data serialization and deserialization</li>
<li>network I/O</li>
</ul>
<p>When creating an RDD, Spark doesn’t necessarily store the data for all keys in a partition since at the time of creation there is no way we can set the key for the data set. Hence, when we run the reduceByKey() operation to aggregate the data on keys, Spark does the following :</p>
<ul>
<li>first runs map tasks on all partitions which groups all values for a single key</li>
<li>the results of the map tasks are kept in memory</li>
<li>when results do not fit in memory, Spark stores the data on a disk</li>
<li>shuffles the mapped data across partitions, sometimes it also stores the shuffled data into a disk for reuse when it needs to recalculate</li>
<li>run the garbage collection</li>
<li>finally runs reduce tasks on each partition based on key</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/02b6c901-8cfb-46c5-af4c-b74e14b56b92-2-8d0b8f70-f843-459b-84d1-9e33616dc123.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">groupby_stage_2.PNG</figcaption>
</figure>
</div>
</section>
</section>
<section id="joins-in-spark" class="level3">
<h3 class="anchored" data-anchor-id="joins-in-spark">5.4.3 Joins in Spark</h3>
<p><code>joining our yellow and green tables by hour and by zone</code></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/99ff377f-685e-46bd-a3dd-b6fa713263d3-1-5903c39b-6bcd-41ce-9323-541c1575e1f3.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">join.PNG</figcaption>
</figure>
</div>
<p>Let’s use the results saved previously :</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>df_green_revenue <span class="op">=</span> spark.read.parquet(<span class="st">'data/report/revenue/green'</span>)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>df_yellow_revenue <span class="op">=</span> spark.read.parquet(<span class="st">'data/report/revenue/yellow'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Rename the columns :</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>df_green_revenue_tmp <span class="op">=</span> df_green_revenue <span class="op">\</span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'amount'</span>, <span class="st">'green_amount'</span>) <span class="op">\</span></span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'number_records'</span>, <span class="st">'green_number_records'</span>)</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a>df_yellow_revenue_tmp <span class="op">=</span> df_yellow_revenue <span class="op">\</span></span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'amount'</span>, <span class="st">'yellow_amount'</span>) <span class="op">\</span></span>
<span id="cb125-7"><a href="#cb125-7" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'number_records'</span>, <span class="st">'yellow_number_records'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And join the two tables :</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>df_join <span class="op">=</span> df_green_revenue_tmp.join(df_yellow_revenue_tmp, on<span class="op">=</span>[<span class="st">'hour'</span>, <span class="st">'zone'</span>], how<span class="op">=</span><span class="st">'outer'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Write the result to parquet and show the result :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>df_join.write.parquet(<span class="st">'data/report/revenue/total'</span>, mode<span class="op">=</span><span class="st">'overwrite'</span>)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>df_join.show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/d0a2298d-6c2d-444f-9d1e-58deaabc8989-1-83487d02-5340-4dcb-9bc5-96fbf7ccfcd2.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">join_parquet.PNG</figcaption>
</figure>
</div>
<section id="what-exactly-is-spark-doing-1" class="level4">
<h4 class="anchored" data-anchor-id="what-exactly-is-spark-doing-1">What exactly is Spark doing ?</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/5d71338c-5cc7-433e-8660-b1d552280b4c-1-f3c7a922-8e1b-4d04-83ca-264734f87878.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">merge_sort.PNG</figcaption>
</figure>
</div>
<p><code>Joining a large table to a small table</code></p>
<p>Once again we can work with our previous result :</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>df_join <span class="op">=</span> spark.read.parquet(<span class="st">'data/report/revenue/total'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>df_join.printSchema()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>root
 |-- hour: timestamp (nullable = true)
 |-- zone: integer (nullable = true)
 |-- green_amount: double (nullable = true)
 |-- green_number_records: long (nullable = true)
 |-- yellow_amount: double (nullable = true)
 |-- yellow_number_records: long (nullable = true)
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>df_join.show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------------+----+------------------+--------------------+------------------+---------------------+
|               hour|zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|
+-------------------+----+------------------+--------------------+------------------+---------------------+
|2020-01-01 00:00:00|  13|              null|                null|1214.8000000000002|                   56|
|2020-01-01 00:00:00|  48|              null|                null|10773.360000000004|                  455|
|2020-01-01 00:00:00|  76|143.77999999999997|                   4|             35.51|                    2|
|2020-01-01 00:00:00| 130|            133.35|                   7|              null|                 null|
|2020-01-01 00:00:00| 186|              null|                null| 4011.449999999998|                  188|
+-------------------+----+------------------+--------------------+------------------+---------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>Let’s find out more about the <code>zone</code> column. The information is stored in another table which I have already downloaded :</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>df_zones <span class="op">=</span> spark.read.parquet(<span class="st">'zones/'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>df_zones.printSchema()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>root
 |-- LocationID: string (nullable = true)
 |-- Borough: string (nullable = true)
 |-- Zone: string (nullable = true)
 |-- service_zone: string (nullable = true)
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>df_zones.show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+----------+-------------+--------------------+------------+
|LocationID|      Borough|                Zone|service_zone|
+----------+-------------+--------------------+------------+
|         1|          EWR|      Newark Airport|         EWR|
|         2|       Queens|         Jamaica Bay|   Boro Zone|
|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|
|         4|    Manhattan|       Alphabet City| Yellow Zone|
|         5|Staten Island|       Arden Heights|   Boro Zone|
+----------+-------------+--------------------+------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>Let’s join the <code>df_zones</code> table to our <code>df_join</code> table :</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>df_result <span class="op">=</span> df_join.join(df_zones, df_join.zone <span class="op">==</span> df_zones.LocationID)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>df_result.show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------------+----+------------------+--------------------+------------------+---------------------+----------+---------+--------------------+------------+
|               hour|zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|LocationID|  Borough|                Zone|service_zone|
+-------------------+----+------------------+--------------------+------------------+---------------------+----------+---------+--------------------+------------+
|2020-01-01 00:00:00|  13|              null|                null|1214.8000000000002|                   56|        13|Manhattan|   Battery Park City| Yellow Zone|
|2020-01-01 00:00:00|  48|              null|                null|10773.360000000004|                  455|        48|Manhattan|        Clinton East| Yellow Zone|
|2020-01-01 00:00:00|  76|143.77999999999997|                   4|             35.51|                    2|        76| Brooklyn|       East New York|   Boro Zone|
|2020-01-01 00:00:00| 130|            133.35|                   7|              null|                 null|       130|   Queens|             Jamaica|   Boro Zone|
|2020-01-01 00:00:00| 186|              null|                null| 4011.449999999998|                  188|       186|Manhattan|Penn Station/Madi...| Yellow Zone|
+-------------------+----+------------------+--------------------+------------------+---------------------+----------+---------+--------------------+------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>Let’s drop the <code>LocationID</code>, and <code>zone</code> columns as these are redundant :</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>df_result.drop(<span class="st">'LocationID'</span>, <span class="st">'zone'</span>).show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------------+------------------+--------------------+------------------+---------------------+---------+------------+
|               hour|      green_amount|green_number_records|     yellow_amount|yellow_number_records|  Borough|service_zone|
+-------------------+------------------+--------------------+------------------+---------------------+---------+------------+
|2020-01-01 00:00:00|              null|                null|1214.8000000000002|                   56|Manhattan| Yellow Zone|
|2020-01-01 00:00:00|              null|                null|10773.360000000004|                  455|Manhattan| Yellow Zone|
|2020-01-01 00:00:00|143.77999999999997|                   4|             35.51|                    2| Brooklyn|   Boro Zone|
|2020-01-01 00:00:00|            133.35|                   7|              null|                 null|   Queens|   Boro Zone|
|2020-01-01 00:00:00|              null|                null| 4011.449999999998|                  188|Manhattan| Yellow Zone|
+-------------------+------------------+--------------------+------------------+---------------------+---------+------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>and write our results to parquet :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>df_result.drop(<span class="st">'LocationID'</span>, <span class="st">'zone'</span>).write.parquet(<span class="st">'tmp/revenue-zones'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="what-exactly-is-spark-doing-2" class="level4">
<h4 class="anchored" data-anchor-id="what-exactly-is-spark-doing-2">What exactly is Spark doing ?</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/c377ff6b-ac69-4561-83bc-d7a628630cf8-1-013b9b96-f6ea-49bb-807d-017cb150cd55.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">zones.PNG</figcaption>
</figure>
</div>
<ul>
<li>each executor processes a partition of the Revenue DataFrame</li>
<li>the <code>zones</code> DataFrame is a small table, so each executor gets a copy of the entire DataFrame and merges it with their partition of the Revenue DataFrame within memory</li>
<li>Spark can <a href="https://en.wikipedia.org/wiki/Broadcasting_(networking)">broadcast</a> a small DataFrame by sending all the data in that small DataFrame to all nodes in the cluster</li>
<li>After the small DataFrame is broadcasted, Spark can perform a join without shuffling any of the data in the large DataFrame</li>
<li>Spark broadcast joins are perfect for joining a large DataFrame with a small DataFrame</li>
</ul>
<p>This is <strong><em>extremely</em></strong> fast.</p>
</section>
</section>
<section id="connecting-to-google-cloud-storage" class="level3">
<h3 class="anchored" data-anchor-id="connecting-to-google-cloud-storage">5.6.1 Connecting to Google Cloud Storage</h3>
<p>We can move the parquet files we created using Spark to Google Cloud Storage (GCS) by running the follwowing from the command line :</p>
<pre><code>gsutil -m cp -r pq/ gs://&lt;google_cloud_storage_bucket_name&gt;/&lt;bucket_folder_name&gt;</code></pre>
<p>In my case :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/b6c6fa69-e2cf-48f7-98f8-63b02e0c5382-1-129645ce-8f32-48f7-8770-45ca8d6eed80.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">upload_to_GCS.PNG</figcaption>
</figure>
</div>
<p>And we can see that my bucket now includes a <code>pq</code> folder and has been loaded :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/b6c6fa69-e2cf-48f7-98f8-63b02e0c5382-2-f801f305-d61e-449f-83c0-30506e627535.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">GCS.PNG</figcaption>
</figure>
</div>
<p>The Google <a href="https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage#benefits_of_the_connector">Cloud Storage connector docs</a> provide detailed guidance, but essentially in order to enable PySpark to speak to Google Cloud we need to configure a <code>.jar</code> file which can be downloaded to any location (e.g.&nbsp;the <code>lib</code> folder) from the command line :</p>
<p>gsutil cp gs://hadoop-lib/gcs/gcs-connector-hadoop3-2.2.5.jar gcs-connector-hadoop3-2.2.5.jar</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/3f59ef1b-8368-4724-9654-e59f314f2f9d-1-090f6d15-099e-4314-abad-f8b605035c65.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">hadoop_connector.PNG</figcaption>
</figure>
</div>
<p>We now need to re-configure our normal entry point into Spark :</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark</span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.conf <span class="im">import</span> SparkConf</span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.context <span class="im">import</span> SparkContext</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We first need to specify the location of our Google Credential json file. Adjust your own details accordingly :</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>credentials_location <span class="op">=</span> <span class="st">'/home/stephen137/.google/taxi-rides-ny-137-abb685b49ccb.json'</span></span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>conf <span class="op">=</span> SparkConf() <span class="op">\</span></span>
<span id="cb146-4"><a href="#cb146-4" aria-hidden="true" tabindex="-1"></a>    .setMaster(<span class="st">'local[*]'</span>) <span class="op">\</span></span>
<span id="cb146-5"><a href="#cb146-5" aria-hidden="true" tabindex="-1"></a>    .setAppName(<span class="st">'test'</span>) <span class="op">\</span></span>
<span id="cb146-6"><a href="#cb146-6" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">set</span>(<span class="st">"spark.jars"</span>, <span class="st">"./lib/gcs-connector-hadoop3-2.2.5.jar"</span>) <span class="op">\</span></span>
<span id="cb146-7"><a href="#cb146-7" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">set</span>(<span class="st">"spark.hadoop.google.cloud.auth.service.account.enable"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb146-8"><a href="#cb146-8" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">set</span>(<span class="st">"spark.hadoop.google.cloud.auth.service.account.json.keyfile"</span>, credentials_location)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The next thing we need to do is create a Spark context :</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>sc <span class="op">=</span> SparkContext(conf<span class="op">=</span>conf)</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>hadoop_conf <span class="op">=</span> sc._jsc.hadoopConfiguration()</span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-5"><a href="#cb147-5" aria-hidden="true" tabindex="-1"></a>hadoop_conf.<span class="bu">set</span>(<span class="st">"fs.AbstractFileSystem.gs.impl"</span>,  <span class="st">"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS"</span>)</span>
<span id="cb147-6"><a href="#cb147-6" aria-hidden="true" tabindex="-1"></a>hadoop_conf.<span class="bu">set</span>(<span class="st">"fs.gs.impl"</span>, <span class="st">"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem"</span>)</span>
<span id="cb147-7"><a href="#cb147-7" aria-hidden="true" tabindex="-1"></a>hadoop_conf.<span class="bu">set</span>(<span class="st">"fs.gs.auth.service.account.json.keyfile"</span>, credentials_location)</span>
<span id="cb147-8"><a href="#cb147-8" aria-hidden="true" tabindex="-1"></a>hadoop_conf.<span class="bu">set</span>(<span class="st">"fs.gs.auth.service.account.enable"</span>, <span class="st">"true"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>23/03/31 14:55:39 WARN Utils: Your hostname, DESKTOP-1UDJOCI resolves to a loopback address: 127.0.1.1; using 172.24.13.131 instead (on interface eth0)
23/03/31 14:55:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/03/31 14:55:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</code></pre>
</div>
</div>
<p>Once we have run this, we can now build our <code>SparkSession</code> using the parameters we instantiated in the previous step :</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder <span class="op">\</span></span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>    .config(conf<span class="op">=</span>sc.getConf()) <span class="op">\</span></span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>spark</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">

            <div>
                <p><b>SparkSession - in-memory</b></p>
                
        <div>
            <p><b>SparkContext</b></p>

            <p><a href="http://172.24.13.131:4040">Spark UI</a></p>

            <dl>
              <dt>Version</dt>
                <dd><code>v3.3.2</code></dd>
              <dt>Master</dt>
                <dd><code>local[*]</code></dd>
              <dt>AppName</dt>
                <dd><code>test</code></dd>
            </dl>
        </div>
        
            </div>
        
</div>
</div>
<p>We are now able to read our files straight from Google Cloud Storage! Let’s do something simple to test our connection is working :</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> spark.read.parquet(<span class="st">'gs://dtc_data_lake_taxi-rides-ny-137/pq/green/*/*'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>                                                                                </code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>df_green.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[Stage 1:&gt;                                                          (0 + 1) / 1]                                                                                </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+
|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|
+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+
|       2| 2020-01-12 18:15:04|  2020-01-12 18:19:52|                 N|         1|          41|          41|              1|         0.78|        5.5|  0.0|    0.5|      1.58|         0.0|     null|                  0.3|        7.88|           1|        1|                 0.0|
|       2| 2020-01-31 20:24:10|  2020-01-31 20:31:51|                 N|         1|         173|          70|              1|         0.98|        7.0|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|         8.3|           2|        1|                 0.0|
|       2| 2020-01-07 08:16:53|  2020-01-07 08:41:39|                 N|         1|          74|         236|              1|          2.7|       16.0|  0.0|    0.5|      3.91|         0.0|     null|                  0.3|       23.46|           1|        1|                2.75|
|       1| 2020-01-15 14:47:15|  2020-01-15 14:54:34|                 N|         1|          25|          66|              1|          0.8|        6.5|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|         7.3|           2|        1|                 0.0|
|    null| 2020-01-31 10:08:00|  2020-01-31 10:20:00|              null|      null|         259|          51|           null|         2.33|      22.49| 2.75|    0.0|       0.0|         0.0|     null|                  0.3|       25.54|        null|     null|                null|
|       2| 2020-01-18 17:46:45|  2020-01-18 18:04:08|                 N|         1|         177|         188|              1|         2.62|       12.5|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        13.3|           1|        1|                 0.0|
|       2| 2020-01-17 20:08:44|  2020-01-17 20:18:47|                 N|         1|          65|          97|              1|         1.13|        8.0|  0.5|    0.5|      1.86|         0.0|     null|                  0.3|       11.16|           1|        1|                 0.0|
|    null| 2020-01-13 10:47:00|  2020-01-13 10:54:00|              null|      null|         165|         123|           null|         1.36|      17.51| 2.75|    0.0|       0.0|         0.0|     null|                  0.3|       20.56|        null|     null|                null|
|    null| 2020-01-07 15:36:00|  2020-01-07 16:11:00|              null|      null|         170|         220|           null|        11.15|       46.0| 2.75|    0.0|       0.0|         0.0|     null|                  0.3|       49.05|        null|     null|                null|
|    null| 2020-01-10 11:47:00|  2020-01-10 12:03:00|              null|      null|          74|          41|           null|         1.78|       8.76|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        9.56|        null|     null|                null|
|       1| 2020-01-08 20:17:48|  2020-01-08 20:23:24|                 Y|         1|          75|          41|              1|          1.0|        6.0|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|         7.3|           2|        1|                 0.0|
|       2| 2020-01-28 10:57:21|  2020-01-28 11:15:13|                 N|         1|          74|         151|              1|         2.75|       13.5|  0.0|    0.5|      2.86|         0.0|     null|                  0.3|       17.16|           1|        1|                 0.0|
|       1| 2020-01-16 18:02:21|  2020-01-16 18:11:21|                 N|         1|          41|          74|              1|          1.1|        7.5|  1.0|    0.5|       2.3|         0.0|     null|                  0.3|        11.6|           1|        1|                 0.0|
|       2| 2020-01-07 14:03:38|  2020-01-07 14:17:02|                 N|         1|         116|          74|              1|         3.81|       13.5|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        14.3|           2|        1|                 0.0|
|       2| 2020-01-14 09:52:46|  2020-01-14 10:06:41|                 N|         1|         152|         244|              1|         1.85|       11.0|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        11.8|           1|        1|                 0.0|
|    null| 2020-01-23 05:40:00|  2020-01-23 06:13:00|              null|      null|          71|          88|           null|         9.14|      30.99| 2.75|    0.0|       0.0|         0.0|     null|                  0.3|       34.04|        null|     null|                null|
|       2| 2020-01-23 10:17:52|  2020-01-23 10:24:02|                 N|         1|          43|         236|              1|         1.04|        6.0|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        9.55|           2|        1|                2.75|
|       2| 2020-01-09 21:09:46|  2020-01-09 21:14:35|                 N|         1|          65|          49|              1|         1.14|        5.5|  0.5|    0.5|       1.2|         0.0|     null|                  0.3|         8.0|           1|        1|                 0.0|
|    null| 2020-01-08 20:53:00|  2020-01-08 21:00:00|              null|      null|         254|         254|           null|         1.15|        8.0|  0.0|    0.0|       0.0|         0.0|     null|                  0.3|         8.3|        null|     null|                null|
|       2| 2020-01-02 09:04:51|  2020-01-02 09:11:18|                 N|         1|         116|         244|              1|         0.92|        6.0|  0.0|    0.0|       0.0|         0.0|     null|                  0.0|         6.0|           2|        2|                 0.0|
+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+
only showing top 20 rows
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>df_green.count()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>                                                                                </code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>2304517</code></pre>
</div>
</div>
<p>Excellent. Spark and GCS are talking to each other :)</p>
</section>
<section id="creating-a-local-clark-cluster" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-local-clark-cluster">5.6.2 Creating a Local Clark Cluster</h3>
<p>If we consult the <a href="https://spark.apache.org/docs/latest/spark-standalone.html#starting-a-cluster-manually">official documentation</a> we can see that it is very simple to start a cluster manually. From the command line check where Spark has been downloaded using :</p>
<pre><code>echo $SPARK_HOME</code></pre>
<p>and then navigate to that directory and execute the following :</p>
<pre><code>./sbin/start-master.sh</code></pre>
<p>Note that when we create a local session it runs at <code>localhost:8080</code>.</p>
<p><code>Killing a localhost session</code></p>
<p>Note, on Linux or Ubuntu, to find out the PID of process bound on a particular port you can use :</p>
<pre><code>fuser &lt;port_number&gt;/tcp</code></pre>
<p>and then :</p>
<pre><code>fuser -k &lt;port_number&gt;/tcp</code></pre>
<p>to kill that session.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/a9bd4a92-88a9-48fa-be71-79036eb9dc37-1-8de63d6e-0efd-4aee-ae0b-11eb24fbd566.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">local_spark.PNG</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/0fcbd34a-7ba6-42ce-8884-332089381ff7-1-8d0cf4b4-afb9-45d0-a74a-ee163d1f2aba.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_master.PNG</figcaption>
</figure>
</div>
<p>And our Spark Session configuration is as follows :</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder <span class="op">\</span></span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>    .master(<span class="st">""</span>) <span class="op">\</span></span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a>    .appName(<span class="st">'test'</span>) <span class="op">\</span></span>
<span id="cb165-4"><a href="#cb165-4" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>spark</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">

            <div>
                <p><b>SparkSession - in-memory</b></p>
                
        <div>
            <p><b>SparkContext</b></p>

            <p><a href="http://172.24.13.131:4041">Spark UI</a></p>

            <dl>
              <dt>Version</dt>
                <dd><code>v3.3.2</code></dd>
              <dt>Master</dt>
                <dd><code>spark://DESKTOP-1UDJOCI.localdomain:7077</code></dd>
              <dt>AppName</dt>
                <dd><code>test</code></dd>
            </dl>
        </div>
        
            </div>
        
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> spark.read.parquet(<span class="st">'data/pq/green/*/*'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>                                                                                </code></pre>
</div>
</div>
<p>Note that although we have started a cluster we have zero workers, we only have a master.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/c231815d-18d1-437f-a19f-b11bf31161bb-2-9c1bcbda-721f-4f06-9a61-ce05c56b9db0.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_master.PNG</figcaption>
</figure>
</div>
<p>We need an executor. To start a worker run the following from the command line :</p>
<pre><code>./sbin/start-worker.sh spark://DESKTOP-1UDJOCI.localdomain:7077</code></pre>
<p>Now we have a worker and our task has completed:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/c231815d-18d1-437f-a19f-b11bf31161bb-1-63a627f7-26aa-4cd2-bc27-2aed80aa56f1.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">worker.PNG</figcaption>
</figure>
</div>
<section id="turning-the-notebook-into-a-python-script" class="level4">
<h4 class="anchored" data-anchor-id="turning-the-notebook-into-a-python-script">Turning the NoteBook into a Python script</h4>
<p>To convert a Jupyter Notebook to a Python script you simply run the following from the command line:</p>
<pre><code>jupyter nbconvert --to=script &lt;notebook_name&gt;</code></pre>
<p>Then we can run the created <code>06_spark_sql_notebook.py</code> file :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/usr/bin/env python</span></span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a><span class="co"># coding: utf-8</span></span>
<span id="cb171-3"><a href="#cb171-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-4"><a href="#cb171-4" aria-hidden="true" tabindex="-1"></a><span class="co"># In[1]:</span></span>
<span id="cb171-5"><a href="#cb171-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark</span>
<span id="cb171-6"><a href="#cb171-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb171-7"><a href="#cb171-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-8"><a href="#cb171-8" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder</span>
<span id="cb171-9"><a href="#cb171-9" aria-hidden="true" tabindex="-1"></a>    .master(<span class="st">"spark://DESKTOP-1UDJOCI.localdomain:7077"</span>)</span>
<span id="cb171-10"><a href="#cb171-10" aria-hidden="true" tabindex="-1"></a>    .appName(<span class="st">'test'</span>)</span>
<span id="cb171-11"><a href="#cb171-11" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span>
<span id="cb171-12"><a href="#cb171-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-13"><a href="#cb171-13" aria-hidden="true" tabindex="-1"></a><span class="co"># In[2]:</span></span>
<span id="cb171-14"><a href="#cb171-14" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> spark.read.parquet(<span class="st">'data/pq/green/*/*'</span>)</span>
<span id="cb171-15"><a href="#cb171-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-16"><a href="#cb171-16" aria-hidden="true" tabindex="-1"></a><span class="co"># In[3]:</span></span>
<span id="cb171-17"><a href="#cb171-17" aria-hidden="true" tabindex="-1"></a>df_green.count()</span>
<span id="cb171-18"><a href="#cb171-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-19"><a href="#cb171-19" aria-hidden="true" tabindex="-1"></a><span class="co"># In[4]:</span></span>
<span id="cb171-20"><a href="#cb171-20" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> df_green</span>
<span id="cb171-21"><a href="#cb171-21" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>)</span>
<span id="cb171-22"><a href="#cb171-22" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span>
<span id="cb171-23"><a href="#cb171-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-24"><a href="#cb171-24" aria-hidden="true" tabindex="-1"></a><span class="co"># In[5]:</span></span>
<span id="cb171-25"><a href="#cb171-25" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> spark.read.parquet(<span class="st">'data/pq/yellow/*/*'</span>)</span>
<span id="cb171-26"><a href="#cb171-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-27"><a href="#cb171-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-28"><a href="#cb171-28" aria-hidden="true" tabindex="-1"></a><span class="co"># In[6]:</span></span>
<span id="cb171-29"><a href="#cb171-29" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> df_yellow</span>
<span id="cb171-30"><a href="#cb171-30" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>)</span>
<span id="cb171-31"><a href="#cb171-31" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span>
<span id="cb171-32"><a href="#cb171-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-33"><a href="#cb171-33" aria-hidden="true" tabindex="-1"></a><span class="co"># In[7]:</span></span>
<span id="cb171-34"><a href="#cb171-34" aria-hidden="true" tabindex="-1"></a>common_colums <span class="op">=</span> []</span>
<span id="cb171-35"><a href="#cb171-35" aria-hidden="true" tabindex="-1"></a>yellow_columns <span class="op">=</span> <span class="bu">set</span>(df_yellow.columns)</span>
<span id="cb171-36"><a href="#cb171-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-37"><a href="#cb171-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> df_green.columns:</span>
<span id="cb171-38"><a href="#cb171-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> col <span class="kw">in</span> yellow_columns:</span>
<span id="cb171-39"><a href="#cb171-39" aria-hidden="true" tabindex="-1"></a>        common_colums.append(col)</span>
<span id="cb171-40"><a href="#cb171-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-41"><a href="#cb171-41" aria-hidden="true" tabindex="-1"></a><span class="co"># In[13]:</span></span>
<span id="cb171-42"><a href="#cb171-42" aria-hidden="true" tabindex="-1"></a>common_colums <span class="op">=</span> [<span class="st">'VendorID'</span>,</span>
<span id="cb171-43"><a href="#cb171-43" aria-hidden="true" tabindex="-1"></a>     <span class="st">'pickup_datetime'</span>,</span>
<span id="cb171-44"><a href="#cb171-44" aria-hidden="true" tabindex="-1"></a>     <span class="st">'dropoff_datetime'</span>,</span>
<span id="cb171-45"><a href="#cb171-45" aria-hidden="true" tabindex="-1"></a>     <span class="st">'store_and_fwd_flag'</span>,</span>
<span id="cb171-46"><a href="#cb171-46" aria-hidden="true" tabindex="-1"></a>     <span class="st">'RatecodeID'</span>,</span>
<span id="cb171-47"><a href="#cb171-47" aria-hidden="true" tabindex="-1"></a>     <span class="st">'PULocationID'</span>,</span>
<span id="cb171-48"><a href="#cb171-48" aria-hidden="true" tabindex="-1"></a>     <span class="st">'DOLocationID'</span>,</span>
<span id="cb171-49"><a href="#cb171-49" aria-hidden="true" tabindex="-1"></a>     <span class="st">'passenger_count'</span>,</span>
<span id="cb171-50"><a href="#cb171-50" aria-hidden="true" tabindex="-1"></a>     <span class="st">'trip_distance'</span>,</span>
<span id="cb171-51"><a href="#cb171-51" aria-hidden="true" tabindex="-1"></a>     <span class="st">'fare_amount'</span>,</span>
<span id="cb171-52"><a href="#cb171-52" aria-hidden="true" tabindex="-1"></a>     <span class="st">'extra'</span>,</span>
<span id="cb171-53"><a href="#cb171-53" aria-hidden="true" tabindex="-1"></a>     <span class="st">'mta_tax'</span>,</span>
<span id="cb171-54"><a href="#cb171-54" aria-hidden="true" tabindex="-1"></a>     <span class="st">'tip_amount'</span>,</span>
<span id="cb171-55"><a href="#cb171-55" aria-hidden="true" tabindex="-1"></a>     <span class="st">'tolls_amount'</span>,</span>
<span id="cb171-56"><a href="#cb171-56" aria-hidden="true" tabindex="-1"></a>     <span class="st">'improvement_surcharge'</span>,</span>
<span id="cb171-57"><a href="#cb171-57" aria-hidden="true" tabindex="-1"></a>     <span class="st">'total_amount'</span>,</span>
<span id="cb171-58"><a href="#cb171-58" aria-hidden="true" tabindex="-1"></a>     <span class="st">'payment_type'</span>,</span>
<span id="cb171-59"><a href="#cb171-59" aria-hidden="true" tabindex="-1"></a>     <span class="st">'congestion_surcharge'</span></span>
<span id="cb171-60"><a href="#cb171-60" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb171-61"><a href="#cb171-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-62"><a href="#cb171-62" aria-hidden="true" tabindex="-1"></a><span class="co"># In[8]:</span></span>
<span id="cb171-63"><a href="#cb171-63" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> functions <span class="im">as</span> F</span>
<span id="cb171-64"><a href="#cb171-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-65"><a href="#cb171-65" aria-hidden="true" tabindex="-1"></a><span class="co"># In[9]:</span></span>
<span id="cb171-66"><a href="#cb171-66" aria-hidden="true" tabindex="-1"></a>df_green_sel <span class="op">=</span> df_green</span>
<span id="cb171-67"><a href="#cb171-67" aria-hidden="true" tabindex="-1"></a>    .select(common_colums)</span>
<span id="cb171-68"><a href="#cb171-68" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'green'</span>))</span>
<span id="cb171-69"><a href="#cb171-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-70"><a href="#cb171-70" aria-hidden="true" tabindex="-1"></a><span class="co"># In[10]:</span></span>
<span id="cb171-71"><a href="#cb171-71" aria-hidden="true" tabindex="-1"></a>df_yellow_sel <span class="op">=</span> df_yellow</span>
<span id="cb171-72"><a href="#cb171-72" aria-hidden="true" tabindex="-1"></a>    .select(common_colums)</span>
<span id="cb171-73"><a href="#cb171-73" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'yellow'</span>))</span>
<span id="cb171-74"><a href="#cb171-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-75"><a href="#cb171-75" aria-hidden="true" tabindex="-1"></a><span class="co"># In[11]:</span></span>
<span id="cb171-76"><a href="#cb171-76" aria-hidden="true" tabindex="-1"></a>df_trips_data <span class="op">=</span> df_green_sel.unionAll(df_yellow_sel)</span>
<span id="cb171-77"><a href="#cb171-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-78"><a href="#cb171-78" aria-hidden="true" tabindex="-1"></a><span class="co"># In[12]:</span></span>
<span id="cb171-79"><a href="#cb171-79" aria-hidden="true" tabindex="-1"></a>df_trips_data.groupBy(<span class="st">'service_type'</span>).count().show()</span>
<span id="cb171-80"><a href="#cb171-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-81"><a href="#cb171-81" aria-hidden="true" tabindex="-1"></a><span class="co"># In[13]:</span></span>
<span id="cb171-82"><a href="#cb171-82" aria-hidden="true" tabindex="-1"></a>df_trips_data.columns</span>
<span id="cb171-83"><a href="#cb171-83" aria-hidden="true" tabindex="-1"></a>ls</span>
<span id="cb171-84"><a href="#cb171-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-85"><a href="#cb171-85" aria-hidden="true" tabindex="-1"></a><span class="co"># In[14]:</span></span>
<span id="cb171-86"><a href="#cb171-86" aria-hidden="true" tabindex="-1"></a><span class="co"># df_trips_data.registerTempTable('trips_data') # Deprecated.</span></span>
<span id="cb171-87"><a href="#cb171-87" aria-hidden="true" tabindex="-1"></a>df_trips_data.createOrReplaceTempView(<span class="st">"trips_data"</span>)</span>
<span id="cb171-88"><a href="#cb171-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-89"><a href="#cb171-89" aria-hidden="true" tabindex="-1"></a><span class="co"># In[15]:</span></span>
<span id="cb171-90"><a href="#cb171-90" aria-hidden="true" tabindex="-1"></a>df_result <span class="op">=</span> spark.sql(<span class="st">"""</span></span>
<span id="cb171-91"><a href="#cb171-91" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT</span></span>
<span id="cb171-92"><a href="#cb171-92" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Reveneue grouping</span></span>
<span id="cb171-93"><a href="#cb171-93" aria-hidden="true" tabindex="-1"></a><span class="st">    PULocationID AS revenue_zone,</span></span>
<span id="cb171-94"><a href="#cb171-94" aria-hidden="true" tabindex="-1"></a><span class="st">    date_trunc('month', pickup_datetime) AS revenue_month,</span></span>
<span id="cb171-95"><a href="#cb171-95" aria-hidden="true" tabindex="-1"></a><span class="st">    service_type,</span></span>
<span id="cb171-96"><a href="#cb171-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-97"><a href="#cb171-97" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Revenue calculation</span></span>
<span id="cb171-98"><a href="#cb171-98" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(fare_amount) AS revenue_monthly_fare,</span></span>
<span id="cb171-99"><a href="#cb171-99" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(extra) AS revenue_monthly_extra,</span></span>
<span id="cb171-100"><a href="#cb171-100" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(mta_tax) AS revenue_monthly_mta_tax,</span></span>
<span id="cb171-101"><a href="#cb171-101" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tip_amount) AS revenue_monthly_tip_amount,</span></span>
<span id="cb171-102"><a href="#cb171-102" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tolls_amount) AS revenue_monthly_tolls_amount,</span></span>
<span id="cb171-103"><a href="#cb171-103" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,</span></span>
<span id="cb171-104"><a href="#cb171-104" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(total_amount) AS revenue_monthly_total_amount,</span></span>
<span id="cb171-105"><a href="#cb171-105" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,</span></span>
<span id="cb171-106"><a href="#cb171-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-107"><a href="#cb171-107" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Additional calculations</span></span>
<span id="cb171-108"><a href="#cb171-108" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(passenger_count) AS avg_montly_passenger_count,</span></span>
<span id="cb171-109"><a href="#cb171-109" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(trip_distance) AS avg_montly_trip_distance</span></span>
<span id="cb171-110"><a href="#cb171-110" aria-hidden="true" tabindex="-1"></a><span class="st">FROM</span></span>
<span id="cb171-111"><a href="#cb171-111" aria-hidden="true" tabindex="-1"></a><span class="st">    trips_data</span></span>
<span id="cb171-112"><a href="#cb171-112" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY</span></span>
<span id="cb171-113"><a href="#cb171-113" aria-hidden="true" tabindex="-1"></a><span class="st">    1, 2, 3</span></span>
<span id="cb171-114"><a href="#cb171-114" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb171-115"><a href="#cb171-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-116"><a href="#cb171-116" aria-hidden="true" tabindex="-1"></a><span class="co"># In[19]:</span></span>
<span id="cb171-117"><a href="#cb171-117" aria-hidden="true" tabindex="-1"></a>df_result.coalesce(<span class="dv">1</span>).write.parquet(<span class="st">'data/report/revenue/'</span>, mode<span class="op">=</span><span class="st">'overwrite'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>python <span class="dv">0</span><span class="er">6_spark_sql_notebook</span>.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>23/04/03 11:02:47 WARN Utils: Your hostname, DESKTOP-1UDJOCI resolves to a loopback address: 127.0.1.1; using 172.21.104.92 instead (on interface eth0)
23/04/03 11:02:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
23/04/03 11:02:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
                                                                                </code></pre>
</div>
</div>
<p>Now, if we go to the ~/Blog/posts/DE_Zoomcamp_Week_5/data/reportdirectory, we see that the revenue directory has just been created :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/d622ce8a-fc8e-4023-b337-f849d748442b-1-6802b70b-16b1-4c49-980e-67a21767b20d.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">revenue_report_2.PNG</figcaption>
</figure>
</div>
<p>Let’s paramaterize our script using <code>argparse</code> like we did in week 1, to allow us to configure parameters from the command line :</p>
<p><code>06_spark_sql.py</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/usr/bin/env python</span></span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a><span class="co"># coding: utf-8</span></span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-4"><a href="#cb174-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> argparse</span>
<span id="cb174-5"><a href="#cb174-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-6"><a href="#cb174-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark</span>
<span id="cb174-7"><a href="#cb174-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb174-8"><a href="#cb174-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> functions <span class="im">as</span> F</span>
<span id="cb174-9"><a href="#cb174-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-10"><a href="#cb174-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-11"><a href="#cb174-11" aria-hidden="true" tabindex="-1"></a>parser <span class="op">=</span> argparse.ArgumentParser()</span>
<span id="cb174-12"><a href="#cb174-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-13"><a href="#cb174-13" aria-hidden="true" tabindex="-1"></a>parser.add_argument(<span class="st">'--input_green'</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb174-14"><a href="#cb174-14" aria-hidden="true" tabindex="-1"></a>parser.add_argument(<span class="st">'--input_yellow'</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb174-15"><a href="#cb174-15" aria-hidden="true" tabindex="-1"></a>parser.add_argument(<span class="st">'--output'</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb174-16"><a href="#cb174-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-17"><a href="#cb174-17" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> parser.parse_args()</span>
<span id="cb174-18"><a href="#cb174-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-19"><a href="#cb174-19" aria-hidden="true" tabindex="-1"></a>input_green <span class="op">=</span> args.input_green</span>
<span id="cb174-20"><a href="#cb174-20" aria-hidden="true" tabindex="-1"></a>input_yellow <span class="op">=</span> args.input_yellow</span>
<span id="cb174-21"><a href="#cb174-21" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> args.output</span>
<span id="cb174-22"><a href="#cb174-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-23"><a href="#cb174-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-24"><a href="#cb174-24" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder <span class="op">\</span></span>
<span id="cb174-25"><a href="#cb174-25" aria-hidden="true" tabindex="-1"></a>    .appName(<span class="st">'test'</span>) <span class="op">\</span></span>
<span id="cb174-26"><a href="#cb174-26" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span>
<span id="cb174-27"><a href="#cb174-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-28"><a href="#cb174-28" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> spark.read.parquet(input_green)</span>
<span id="cb174-29"><a href="#cb174-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-30"><a href="#cb174-30" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> df_green <span class="op">\</span></span>
<span id="cb174-31"><a href="#cb174-31" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>) <span class="op">\</span></span>
<span id="cb174-32"><a href="#cb174-32" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span>
<span id="cb174-33"><a href="#cb174-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-34"><a href="#cb174-34" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> spark.read.parquet(input_yellow)</span>
<span id="cb174-35"><a href="#cb174-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-36"><a href="#cb174-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-37"><a href="#cb174-37" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> df_yellow <span class="op">\</span></span>
<span id="cb174-38"><a href="#cb174-38" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>) <span class="op">\</span></span>
<span id="cb174-39"><a href="#cb174-39" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span>
<span id="cb174-40"><a href="#cb174-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-41"><a href="#cb174-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-42"><a href="#cb174-42" aria-hidden="true" tabindex="-1"></a>common_colums <span class="op">=</span> [</span>
<span id="cb174-43"><a href="#cb174-43" aria-hidden="true" tabindex="-1"></a>    <span class="st">'VendorID'</span>,</span>
<span id="cb174-44"><a href="#cb174-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pickup_datetime'</span>,</span>
<span id="cb174-45"><a href="#cb174-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dropoff_datetime'</span>,</span>
<span id="cb174-46"><a href="#cb174-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">'store_and_fwd_flag'</span>,</span>
<span id="cb174-47"><a href="#cb174-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RatecodeID'</span>,</span>
<span id="cb174-48"><a href="#cb174-48" aria-hidden="true" tabindex="-1"></a>    <span class="st">'PULocationID'</span>,</span>
<span id="cb174-49"><a href="#cb174-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">'DOLocationID'</span>,</span>
<span id="cb174-50"><a href="#cb174-50" aria-hidden="true" tabindex="-1"></a>    <span class="st">'passenger_count'</span>,</span>
<span id="cb174-51"><a href="#cb174-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">'trip_distance'</span>,</span>
<span id="cb174-52"><a href="#cb174-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fare_amount'</span>,</span>
<span id="cb174-53"><a href="#cb174-53" aria-hidden="true" tabindex="-1"></a>    <span class="st">'extra'</span>,</span>
<span id="cb174-54"><a href="#cb174-54" aria-hidden="true" tabindex="-1"></a>    <span class="st">'mta_tax'</span>,</span>
<span id="cb174-55"><a href="#cb174-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tip_amount'</span>,</span>
<span id="cb174-56"><a href="#cb174-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tolls_amount'</span>,</span>
<span id="cb174-57"><a href="#cb174-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">'improvement_surcharge'</span>,</span>
<span id="cb174-58"><a href="#cb174-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">'total_amount'</span>,</span>
<span id="cb174-59"><a href="#cb174-59" aria-hidden="true" tabindex="-1"></a>    <span class="st">'payment_type'</span>,</span>
<span id="cb174-60"><a href="#cb174-60" aria-hidden="true" tabindex="-1"></a>    <span class="st">'congestion_surcharge'</span></span>
<span id="cb174-61"><a href="#cb174-61" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb174-62"><a href="#cb174-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-63"><a href="#cb174-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-64"><a href="#cb174-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-65"><a href="#cb174-65" aria-hidden="true" tabindex="-1"></a>df_green_sel <span class="op">=</span> df_green <span class="op">\</span></span>
<span id="cb174-66"><a href="#cb174-66" aria-hidden="true" tabindex="-1"></a>    .select(common_colums) <span class="op">\</span></span>
<span id="cb174-67"><a href="#cb174-67" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'green'</span>))</span>
<span id="cb174-68"><a href="#cb174-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-69"><a href="#cb174-69" aria-hidden="true" tabindex="-1"></a>df_yellow_sel <span class="op">=</span> df_yellow <span class="op">\</span></span>
<span id="cb174-70"><a href="#cb174-70" aria-hidden="true" tabindex="-1"></a>    .select(common_colums) <span class="op">\</span></span>
<span id="cb174-71"><a href="#cb174-71" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'yellow'</span>))</span>
<span id="cb174-72"><a href="#cb174-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-73"><a href="#cb174-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-74"><a href="#cb174-74" aria-hidden="true" tabindex="-1"></a>df_trips_data <span class="op">=</span> df_green_sel.unionAll(df_yellow_sel)</span>
<span id="cb174-75"><a href="#cb174-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-76"><a href="#cb174-76" aria-hidden="true" tabindex="-1"></a>df_trips_data.registerTempTable(<span class="st">'trips_data'</span>)</span>
<span id="cb174-77"><a href="#cb174-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-78"><a href="#cb174-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-79"><a href="#cb174-79" aria-hidden="true" tabindex="-1"></a>df_result <span class="op">=</span> spark.sql(<span class="st">"""</span></span>
<span id="cb174-80"><a href="#cb174-80" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT </span></span>
<span id="cb174-81"><a href="#cb174-81" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Reveneue grouping </span></span>
<span id="cb174-82"><a href="#cb174-82" aria-hidden="true" tabindex="-1"></a><span class="st">    PULocationID AS revenue_zone,</span></span>
<span id="cb174-83"><a href="#cb174-83" aria-hidden="true" tabindex="-1"></a><span class="st">    date_trunc('month', pickup_datetime) AS revenue_month, </span></span>
<span id="cb174-84"><a href="#cb174-84" aria-hidden="true" tabindex="-1"></a><span class="st">    service_type, </span></span>
<span id="cb174-85"><a href="#cb174-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-86"><a href="#cb174-86" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Revenue calculation </span></span>
<span id="cb174-87"><a href="#cb174-87" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(fare_amount) AS revenue_monthly_fare,</span></span>
<span id="cb174-88"><a href="#cb174-88" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(extra) AS revenue_monthly_extra,</span></span>
<span id="cb174-89"><a href="#cb174-89" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(mta_tax) AS revenue_monthly_mta_tax,</span></span>
<span id="cb174-90"><a href="#cb174-90" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tip_amount) AS revenue_monthly_tip_amount,</span></span>
<span id="cb174-91"><a href="#cb174-91" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tolls_amount) AS revenue_monthly_tolls_amount,</span></span>
<span id="cb174-92"><a href="#cb174-92" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,</span></span>
<span id="cb174-93"><a href="#cb174-93" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(total_amount) AS revenue_monthly_total_amount,</span></span>
<span id="cb174-94"><a href="#cb174-94" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,</span></span>
<span id="cb174-95"><a href="#cb174-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-96"><a href="#cb174-96" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Additional calculations</span></span>
<span id="cb174-97"><a href="#cb174-97" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(passenger_count) AS avg_montly_passenger_count,</span></span>
<span id="cb174-98"><a href="#cb174-98" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(trip_distance) AS avg_montly_trip_distance</span></span>
<span id="cb174-99"><a href="#cb174-99" aria-hidden="true" tabindex="-1"></a><span class="st">FROM</span></span>
<span id="cb174-100"><a href="#cb174-100" aria-hidden="true" tabindex="-1"></a><span class="st">    trips_data</span></span>
<span id="cb174-101"><a href="#cb174-101" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY</span></span>
<span id="cb174-102"><a href="#cb174-102" aria-hidden="true" tabindex="-1"></a><span class="st">    1, 2, 3</span></span>
<span id="cb174-103"><a href="#cb174-103" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb174-104"><a href="#cb174-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-105"><a href="#cb174-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-106"><a href="#cb174-106" aria-hidden="true" tabindex="-1"></a>df_result.coalesce(<span class="dv">1</span>) <span class="op">\</span></span>
<span id="cb174-107"><a href="#cb174-107" aria-hidden="true" tabindex="-1"></a>    .write.parquet(output, mode<span class="op">=</span><span class="st">'overwrite'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we can run our script with a set of parameters :</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> python <span class="dv">0</span><span class="er">6_spark_sql</span>.py <span class="op">\</span></span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>input_green<span class="op">=</span>data<span class="op">/</span>pq<span class="op">/</span>green<span class="op">/</span><span class="dv">2020</span><span class="op">/*/</span> <span class="op">\</span></span>
<span id="cb175-3"><a href="#cb175-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>input_yellow<span class="op">=</span>data<span class="op">/</span>pq<span class="op">/</span>yellow<span class="op">/</span><span class="dv">2020</span><span class="op">/*/</span> <span class="op">\</span></span>
<span id="cb175-4"><a href="#cb175-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>output<span class="op">=</span>data<span class="op">/</span>report<span class="op">-</span><span class="dv">2020</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>23/04/03 11:13:44 WARN Utils: Your hostname, DESKTOP-1UDJOCI resolves to a loopback address: 127.0.1.1; using 172.21.104.92 instead (on interface eth0)
23/04/03 11:13:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
23/04/03 11:13:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
/home/stephen137/mambaforge/lib/python3.10/site-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.
  warnings.warn("Deprecated in 2.0, use createOrReplaceTempView instead.", FutureWarning)
                                                                                </code></pre>
</div>
</div>
<p>We see that our report is created successfully :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/d7df6763-10c0-4e25-bc21-8ad6dd3b5090-1-fc4db87f-d1f3-43b3-91c7-15371ad8ae9a.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">report_2020.PNG</figcaption>
</figure>
</div>
<p>Imagine we have multiple clusters. It is not convenient to hardcode the <code>.master("spark://DESKTOP-1UDJOCI.localdomain:7077")</code> so we will remove it from our script :</p>
<p><code>06_spark_sql_notebook.py</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder <span class="op">\</span></span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a>    .appName(<span class="st">'test'</span>) <span class="op">\</span></span>
<span id="cb177-3"><a href="#cb177-3" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will specifiy the master outside of our script from the command line by using</p>
<pre><code>spark-submit </code></pre>
<p>The <code>spark-submit</code> script in Spark’s bin directory is used to launch applications on a cluster. See <a href="https://spark.apache.org/docs/latest/submitting-applications.html">Submitting Applications</a> for further information.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>URL<span class="op">=</span><span class="st">"spark://DESKTOP-1UDJOCI.localdomain:7077"</span></span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>spark<span class="op">-</span>submit <span class="op">\</span></span>
<span id="cb179-4"><a href="#cb179-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>master<span class="op">=</span><span class="st">"$</span><span class="sc">{URL}</span><span class="st">"</span> \</span>
<span id="cb179-5"><a href="#cb179-5" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span><span class="er">6_spark_sql</span>.py <span class="op">\</span></span>
<span id="cb179-6"><a href="#cb179-6" aria-hidden="true" tabindex="-1"></a>        <span class="op">--</span>input_green<span class="op">=</span>data<span class="op">/</span>pq<span class="op">/</span>green<span class="op">/</span><span class="dv">2021</span><span class="op">/*/</span> <span class="op">\</span></span>
<span id="cb179-7"><a href="#cb179-7" aria-hidden="true" tabindex="-1"></a>        <span class="op">--</span>input_yellow<span class="op">=</span>data<span class="op">/</span>pq<span class="op">/</span>yellow<span class="op">/</span><span class="dv">2021</span><span class="op">/*/</span> <span class="op">\</span></span>
<span id="cb179-8"><a href="#cb179-8" aria-hidden="true" tabindex="-1"></a>        <span class="op">--</span>output<span class="op">=</span>data<span class="op">/</span>report<span class="op">-</span><span class="dv">2021</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We see that our report is created successfully :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/68c6dcf8-8bc9-4204-b48c-f89144aaa9ea-1-09813afd-0f4e-40dc-844b-5a097a0d9c9e.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">report_2021.PNG</figcaption>
</figure>
</div>
<p>Before we finish, we have to stop the workers and stop the master. Navigate to the directory where Spark is installed on your and run the following from the command line :</p>
<pre><code>./sbin/stop-slave.sh

./sbin/stop-worker.sh

./sbin/stop-master.sh</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/515c8ed9-073d-4916-ac04-c86840a583eb-1-174127a1-ba47-4c29-a30c-e7b4af05bd10.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">stop.PNG</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/515c8ed9-073d-4916-ac04-c86840a583eb-2-5a9aee0c-dba7-4ec3-ba65-7f9d94e0d90c.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">stop_UI.PNG</figcaption>
</figure>
</div>
<p>We have successfully closed down our session.</p>
</section>
</section>
<section id="setting-up-a-dataproc-cluster" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-a-dataproc-cluster">5.6.3 Setting up a Dataproc Cluster</h3>
<p>Google Cloud Dataproc is a managed service for running Apache Hadoop and Spark jobs. It can be used for big data processing and machine learning.</p>
<p>Dataproc actually uses Compute Engine instances under the hood, but it takes care of the management details for you. It’s a layer on top that makes it easy to spin up and down clusters as you need them.</p>
<p>The main benefits are that:</p>
<ul>
<li>it is a managed service, so you don’t need a system administrator to set it up</li>
<li>it is fast. You can spin up a cluster in about 90 seconds</li>
<li>it is cheaper than building your own cluster because you only pay when jobs are running. You can spin up a Dataproc cluster when you need to run a job and shut it down afterward</li>
<li>it is integrated with other Google Cloud services, including Cloud Storage, BigQuery, and <a href="https://cloud.google.com/bigtable">Cloud Bigtable</a>, so it’s easy to get data into and out of it</li>
</ul>
<p>See <a href="https://cloud.google.com/dataproc/docs/quickstarts">Cloud Dataproc docs</a> for a quickstart tour.</p>
<section id="create-a-cluster" class="level4">
<h4 class="anchored" data-anchor-id="create-a-cluster">Create a cluster</h4>
<p>First, navigate to Dataproc on Google Cloud and enable the API if you haven’t already done so :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/4bd0940c-a86a-4871-9cb1-260e69a7e4a1-3-ab26bec6-b96c-4660-9c52-15784da66aaf.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dataproc_API.PNG</figcaption>
</figure>
</div>
<p>Then create a cluster. We’ll use <code>Compute Engine</code> :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/4bd0940c-a86a-4871-9cb1-260e69a7e4a1-2-96dd2c93-5046-4b5e-adbe-e466dd315c7f.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dataproc_compute_engine.PNG</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/4bd0940c-a86a-4871-9cb1-260e69a7e4a1-4-b06a8efa-fdb0-4eb7-9cb5-d70650002e8c.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dataproc_setup.PNG</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/4bd0940c-a86a-4871-9cb1-260e69a7e4a1-1-556a0d75-bffc-42fd-abc0-366132c489ba.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dataproc_components.PNG</figcaption>
</figure>
</div>
<p>By creating a cluster we also create a virtual machine, so it might take a while :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/16b8c135-355c-4274-8c51-2b3b76c722d3-2-fa6f4c4d-1e6f-45a6-ba74-9b623e521fbc.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">cluster_running.PNG</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/16b8c135-355c-4274-8c51-2b3b76c722d3-1-0db4906e-8411-41b0-b3aa-b8f6d88a0b61.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">cluster_VM.PNG</figcaption>
</figure>
</div>
<p>Now that our cluster is running let’s now try to submit a job there. With Dataproc, we don’t need to use the same instructions as before to establish the connection with Google Cloud Storage (GCS). Dataproc is already configured to access GCS.</p>
<p>First, we need to to upload the following file to our data bucket :</p>
<p><code>06_spark_sql.py file</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/usr/bin/env python</span></span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a><span class="co"># coding: utf-8</span></span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-4"><a href="#cb181-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> argparse</span>
<span id="cb181-5"><a href="#cb181-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-6"><a href="#cb181-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark</span>
<span id="cb181-7"><a href="#cb181-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb181-8"><a href="#cb181-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> functions <span class="im">as</span> F</span>
<span id="cb181-9"><a href="#cb181-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-10"><a href="#cb181-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-11"><a href="#cb181-11" aria-hidden="true" tabindex="-1"></a>parser <span class="op">=</span> argparse.ArgumentParser()</span>
<span id="cb181-12"><a href="#cb181-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-13"><a href="#cb181-13" aria-hidden="true" tabindex="-1"></a>parser.add_argument(<span class="st">'--input_green'</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb181-14"><a href="#cb181-14" aria-hidden="true" tabindex="-1"></a>parser.add_argument(<span class="st">'--input_yellow'</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb181-15"><a href="#cb181-15" aria-hidden="true" tabindex="-1"></a>parser.add_argument(<span class="st">'--output'</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb181-16"><a href="#cb181-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-17"><a href="#cb181-17" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> parser.parse_args()</span>
<span id="cb181-18"><a href="#cb181-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-19"><a href="#cb181-19" aria-hidden="true" tabindex="-1"></a>input_green <span class="op">=</span> args.input_green</span>
<span id="cb181-20"><a href="#cb181-20" aria-hidden="true" tabindex="-1"></a>input_yellow <span class="op">=</span> args.input_yellow</span>
<span id="cb181-21"><a href="#cb181-21" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> args.output</span>
<span id="cb181-22"><a href="#cb181-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-23"><a href="#cb181-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-24"><a href="#cb181-24" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder <span class="op">\</span></span>
<span id="cb181-25"><a href="#cb181-25" aria-hidden="true" tabindex="-1"></a>    .appName(<span class="st">'test'</span>) <span class="op">\</span></span>
<span id="cb181-26"><a href="#cb181-26" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span>
<span id="cb181-27"><a href="#cb181-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-28"><a href="#cb181-28" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> spark.read.parquet(input_green)</span>
<span id="cb181-29"><a href="#cb181-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-30"><a href="#cb181-30" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> df_green <span class="op">\</span></span>
<span id="cb181-31"><a href="#cb181-31" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>) <span class="op">\</span></span>
<span id="cb181-32"><a href="#cb181-32" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span>
<span id="cb181-33"><a href="#cb181-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-34"><a href="#cb181-34" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> spark.read.parquet(input_yellow)</span>
<span id="cb181-35"><a href="#cb181-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-36"><a href="#cb181-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-37"><a href="#cb181-37" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> df_yellow <span class="op">\</span></span>
<span id="cb181-38"><a href="#cb181-38" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>) <span class="op">\</span></span>
<span id="cb181-39"><a href="#cb181-39" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span>
<span id="cb181-40"><a href="#cb181-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-41"><a href="#cb181-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-42"><a href="#cb181-42" aria-hidden="true" tabindex="-1"></a>common_colums <span class="op">=</span> [</span>
<span id="cb181-43"><a href="#cb181-43" aria-hidden="true" tabindex="-1"></a>    <span class="st">'VendorID'</span>,</span>
<span id="cb181-44"><a href="#cb181-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pickup_datetime'</span>,</span>
<span id="cb181-45"><a href="#cb181-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dropoff_datetime'</span>,</span>
<span id="cb181-46"><a href="#cb181-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">'store_and_fwd_flag'</span>,</span>
<span id="cb181-47"><a href="#cb181-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RatecodeID'</span>,</span>
<span id="cb181-48"><a href="#cb181-48" aria-hidden="true" tabindex="-1"></a>    <span class="st">'PULocationID'</span>,</span>
<span id="cb181-49"><a href="#cb181-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">'DOLocationID'</span>,</span>
<span id="cb181-50"><a href="#cb181-50" aria-hidden="true" tabindex="-1"></a>    <span class="st">'passenger_count'</span>,</span>
<span id="cb181-51"><a href="#cb181-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">'trip_distance'</span>,</span>
<span id="cb181-52"><a href="#cb181-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fare_amount'</span>,</span>
<span id="cb181-53"><a href="#cb181-53" aria-hidden="true" tabindex="-1"></a>    <span class="st">'extra'</span>,</span>
<span id="cb181-54"><a href="#cb181-54" aria-hidden="true" tabindex="-1"></a>    <span class="st">'mta_tax'</span>,</span>
<span id="cb181-55"><a href="#cb181-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tip_amount'</span>,</span>
<span id="cb181-56"><a href="#cb181-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tolls_amount'</span>,</span>
<span id="cb181-57"><a href="#cb181-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">'improvement_surcharge'</span>,</span>
<span id="cb181-58"><a href="#cb181-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">'total_amount'</span>,</span>
<span id="cb181-59"><a href="#cb181-59" aria-hidden="true" tabindex="-1"></a>    <span class="st">'payment_type'</span>,</span>
<span id="cb181-60"><a href="#cb181-60" aria-hidden="true" tabindex="-1"></a>    <span class="st">'congestion_surcharge'</span></span>
<span id="cb181-61"><a href="#cb181-61" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb181-62"><a href="#cb181-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-63"><a href="#cb181-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-64"><a href="#cb181-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-65"><a href="#cb181-65" aria-hidden="true" tabindex="-1"></a>df_green_sel <span class="op">=</span> df_green <span class="op">\</span></span>
<span id="cb181-66"><a href="#cb181-66" aria-hidden="true" tabindex="-1"></a>    .select(common_colums) <span class="op">\</span></span>
<span id="cb181-67"><a href="#cb181-67" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'green'</span>))</span>
<span id="cb181-68"><a href="#cb181-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-69"><a href="#cb181-69" aria-hidden="true" tabindex="-1"></a>df_yellow_sel <span class="op">=</span> df_yellow <span class="op">\</span></span>
<span id="cb181-70"><a href="#cb181-70" aria-hidden="true" tabindex="-1"></a>    .select(common_colums) <span class="op">\</span></span>
<span id="cb181-71"><a href="#cb181-71" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'yellow'</span>))</span>
<span id="cb181-72"><a href="#cb181-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-73"><a href="#cb181-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-74"><a href="#cb181-74" aria-hidden="true" tabindex="-1"></a>df_trips_data <span class="op">=</span> df_green_sel.unionAll(df_yellow_sel)</span>
<span id="cb181-75"><a href="#cb181-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-76"><a href="#cb181-76" aria-hidden="true" tabindex="-1"></a>df_trips_data.registerTempTable(<span class="st">'trips_data'</span>)</span>
<span id="cb181-77"><a href="#cb181-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-78"><a href="#cb181-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-79"><a href="#cb181-79" aria-hidden="true" tabindex="-1"></a>df_result <span class="op">=</span> spark.sql(<span class="st">"""</span></span>
<span id="cb181-80"><a href="#cb181-80" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT </span></span>
<span id="cb181-81"><a href="#cb181-81" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Reveneue grouping </span></span>
<span id="cb181-82"><a href="#cb181-82" aria-hidden="true" tabindex="-1"></a><span class="st">    PULocationID AS revenue_zone,</span></span>
<span id="cb181-83"><a href="#cb181-83" aria-hidden="true" tabindex="-1"></a><span class="st">    date_trunc('month', pickup_datetime) AS revenue_month, </span></span>
<span id="cb181-84"><a href="#cb181-84" aria-hidden="true" tabindex="-1"></a><span class="st">    service_type, </span></span>
<span id="cb181-85"><a href="#cb181-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-86"><a href="#cb181-86" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Revenue calculation </span></span>
<span id="cb181-87"><a href="#cb181-87" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(fare_amount) AS revenue_monthly_fare,</span></span>
<span id="cb181-88"><a href="#cb181-88" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(extra) AS revenue_monthly_extra,</span></span>
<span id="cb181-89"><a href="#cb181-89" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(mta_tax) AS revenue_monthly_mta_tax,</span></span>
<span id="cb181-90"><a href="#cb181-90" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tip_amount) AS revenue_monthly_tip_amount,</span></span>
<span id="cb181-91"><a href="#cb181-91" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tolls_amount) AS revenue_monthly_tolls_amount,</span></span>
<span id="cb181-92"><a href="#cb181-92" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,</span></span>
<span id="cb181-93"><a href="#cb181-93" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(total_amount) AS revenue_monthly_total_amount,</span></span>
<span id="cb181-94"><a href="#cb181-94" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,</span></span>
<span id="cb181-95"><a href="#cb181-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-96"><a href="#cb181-96" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Additional calculations</span></span>
<span id="cb181-97"><a href="#cb181-97" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(passenger_count) AS avg_montly_passenger_count,</span></span>
<span id="cb181-98"><a href="#cb181-98" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(trip_distance) AS avg_montly_trip_distance</span></span>
<span id="cb181-99"><a href="#cb181-99" aria-hidden="true" tabindex="-1"></a><span class="st">FROM</span></span>
<span id="cb181-100"><a href="#cb181-100" aria-hidden="true" tabindex="-1"></a><span class="st">    trips_data</span></span>
<span id="cb181-101"><a href="#cb181-101" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY</span></span>
<span id="cb181-102"><a href="#cb181-102" aria-hidden="true" tabindex="-1"></a><span class="st">    1, 2, 3</span></span>
<span id="cb181-103"><a href="#cb181-103" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb181-104"><a href="#cb181-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-105"><a href="#cb181-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-106"><a href="#cb181-106" aria-hidden="true" tabindex="-1"></a>df_result.coalesce(<span class="dv">1</span>) <span class="op">\</span></span>
<span id="cb181-107"><a href="#cb181-107" aria-hidden="true" tabindex="-1"></a>    .write.parquet(output, mode<span class="op">=</span><span class="st">'overwrite'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can do this from the command line using :</p>
<pre><code>gsutil cp 06_spark_sql.py &lt;data_bucket_path&gt;/code/06_spark_sql.py&gt;</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/fda61189-3fad-4bb2-be89-4434b7f39b41-1-e15bdb7e-3881-4b84-92fa-2a5b0ef82761.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">spark_sql_to_gcs.PNG</figcaption>
</figure>
</div>
<p>Now <code>SUBMIT JOB</code> from within our cluster in Google Cloud, passing the following arguments:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a> <span class="op">--</span>input_green<span class="op">=</span>gs:<span class="op">//</span>dtc_data_lake_taxi<span class="op">-</span>rides<span class="op">-</span>ny<span class="op">-</span><span class="dv">137</span><span class="op">/</span>pq<span class="op">/</span>green<span class="op">/</span><span class="dv">2021</span><span class="op">/*/</span> </span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a>        <span class="op">--</span>input_yellow<span class="op">=</span>gs:<span class="op">//</span>dtc_data_lake_taxi<span class="op">-</span>rides<span class="op">-</span>ny<span class="op">-</span><span class="dv">137</span><span class="op">/</span>pq<span class="op">/</span>yellow<span class="op">/</span><span class="dv">2021</span><span class="op">/*/</span> </span>
<span id="cb183-3"><a href="#cb183-3" aria-hidden="true" tabindex="-1"></a>        <span class="op">--</span>output<span class="op">=</span>gs:<span class="op">//</span>dtc_data_lake_taxi<span class="op">-</span>rides<span class="op">-</span>ny<span class="op">-</span><span class="dv">137</span><span class="op">/</span>report<span class="op">-</span><span class="dv">2021</span>   </span>
<span id="cb183-4"><a href="#cb183-4" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Make sure you specify your own unique bucket path when doing this.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/25fe4cfb-4123-48e1-b688-5913daa2c57e-1-0eaffdae-40fb-44ae-8c81-dc9aad91f12e.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dataproc_submit.PNG</figcaption>
</figure>
</div>
<p>So we have successfully submitted our job to a cluster we created on Google Cloud, and it did some compute and saved the results in our bucket :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/25fe4cfb-4123-48e1-b688-5913daa2c57e-2-8a426d33-0a54-425d-a630-553f9d282b4e.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dataproc_bucket.PNG</figcaption>
</figure>
</div>
</section>
<section id="equivalent-rest" class="level4">
<h4 class="anchored" data-anchor-id="equivalent-rest">Equivalent REST</h4>
<p>If we click on <code>EQUIVALENT REST</code> at the bottom left of the Job Configuration we can construct an <code>equivalent API REST request or gcloud tool command</code> to use inyour code or from the command line to create a cluster.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/0be920fa-bf57-4af8-afde-952e1c293e0e-1-b416a2bc-9e3f-441b-8ccb-eeb1070e4e32.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">equivalent_REST.PNG</figcaption>
</figure>
</div>
<p>The Equivalent REST response looks like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb184-2"><a href="#cb184-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"reference"</span>: {</span>
<span id="cb184-3"><a href="#cb184-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"jobId"</span>: <span class="st">"job-baedec74"</span>,</span>
<span id="cb184-4"><a href="#cb184-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"projectId"</span>: <span class="st">"taxi-rides-ny-137"</span></span>
<span id="cb184-5"><a href="#cb184-5" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb184-6"><a href="#cb184-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"placement"</span>: {</span>
<span id="cb184-7"><a href="#cb184-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"clusterName"</span>: <span class="st">"de-zoomcamp-cluster"</span></span>
<span id="cb184-8"><a href="#cb184-8" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb184-9"><a href="#cb184-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">"status"</span>: {</span>
<span id="cb184-10"><a href="#cb184-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"state"</span>: <span class="st">"DONE"</span>,</span>
<span id="cb184-11"><a href="#cb184-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"stateStartTime"</span>: <span class="st">"2023-04-03T11:46:50.903406Z"</span></span>
<span id="cb184-12"><a href="#cb184-12" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb184-13"><a href="#cb184-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">"yarnApplications"</span>: [</span>
<span id="cb184-14"><a href="#cb184-14" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb184-15"><a href="#cb184-15" aria-hidden="true" tabindex="-1"></a>      <span class="st">"name"</span>: <span class="st">"test"</span>,</span>
<span id="cb184-16"><a href="#cb184-16" aria-hidden="true" tabindex="-1"></a>      <span class="st">"state"</span>: <span class="st">"FINISHED"</span>,</span>
<span id="cb184-17"><a href="#cb184-17" aria-hidden="true" tabindex="-1"></a>      <span class="st">"progress"</span>: <span class="dv">1</span>,</span>
<span id="cb184-18"><a href="#cb184-18" aria-hidden="true" tabindex="-1"></a>      <span class="st">"trackingUrl"</span>: <span class="st">"http://de-zoomcamp-cluster-m:8088/proxy/application_1680518000410_0002/"</span></span>
<span id="cb184-19"><a href="#cb184-19" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb184-20"><a href="#cb184-20" aria-hidden="true" tabindex="-1"></a>  ],</span>
<span id="cb184-21"><a href="#cb184-21" aria-hidden="true" tabindex="-1"></a>  <span class="st">"statusHistory"</span>: [</span>
<span id="cb184-22"><a href="#cb184-22" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb184-23"><a href="#cb184-23" aria-hidden="true" tabindex="-1"></a>      <span class="st">"state"</span>: <span class="st">"PENDING"</span>,</span>
<span id="cb184-24"><a href="#cb184-24" aria-hidden="true" tabindex="-1"></a>      <span class="st">"stateStartTime"</span>: <span class="st">"2023-04-03T11:46:05.044918Z"</span></span>
<span id="cb184-25"><a href="#cb184-25" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb184-26"><a href="#cb184-26" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb184-27"><a href="#cb184-27" aria-hidden="true" tabindex="-1"></a>      <span class="st">"state"</span>: <span class="st">"SETUP_DONE"</span>,</span>
<span id="cb184-28"><a href="#cb184-28" aria-hidden="true" tabindex="-1"></a>      <span class="st">"stateStartTime"</span>: <span class="st">"2023-04-03T11:46:05.103569Z"</span></span>
<span id="cb184-29"><a href="#cb184-29" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb184-30"><a href="#cb184-30" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb184-31"><a href="#cb184-31" aria-hidden="true" tabindex="-1"></a>      <span class="st">"state"</span>: <span class="st">"RUNNING"</span>,</span>
<span id="cb184-32"><a href="#cb184-32" aria-hidden="true" tabindex="-1"></a>      <span class="st">"details"</span>: <span class="st">"Agent reported job success"</span>,</span>
<span id="cb184-33"><a href="#cb184-33" aria-hidden="true" tabindex="-1"></a>      <span class="st">"stateStartTime"</span>: <span class="st">"2023-04-03T11:46:05.575809Z"</span></span>
<span id="cb184-34"><a href="#cb184-34" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb184-35"><a href="#cb184-35" aria-hidden="true" tabindex="-1"></a>  ],</span>
<span id="cb184-36"><a href="#cb184-36" aria-hidden="true" tabindex="-1"></a>  <span class="st">"driverControlFilesUri"</span>: <span class="st">"gs://dataproc-staging-europe-central2-684134901955-zy3qc9tq/google-cloud-dataproc-metainfo/9b321dfc-9e87-4daa-8a26-df51150917c0/jobs/job-baedec74/"</span>,</span>
<span id="cb184-37"><a href="#cb184-37" aria-hidden="true" tabindex="-1"></a>  <span class="st">"driverOutputResourceUri"</span>: <span class="st">"gs://dataproc-staging-europe-central2-684134901955-zy3qc9tq/google-cloud-dataproc-metainfo/9b321dfc-9e87-4daa-8a26-df51150917c0/jobs/job-baedec74/driveroutput"</span>,</span>
<span id="cb184-38"><a href="#cb184-38" aria-hidden="true" tabindex="-1"></a>  <span class="st">"jobUuid"</span>: <span class="st">"86629eb7-f8b1-43eb-9371-7d955f572160"</span>,</span>
<span id="cb184-39"><a href="#cb184-39" aria-hidden="true" tabindex="-1"></a>  <span class="st">"done"</span>: true,</span>
<span id="cb184-40"><a href="#cb184-40" aria-hidden="true" tabindex="-1"></a>  <span class="st">"pysparkJob"</span>: {</span>
<span id="cb184-41"><a href="#cb184-41" aria-hidden="true" tabindex="-1"></a>    <span class="st">"mainPythonFileUri"</span>: <span class="st">"gs://dtc_data_lake_taxi-rides-ny-137/code/06_spark_sql.py"</span>,</span>
<span id="cb184-42"><a href="#cb184-42" aria-hidden="true" tabindex="-1"></a>    <span class="st">"args"</span>: [</span>
<span id="cb184-43"><a href="#cb184-43" aria-hidden="true" tabindex="-1"></a>      <span class="st">"--input_green=gs://dtc_data_lake_taxi-rides-ny-137/pq/green/2021/*/"</span>,</span>
<span id="cb184-44"><a href="#cb184-44" aria-hidden="true" tabindex="-1"></a>      <span class="st">"--input_yellow=gs://dtc_data_lake_taxi-rides-ny-137/pq/yellow/2021/*/"</span>,</span>
<span id="cb184-45"><a href="#cb184-45" aria-hidden="true" tabindex="-1"></a>      <span class="st">"--output=gs://dtc_data_lake_taxi-rides-ny-137/report-2021"</span></span>
<span id="cb184-46"><a href="#cb184-46" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb184-47"><a href="#cb184-47" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb184-48"><a href="#cb184-48" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="submit-a-job-with-gcloud-cli" class="level4">
<h4 class="anchored" data-anchor-id="submit-a-job-with-gcloud-cli">Submit a job with gcloud CLI</h4>
<p>See <a href="https://cloud.google.com/dataproc/docs/guides/submit-job">Submit a job</a> for details as to how to submit a job with Google Cloud SDK.</p>
<p>For example, to submit a job to a Dataproc cluster with gcloud CLI, run the following from the command line :</p>
<pre><code>gcloud dataproc jobs submit pyspark \
--cluster=de-zoomcamp-cluster \
--region=europe-central2 \
gs://dtc_data_lake_taxi-rides-ny-137/code/06_spark_sql.py \
-- \
    --input_green=gs://dtc_data_lake_taxi-rides-ny-137/pq/green/2021/*/ \
    --input_yellow=gs://dtc_data_lake_taxi-rides-ny-137/pq/yellow/2021/*/ \
    --output=gs://dtc_data_lake_taxi-rides-ny-137/report-2021</code></pre>
<p>Before submitting this command, you may find that you need to add the role <code>Dataproc Administrator</code> to the permissions created in the previous weeks. I had already set this up possibly :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/d951d164-5cb3-4dd2-ae22-1aa7ff437043-1-00051dbc-d026-4ed8-baa6-ec46c7aca913.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dataproc_gcloud.PNG</figcaption>
</figure>
</div>
</section>
</section>
<section id="connecting-spark-to-bigquery" class="level3">
<h3 class="anchored" data-anchor-id="connecting-spark-to-bigquery">5.6.4 Connecting Spark to BigQuery</h3>
<p>Sometimes we want to write directly to our data warehouse, BigQuery. A template example of how to connect to Spark is included within the <a href="https://cloud.google.com/dataproc/docs/tutorials/bigquery-connector-spark-example#pyspark">Google Docs</a> which we will modify for our specific purposes. The template is included below :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/usr/bin/env python</span></span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a><span class="co">"""BigQuery I/O PySpark example."""</span></span>
<span id="cb186-4"><a href="#cb186-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-5"><a href="#cb186-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb186-6"><a href="#cb186-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-7"><a href="#cb186-7" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession <span class="op">\</span></span>
<span id="cb186-8"><a href="#cb186-8" aria-hidden="true" tabindex="-1"></a>  .builder <span class="op">\</span></span>
<span id="cb186-9"><a href="#cb186-9" aria-hidden="true" tabindex="-1"></a>  .master(<span class="st">'yarn'</span>) <span class="op">\</span></span>
<span id="cb186-10"><a href="#cb186-10" aria-hidden="true" tabindex="-1"></a>  .appName(<span class="st">'spark-bigquery-demo'</span>) <span class="op">\</span></span>
<span id="cb186-11"><a href="#cb186-11" aria-hidden="true" tabindex="-1"></a>  .getOrCreate()</span>
<span id="cb186-12"><a href="#cb186-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-13"><a href="#cb186-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the Cloud Storage bucket for temporary BigQuery export data used</span></span>
<span id="cb186-14"><a href="#cb186-14" aria-hidden="true" tabindex="-1"></a><span class="co"># by the connector.</span></span>
<span id="cb186-15"><a href="#cb186-15" aria-hidden="true" tabindex="-1"></a>bucket <span class="op">=</span> <span class="st">"[bucket]"</span></span>
<span id="cb186-16"><a href="#cb186-16" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">'temporaryGcsBucket'</span>, bucket)</span>
<span id="cb186-17"><a href="#cb186-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-18"><a href="#cb186-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data from BigQuery.</span></span>
<span id="cb186-19"><a href="#cb186-19" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> spark.read.<span class="bu">format</span>(<span class="st">'bigquery'</span>) <span class="op">\</span></span>
<span id="cb186-20"><a href="#cb186-20" aria-hidden="true" tabindex="-1"></a>  .option(<span class="st">'table'</span>, <span class="st">'bigquery-public-data:samples.shakespeare'</span>) <span class="op">\</span></span>
<span id="cb186-21"><a href="#cb186-21" aria-hidden="true" tabindex="-1"></a>  .load()</span>
<span id="cb186-22"><a href="#cb186-22" aria-hidden="true" tabindex="-1"></a>words.createOrReplaceTempView(<span class="st">'words'</span>)</span>
<span id="cb186-23"><a href="#cb186-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-24"><a href="#cb186-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform word count.</span></span>
<span id="cb186-25"><a href="#cb186-25" aria-hidden="true" tabindex="-1"></a>word_count <span class="op">=</span> spark.sql(</span>
<span id="cb186-26"><a href="#cb186-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SELECT word, SUM(word_count) AS word_count FROM words GROUP BY word'</span>)</span>
<span id="cb186-27"><a href="#cb186-27" aria-hidden="true" tabindex="-1"></a>word_count.show()</span>
<span id="cb186-28"><a href="#cb186-28" aria-hidden="true" tabindex="-1"></a>word_count.printSchema()</span>
<span id="cb186-29"><a href="#cb186-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-30"><a href="#cb186-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Saving the data to BigQuery</span></span>
<span id="cb186-31"><a href="#cb186-31" aria-hidden="true" tabindex="-1"></a>word_count.write.<span class="bu">format</span>(<span class="st">'bigquery'</span>) <span class="op">\</span></span>
<span id="cb186-32"><a href="#cb186-32" aria-hidden="true" tabindex="-1"></a>  .option(<span class="st">'table'</span>, <span class="st">'wordcount_dataset.wordcount_output'</span>) <span class="op">\</span></span>
<span id="cb186-33"><a href="#cb186-33" aria-hidden="true" tabindex="-1"></a>  .save()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Navigate to the buckets created by Dataproc :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/ef349c9e-3dcd-4a99-b9b0-e162da3d6f81-1-c072b33b-235b-469a-a2f4-cdf17817ba02.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dataproc_bucket_BQ.PNG</figcaption>
</figure>
</div>
<p>and modify the <code>06_spark_sql_big_query.py</code> file to reference this Dataproc bucket :</p>
<p><code>06_spark_sql_big_query.py</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/usr/bin/env python</span></span>
<span id="cb187-2"><a href="#cb187-2" aria-hidden="true" tabindex="-1"></a><span class="co"># coding: utf-8</span></span>
<span id="cb187-3"><a href="#cb187-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-4"><a href="#cb187-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> argparse</span>
<span id="cb187-5"><a href="#cb187-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-6"><a href="#cb187-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark</span>
<span id="cb187-7"><a href="#cb187-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb187-8"><a href="#cb187-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> functions <span class="im">as</span> F</span>
<span id="cb187-9"><a href="#cb187-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-10"><a href="#cb187-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-11"><a href="#cb187-11" aria-hidden="true" tabindex="-1"></a>parser <span class="op">=</span> argparse.ArgumentParser()</span>
<span id="cb187-12"><a href="#cb187-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-13"><a href="#cb187-13" aria-hidden="true" tabindex="-1"></a>parser.add_argument(<span class="st">'--input_green'</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb187-14"><a href="#cb187-14" aria-hidden="true" tabindex="-1"></a>parser.add_argument(<span class="st">'--input_yellow'</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb187-15"><a href="#cb187-15" aria-hidden="true" tabindex="-1"></a>parser.add_argument(<span class="st">'--output'</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb187-16"><a href="#cb187-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-17"><a href="#cb187-17" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> parser.parse_args()</span>
<span id="cb187-18"><a href="#cb187-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-19"><a href="#cb187-19" aria-hidden="true" tabindex="-1"></a>input_green <span class="op">=</span> args.input_green</span>
<span id="cb187-20"><a href="#cb187-20" aria-hidden="true" tabindex="-1"></a>input_yellow <span class="op">=</span> args.input_yellow</span>
<span id="cb187-21"><a href="#cb187-21" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> args.output</span>
<span id="cb187-22"><a href="#cb187-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-23"><a href="#cb187-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-24"><a href="#cb187-24" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder <span class="op">\</span></span>
<span id="cb187-25"><a href="#cb187-25" aria-hidden="true" tabindex="-1"></a>    .appName(<span class="st">'test'</span>) <span class="op">\</span></span>
<span id="cb187-26"><a href="#cb187-26" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span>
<span id="cb187-27"><a href="#cb187-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-28"><a href="#cb187-28" aria-hidden="true" tabindex="-1"></a><span class="co"># First modification.</span></span>
<span id="cb187-29"><a href="#cb187-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the Cloud Storage bucket for temporary BigQuery export data used</span></span>
<span id="cb187-30"><a href="#cb187-30" aria-hidden="true" tabindex="-1"></a><span class="co"># by the connector.</span></span>
<span id="cb187-31"><a href="#cb187-31" aria-hidden="true" tabindex="-1"></a>bucket <span class="op">=</span> <span class="st">"dataproc-temp-europe-central2-684134901955-awcbvroo"</span></span>
<span id="cb187-32"><a href="#cb187-32" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">'temporaryGcsBucket'</span>, bucket)</span>
<span id="cb187-33"><a href="#cb187-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-34"><a href="#cb187-34" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> spark.read.parquet(input_green)</span>
<span id="cb187-35"><a href="#cb187-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-36"><a href="#cb187-36" aria-hidden="true" tabindex="-1"></a>df_green <span class="op">=</span> df_green <span class="op">\</span></span>
<span id="cb187-37"><a href="#cb187-37" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>) <span class="op">\</span></span>
<span id="cb187-38"><a href="#cb187-38" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'lpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span>
<span id="cb187-39"><a href="#cb187-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-40"><a href="#cb187-40" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> spark.read.parquet(input_yellow)</span>
<span id="cb187-41"><a href="#cb187-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-42"><a href="#cb187-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-43"><a href="#cb187-43" aria-hidden="true" tabindex="-1"></a>df_yellow <span class="op">=</span> df_yellow <span class="op">\</span></span>
<span id="cb187-44"><a href="#cb187-44" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_pickup_datetime'</span>, <span class="st">'pickup_datetime'</span>) <span class="op">\</span></span>
<span id="cb187-45"><a href="#cb187-45" aria-hidden="true" tabindex="-1"></a>    .withColumnRenamed(<span class="st">'tpep_dropoff_datetime'</span>, <span class="st">'dropoff_datetime'</span>)</span>
<span id="cb187-46"><a href="#cb187-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-47"><a href="#cb187-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-48"><a href="#cb187-48" aria-hidden="true" tabindex="-1"></a>common_colums <span class="op">=</span> [</span>
<span id="cb187-49"><a href="#cb187-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">'VendorID'</span>,</span>
<span id="cb187-50"><a href="#cb187-50" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pickup_datetime'</span>,</span>
<span id="cb187-51"><a href="#cb187-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dropoff_datetime'</span>,</span>
<span id="cb187-52"><a href="#cb187-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'store_and_fwd_flag'</span>,</span>
<span id="cb187-53"><a href="#cb187-53" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RatecodeID'</span>,</span>
<span id="cb187-54"><a href="#cb187-54" aria-hidden="true" tabindex="-1"></a>    <span class="st">'PULocationID'</span>,</span>
<span id="cb187-55"><a href="#cb187-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">'DOLocationID'</span>,</span>
<span id="cb187-56"><a href="#cb187-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">'passenger_count'</span>,</span>
<span id="cb187-57"><a href="#cb187-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">'trip_distance'</span>,</span>
<span id="cb187-58"><a href="#cb187-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fare_amount'</span>,</span>
<span id="cb187-59"><a href="#cb187-59" aria-hidden="true" tabindex="-1"></a>    <span class="st">'extra'</span>,</span>
<span id="cb187-60"><a href="#cb187-60" aria-hidden="true" tabindex="-1"></a>    <span class="st">'mta_tax'</span>,</span>
<span id="cb187-61"><a href="#cb187-61" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tip_amount'</span>,</span>
<span id="cb187-62"><a href="#cb187-62" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tolls_amount'</span>,</span>
<span id="cb187-63"><a href="#cb187-63" aria-hidden="true" tabindex="-1"></a>    <span class="st">'improvement_surcharge'</span>,</span>
<span id="cb187-64"><a href="#cb187-64" aria-hidden="true" tabindex="-1"></a>    <span class="st">'total_amount'</span>,</span>
<span id="cb187-65"><a href="#cb187-65" aria-hidden="true" tabindex="-1"></a>    <span class="st">'payment_type'</span>,</span>
<span id="cb187-66"><a href="#cb187-66" aria-hidden="true" tabindex="-1"></a>    <span class="st">'congestion_surcharge'</span></span>
<span id="cb187-67"><a href="#cb187-67" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb187-68"><a href="#cb187-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-69"><a href="#cb187-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-70"><a href="#cb187-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-71"><a href="#cb187-71" aria-hidden="true" tabindex="-1"></a>df_green_sel <span class="op">=</span> df_green <span class="op">\</span></span>
<span id="cb187-72"><a href="#cb187-72" aria-hidden="true" tabindex="-1"></a>    .select(common_colums) <span class="op">\</span></span>
<span id="cb187-73"><a href="#cb187-73" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'green'</span>))</span>
<span id="cb187-74"><a href="#cb187-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-75"><a href="#cb187-75" aria-hidden="true" tabindex="-1"></a>df_yellow_sel <span class="op">=</span> df_yellow <span class="op">\</span></span>
<span id="cb187-76"><a href="#cb187-76" aria-hidden="true" tabindex="-1"></a>    .select(common_colums) <span class="op">\</span></span>
<span id="cb187-77"><a href="#cb187-77" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">'service_type'</span>, F.lit(<span class="st">'yellow'</span>))</span>
<span id="cb187-78"><a href="#cb187-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-79"><a href="#cb187-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-80"><a href="#cb187-80" aria-hidden="true" tabindex="-1"></a>df_trips_data <span class="op">=</span> df_green_sel.unionAll(df_yellow_sel)</span>
<span id="cb187-81"><a href="#cb187-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-82"><a href="#cb187-82" aria-hidden="true" tabindex="-1"></a>df_trips_data.registerTempTable(<span class="st">'trips_data'</span>)</span>
<span id="cb187-83"><a href="#cb187-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-84"><a href="#cb187-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-85"><a href="#cb187-85" aria-hidden="true" tabindex="-1"></a>df_result <span class="op">=</span> spark.sql(<span class="st">"""</span></span>
<span id="cb187-86"><a href="#cb187-86" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT</span></span>
<span id="cb187-87"><a href="#cb187-87" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Revenue grouping</span></span>
<span id="cb187-88"><a href="#cb187-88" aria-hidden="true" tabindex="-1"></a><span class="st">    PULocationID AS revenue_zone,</span></span>
<span id="cb187-89"><a href="#cb187-89" aria-hidden="true" tabindex="-1"></a><span class="st">    date_trunc('month', pickup_datetime) AS revenue_month,</span></span>
<span id="cb187-90"><a href="#cb187-90" aria-hidden="true" tabindex="-1"></a><span class="st">    service_type,</span></span>
<span id="cb187-91"><a href="#cb187-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-92"><a href="#cb187-92" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Revenue calculation</span></span>
<span id="cb187-93"><a href="#cb187-93" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(fare_amount) AS revenue_monthly_fare,</span></span>
<span id="cb187-94"><a href="#cb187-94" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(extra) AS revenue_monthly_extra,</span></span>
<span id="cb187-95"><a href="#cb187-95" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(mta_tax) AS revenue_monthly_mta_tax,</span></span>
<span id="cb187-96"><a href="#cb187-96" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tip_amount) AS revenue_monthly_tip_amount,</span></span>
<span id="cb187-97"><a href="#cb187-97" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(tolls_amount) AS revenue_monthly_tolls_amount,</span></span>
<span id="cb187-98"><a href="#cb187-98" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,</span></span>
<span id="cb187-99"><a href="#cb187-99" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(total_amount) AS revenue_monthly_total_amount,</span></span>
<span id="cb187-100"><a href="#cb187-100" aria-hidden="true" tabindex="-1"></a><span class="st">    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,</span></span>
<span id="cb187-101"><a href="#cb187-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-102"><a href="#cb187-102" aria-hidden="true" tabindex="-1"></a><span class="st">    -- Additional calculations</span></span>
<span id="cb187-103"><a href="#cb187-103" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(passenger_count) AS avg_montly_passenger_count,</span></span>
<span id="cb187-104"><a href="#cb187-104" aria-hidden="true" tabindex="-1"></a><span class="st">    AVG(trip_distance) AS avg_montly_trip_distance</span></span>
<span id="cb187-105"><a href="#cb187-105" aria-hidden="true" tabindex="-1"></a><span class="st">FROM</span></span>
<span id="cb187-106"><a href="#cb187-106" aria-hidden="true" tabindex="-1"></a><span class="st">    trips_data</span></span>
<span id="cb187-107"><a href="#cb187-107" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY</span></span>
<span id="cb187-108"><a href="#cb187-108" aria-hidden="true" tabindex="-1"></a><span class="st">    1, 2, 3</span></span>
<span id="cb187-109"><a href="#cb187-109" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb187-110"><a href="#cb187-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-111"><a href="#cb187-111" aria-hidden="true" tabindex="-1"></a><span class="co"># Second modification.</span></span>
<span id="cb187-112"><a href="#cb187-112" aria-hidden="true" tabindex="-1"></a><span class="co"># Saving the data to BigQuery</span></span>
<span id="cb187-113"><a href="#cb187-113" aria-hidden="true" tabindex="-1"></a>df_result.write.<span class="bu">format</span>(<span class="st">'bigquery'</span>) <span class="op">\</span></span>
<span id="cb187-114"><a href="#cb187-114" aria-hidden="true" tabindex="-1"></a>    .option(<span class="st">'table'</span>, output) <span class="op">\</span></span>
<span id="cb187-115"><a href="#cb187-115" aria-hidden="true" tabindex="-1"></a>    .save()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Upload this script to our data bucket from the command line using :</p>
<pre><code>gsutil cp 06_spark_sql_big_query.py gs://dtc_data_lake_taxi-rides-ny-137/code/06_spark_sql_big_query.py  </code></pre>
<p>he BigQuery schema we already have is trips_data_all.</p>
<p>So, we slightly modify the script created previously to create the report in BigQuery by indicating the schema name for the report:</p>
<p><code>--output=trips_data_all.reports-2020</code></p>
<p>We also need to specify the connector jar :</p>
<p><code>--jars=gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar</code></p>
<p>And run the following from the command line :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>gcloud dataproc jobs submit pyspark <span class="op">\</span></span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>cluster<span class="op">=</span>de<span class="op">-</span>zoomcamp<span class="op">-</span>cluster <span class="op">\</span></span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>region<span class="op">=</span>europe<span class="op">-</span>central2 <span class="op">\</span></span>
<span id="cb189-4"><a href="#cb189-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>jars<span class="op">=</span>gs:<span class="op">//</span>spark<span class="op">-</span>lib<span class="op">/</span>bigquery<span class="op">/</span>spark<span class="op">-</span>bigquery<span class="op">-</span>latest_2<span class="fl">.12</span>.jar <span class="op">\</span></span>
<span id="cb189-5"><a href="#cb189-5" aria-hidden="true" tabindex="-1"></a>    gs:<span class="op">//</span>dtc_data_lake_taxi<span class="op">-</span>rides<span class="op">-</span>ny<span class="op">-</span><span class="dv">137</span><span class="op">/</span>code<span class="op">/</span><span class="dv">0</span><span class="er">6_spark_sql_big_query</span>.py <span class="op">\</span></span>
<span id="cb189-6"><a href="#cb189-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span> <span class="op">\</span></span>
<span id="cb189-7"><a href="#cb189-7" aria-hidden="true" tabindex="-1"></a>        <span class="op">--</span>input_green<span class="op">=</span>gs:<span class="op">//</span>dtc_data_lake_taxi<span class="op">-</span>rides<span class="op">-</span>ny<span class="op">-</span><span class="dv">137</span><span class="op">/</span>pq<span class="op">/</span>green<span class="op">/</span><span class="dv">2020</span><span class="op">/*/</span> <span class="op">\</span></span>
<span id="cb189-8"><a href="#cb189-8" aria-hidden="true" tabindex="-1"></a>        <span class="op">--</span>input_yellow<span class="op">=</span>gs:<span class="op">//</span>dtc_data_lake_taxi<span class="op">-</span>rides<span class="op">-</span>ny<span class="op">-</span><span class="dv">137</span><span class="op">/</span>pq<span class="op">/</span>yellow<span class="op">/</span><span class="dv">2020</span><span class="op">/*/</span> <span class="op">\</span></span>
<span id="cb189-9"><a href="#cb189-9" aria-hidden="true" tabindex="-1"></a>        <span class="op">--</span>output<span class="op">=</span>trips_data_all.reports<span class="op">-</span><span class="dv">2020</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/71f13ad7-1567-494b-8228-4c01de240b0c-1-d8823858-eb2d-48f0-9e56-e208640d682d.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">gcloud_BQ.PNG</figcaption>
</figure>
</div>
<p>That seems to have run successfully. Let’s check BigQuery :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DE_Zoomcamp_Week_5_files/figure-html/d1ef734a-e263-475c-b175-dc44949a4d10-1-fae24962-07f7-46ba-93ba-2b220ad34e98.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">gcloud_cluster_BQ_reports_2020.PNG</figcaption>
</figure>
</div>
<p>Our table has been created and we can see the first 10 rows.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>