<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Stephen Barrie">
<meta name="dcterms.date" content="2023-02-14">

<title>Into the Unknown - Data Engineering Zoomcamp - Week 1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Into the Unknown</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">Stephen Barrie</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"><i class="bi bi-rss" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Stephen137"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com/in/sjbarrie"><i class="bi bi-linkedin" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Data Engineering Zoomcamp - Week 1</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Docker</div>
                <div class="quarto-category">GCP</div>
                <div class="quarto-category">Terraform</div>
                <div class="quarto-category">PostgreSQL</div>
                <div class="quarto-category">DataTalksClub</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Stephen Barrie </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 14, 2023</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#week-1---basics-and-set-up" id="toc-week-1---basics-and-set-up" class="nav-link active" data-scroll-target="#week-1---basics-and-set-up">Week 1 - Basics and set-up</a>
  <ul class="collapse">
  <li><a href="#introduction-to-google-cloud-platform-gcp" id="toc-introduction-to-google-cloud-platform-gcp" class="nav-link" data-scroll-target="#introduction-to-google-cloud-platform-gcp">1.1.1 Introduction to Google Cloud Platform (GCP)</a></li>
  <li><a href="#introduction-to-docker" id="toc-introduction-to-docker" class="nav-link" data-scroll-target="#introduction-to-docker">1.2.1 Introduction to Docker</a></li>
  <li><a href="#wheres-that-confounded-bridge" id="toc-wheres-that-confounded-bridge" class="nav-link" data-scroll-target="#wheres-that-confounded-bridge">Where’s that confounded bridge</a></li>
  <li><a href="#docker-container-ip-address" id="toc-docker-container-ip-address" class="nav-link" data-scroll-target="#docker-container-ip-address">Docker Container IP Address</a></li>
  <li><a href="#how-to-get-a-docker-container-ip-address" id="toc-how-to-get-a-docker-container-ip-address" class="nav-link" data-scroll-target="#how-to-get-a-docker-container-ip-address">How to Get A Docker Container IP Address</a></li>
  <li><a href="#creating-a-data-pipeline-within-docker" id="toc-creating-a-data-pipeline-within-docker" class="nav-link" data-scroll-target="#creating-a-data-pipeline-within-docker">Creating a Data Pipeline within Docker</a></li>
  <li><a href="#fine-tuning-our-docker-container" id="toc-fine-tuning-our-docker-container" class="nav-link" data-scroll-target="#fine-tuning-our-docker-container">Fine tuning our Docker container</a></li>
  </ul></li>
  <li><a href="#running-postgresql-postgres-locally-with-docker" id="toc-running-postgresql-postgres-locally-with-docker" class="nav-link" data-scroll-target="#running-postgresql-postgres-locally-with-docker">Running PostgreSQL (Postgres) locally with Docker</a>
  <ul class="collapse">
  <li><a href="#accessing-postgresql" id="toc-accessing-postgresql" class="nav-link" data-scroll-target="#accessing-postgresql">Accessing PostgreSQL</a></li>
  <li><a href="#downloading-a-file" id="toc-downloading-a-file" class="nav-link" data-scroll-target="#downloading-a-file">Downloading a file</a></li>
  <li><a href="#copying-a-file-to-existing-directory-using" id="toc-copying-a-file-to-existing-directory-using" class="nav-link" data-scroll-target="#copying-a-file-to-existing-directory-using">Copying a file to existing directory using <code>~</code></a></li>
  </ul></li>
  <li><a href="#sql-alchemy" id="toc-sql-alchemy" class="nav-link" data-scroll-target="#sql-alchemy">SQL Alchemy</a>
  <ul class="collapse">
  <li><a href="#pgadmin" id="toc-pgadmin" class="nav-link" data-scroll-target="#pgadmin">pgAdmin</a></li>
  <li><a href="#connecting-pgadmin-and-postgres" id="toc-connecting-pgadmin-and-postgres" class="nav-link" data-scroll-target="#connecting-pgadmin-and-postgres">1.2.3 Connecting pgAdmin and Postgres</a></li>
  <li><a href="#ingesting-data" id="toc-ingesting-data" class="nav-link" data-scroll-target="#ingesting-data">Ingesting data</a></li>
  <li><a href="#dockerizing-our-data-ingestion-file" id="toc-dockerizing-our-data-ingestion-file" class="nav-link" data-scroll-target="#dockerizing-our-data-ingestion-file">1.2.4 Dockerizing our data ingestion file</a></li>
  <li><a href="#docker-compose" id="toc-docker-compose" class="nav-link" data-scroll-target="#docker-compose">1.2.5 Docker Compose</a></li>
  <li><a href="#sql-refresher" id="toc-sql-refresher" class="nav-link" data-scroll-target="#sql-refresher">1.2.6 - SQL Refresher</a></li>
  <li><a href="#google-cloud-platform-gcp" id="toc-google-cloud-platform-gcp" class="nav-link" data-scroll-target="#google-cloud-platform-gcp">Google Cloud Platform (GCP)</a></li>
  <li><a href="#gcp-pre-requisites" id="toc-gcp-pre-requisites" class="nav-link" data-scroll-target="#gcp-pre-requisites">GCP Pre-requisites</a></li>
  <li><a href="#cloud-sdk" id="toc-cloud-sdk" class="nav-link" data-scroll-target="#cloud-sdk">Cloud SDK</a></li>
  <li><a href="#installation-of-gcloud-cli" id="toc-installation-of-gcloud-cli" class="nav-link" data-scroll-target="#installation-of-gcloud-cli">Installation of gcloud CLI</a></li>
  <li><a href="#terraform" id="toc-terraform" class="nav-link" data-scroll-target="#terraform">Terraform</a></li>
  <li><a href="#creating-gcp-inftastructure-with-terraform" id="toc-creating-gcp-inftastructure-with-terraform" class="nav-link" data-scroll-target="#creating-gcp-inftastructure-with-terraform">1.3.2 Creating GCP Inftastructure with Terraform</a></li>
  </ul></li>
  <li><a href="#data-lake-bucket" id="toc-data-lake-bucket" class="nav-link" data-scroll-target="#data-lake-bucket">Data Lake Bucket</a></li>
  <li><a href="#ref-httpsregistry.terraform.ioprovidershashicorpgooglelatestdocsresourcesstorage_bucket" id="toc-ref-httpsregistry.terraform.ioprovidershashicorpgooglelatestdocsresourcesstorage_bucket" class="nav-link" data-scroll-target="#ref-httpsregistry.terraform.ioprovidershashicorpgooglelatestdocsresourcesstorage_bucket">Ref: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/storage_bucket</a></li>
  <li><a href="#dwh" id="toc-dwh" class="nav-link" data-scroll-target="#dwh">DWH</a></li>
  <li><a href="#ref-httpsregistry.terraform.ioprovidershashicorpgooglelatestdocsresourcesbigquery_dataset" id="toc-ref-httpsregistry.terraform.ioprovidershashicorpgooglelatestdocsresourcesbigquery_dataset" class="nav-link" data-scroll-target="#ref-httpsregistry.terraform.ioprovidershashicorpgooglelatestdocsresourcesbigquery_dataset">Ref: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="week-1---basics-and-set-up" class="level2">
<h2 class="anchored" data-anchor-id="week-1---basics-and-set-up">Week 1 - Basics and set-up</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/28b692f9-439f-4c05-9c77-28c17ed6e8c5.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">week_1.JPG</figcaption><p></p>
</figure>
</div>
<section id="introduction-to-google-cloud-platform-gcp" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-google-cloud-platform-gcp">1.1.1 Introduction to Google Cloud Platform (GCP)</h3>
</section>
<section id="introduction-to-docker" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-docker">1.2.1 Introduction to Docker</h3>
<p>What is Docker? Why do we need it?</p>
<ul>
<li>Local experiments</li>
<li>Integration tests (Continuous Integraton (CI) / Continuous Development (CD)) - Github Actions, Jenkins</li>
<li>Reproducibility (isolated CONTAINER) ensures environment on local machine can be directly replicated ANYWHERE</li>
<li>Running pipelines on the cloud (AWS Batch, Kubernetes jobs)</li>
<li>Spark</li>
<li>Serverless (AWS Lambda, [Google] Cloud functions)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/2f2ebe95-f73e-45af-bd35-4160c7084c54.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">docker_network.JPG</figcaption><p></p>
</figure>
</div>
</section>
<section id="wheres-that-confounded-bridge" class="level3">
<h3 class="anchored" data-anchor-id="wheres-that-confounded-bridge">Where’s that confounded bridge</h3>
<p>The bridge network works as a private network internal to the host so containers on it can communicate. External access is granted by exposing ports to containers.</p>
<p>Bridge networks are used when your applications run in standalone containers that need to communicate.</p>
<p>In the picture above db and web can communicate with each other on a user created bridge network called mybridge.</p>
</section>
<section id="docker-container-ip-address" class="level3">
<h3 class="anchored" data-anchor-id="docker-container-ip-address">Docker Container IP Address</h3>
<p>By default, the container is assigned an IP address for every Docker network it connects to. And each network is created with a default subnet mask, using it as a pool later on to give away the IP addresses. Usually Docker uses the default 172.17. 0.0/16 subnet for container networking.</p>
<p>Now to better understand it, we will execute a real use case.</p>
<p>To illustrate this, we will use a postgreSQL and pgADmin environment, containing 2 Docker Containers, configured in the <code>yaml</code> file below:</p>
<p>services: pgdatabase: image: postgres:13 environment: - POSTGRES_USER=root - POSTGRES_PASSWORD=root - POSTGRES_DB=ny_taxi volumes: - “./data/ny_taxi_postgres_data:/var/lib/postgresql/data:rw” ports: - “5432:5432” pgadmin: image: dpage/pgadmin4 environment: - PGADMIN_DEFAULT_EMAIL=admin@admin.com - PGADMIN_DEFAULT_PASSWORD=root ports: - “8080:80”</p>
<p>Now let’s start up those containers :</p>
<pre><code>docker-compose up </code></pre>
<p>We can see the two containers:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/49edfbdf-ea8d-4cc6-9168-a1189068c32f.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">containers.JPG</figcaption><p></p>
</figure>
</div>
<p>Next let’s check our Docker networks again:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/aee00ff6-99d2-43c2-9d0b-82dcbd559e94.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">new_network.JPG</figcaption><p></p>
</figure>
</div>
<p>There’s a new network called 2_docker_sql_default!</p>
<p>By default docker compose sets up a single network for your app. And your app’s network is given a name based on the “project name”, originated from the name of the directory it lives in. So since our directory is named docker_sql, this explains the new network.</p>
<p>Next some examples on how to get the Docker IP Address.</p>
</section>
<section id="how-to-get-a-docker-container-ip-address" class="level3">
<h3 class="anchored" data-anchor-id="how-to-get-a-docker-container-ip-address">How to Get A Docker Container IP Address</h3>
<p>Docker inspect is a great way to retrieve low-level information on Docker objects. We can pick out any field from the returned JSON in a fairly straightforward manner.</p>
<p>So let’s use it to get the IP Address from the <code>2_docker_sql_pgadmin-1 container</code> using :</p>
<pre><code>       docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' e1feece979bc</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/27e5f8fc-2038-491e-8ab3-c5a83730da36.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">container_IP.JPG</figcaption><p></p>
</figure>
</div>
<p>Didn’t we say that Docker uses the default 172.17. 0.0/16 subnet for container networking? Why is the returned IP Address: 172.20.0.2 outside it? To answer that we have to look at our network settings:</p>
<pre><code>docker network inspect -f '{{range .IPAM.Config}}{{.Subnet}}{{end}}' b7be6c0c20e1</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/e443c142-9d43-49a1-9b50-0d0c503fb492.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">network_inspect.JPG</figcaption><p></p>
</figure>
</div>
<p>We executed this example in a Compute Engine VM, and in this test, the docker network was assigned a different subnet: 172.20.0.0/16. That explains it! Furthermore, we can also lookup all IP Addresses inside the <code>2_docker_sql_deafult</code> network.</p>
<p>So we don’t need to look up each Container’s IP individually:</p>
<pre><code>docker network inspect -f '{{json .Containers}}' b7be6c0c20e1 | jq '.[] | .Name + ":" + .IPv4Address'</code></pre>
<p>Note that we used <code>jq</code> help to parse the Containers map object which you may need to install.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/d1fc1240-f5b2-4406-a339-0d8412bfc646.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">networked_containers_IP.JPG</figcaption><p></p>
</figure>
</div>
<p>So we can see the IP addresses of our containers :</p>
<ul>
<li>pgdatabase-1 <code>172.20.0.3</code> clear</li>
<li>pgadmin-1 <code>172.20.0.2</code></li>
</ul>
<p>This will be useful for mapping our database container to pgadmin:</p>
<p><code>Visual Studio Code</code> can be accessed from the command line using :</p>
<pre><code>code .</code></pre>
<p>Other things we can do from the command line:</p>
<pre><code>ls (lists all files in the directory)
exit (self explanatory)
rm - rf / (remove all files from directory)</code></pre>
<p>We can use <code>sudo</code> to execute commands where we don’t have the necessary permissions.</p>
<p>docker run -it ubuntu bash (run bash commands from within our docker CONTAINER)</p>
<p>docker run -it –entrypoint=bash python:3.9 (bash command to open python) - note that this creates an image (snapshot) of our environment at this particular time. If we make changes subsequently (e.g install pandas) then when we call this command again, pandas will not be there!</p>
<p>pip install pandas (from within Python install pandas)</p>
<p>pandas.__version__ (check which version we have)</p>
<p>We can configure our Docker CONTAINER by creating a Dockerfile within Visual Studio Code (VSC) :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/d8e8be84-f633-4f1b-9c22-57ac7f47d183.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">dockerfile.JPG</figcaption><p></p>
</figure>
</div>
<p>Then build the IMAGE - we’ll name it <code>test:pandas</code> by running the following command from within the terminal:</p>
<p>docker build -t test:pandas .</p>
<p>And run the image:</p>
<p>docker run -it test:pandas</p>
<p>This takes us to a bash command prompt (as this is our ENTRYPOINT defined in our Dockerfile above). We can then open up Python, import pandas and check which version we have:</p>
<p>python import pandas pandas.__version__</p>
</section>
<section id="creating-a-data-pipeline-within-docker" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-data-pipeline-within-docker">Creating a Data Pipeline within Docker</h3>
<p>Create a new file <code>pipeline.py</code> within VSC</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/75f87860-c874-4a8b-9d45-2f0db1485a85.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pipeline.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/2c9f178b-7d37-46c0-8445-7f2e374adcc3.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">dockerfile_2.JPG</figcaption><p></p>
</figure>
</div>
<p>Let’s run the following command in the terminal :</p>
<p>docker run -it test:pandas root@f009333fb3e5:/app# pwd (<code>pwd</code> takes us to the CURRENT directory)</p>
<p>/app</p>
<p>We can see that this is <code>/app</code> as specified in <code>WORKDIR</code> in our Dockefile above</p>
<p>Next run our <code>pipeline.py</code> file:</p>
<p>python pipeline.py</p>
<p>And we get the following output:</p>
<p>job finished successfully</p>
<p>This was the final item in our pipeline.py file :)</p>
</section>
<section id="fine-tuning-our-docker-container" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-our-docker-container">Fine tuning our Docker container</h3>
<p>Let’s fine tune the configuration of our container a bit more prior to scheduling a run:</p>
<p><img src="Data_Eng_Week_1_files/figure-html/2a7f19a2-85db-498b-916f-39030b4a95b4.JPG" class="img-fluid" alt="pipeline_2.JPG"><img src="Data_Eng_Week_1_files/figure-html/1a758c7e-2c2b-4c07-aac8-337c3cc28e9c.jpg" class="img-fluid" alt="download.jpg"></p>
<p>We first rebuild using our usual command:</p>
<p>docker build -t test:pandas .</p>
<p>Say we want to schedule the run for a particular today - for illustrative purposes let’s use today’s date. We define <code>day</code> as system <em>argument</em> number 1 (argument 0 is the file name). We then pass in that argument (today’s date - 2023-02-09) in our command line prompt:</p>
<p>docker run -it test:pandas 2023-02-09</p>
<p>And we get the following output:</p>
<p>[‘pipeline.py’, ‘2023-02-09’]</p>
<p>job finished successfully for day = 2023-02-09</p>
<p>The items inside [ ] are the <code>arguments</code> - number 0 is the file name <code>pipeline.py</code>, number 1 is the date</p>
<p>We can include further arguments within our command line propmpt e.g :</p>
<p>docker run -it test:pandas 2023-02-09 Incoming. 137 new album!</p>
<p>This returns the following output:</p>
<p>[‘pipeline.py’, ‘2023-02-09’, ‘Incoming.’, ‘137’, ‘new’, ‘album!’] job finished successfully for day = 2023-02-09</p>
<p>The additonal agruments specified are listed as we included</p>
<pre><code>print(sys.arg)</code></pre>
<p>in our <code>pipeline.py</code> file</p>
</section>
</section>
<section id="running-postgresql-postgres-locally-with-docker" class="level2">
<h2 class="anchored" data-anchor-id="running-postgresql-postgres-locally-with-docker">Running PostgreSQL (Postgres) locally with Docker</h2>
<p>PostgreSQL, often simply “Postgres”, is an object-relational database management system (ORDBMS) with an emphasis on extensibility and standards-compliance. As a database server, its primary function is to store data, securely and supporting best practices, and retrieve it later, as requested by other software applications, be it those on the same computer or those running on another computer across a network (including the Internet). It can handle workloads ranging from small single-machine applications to large Internet-facing applications with many concurrent users. Recent versions also provide replication of the database itself for security and scalability.</p>
<p>PostgreSQL implements the majority of the SQL:2011 standard, is ACID-compliant and transactional (including most DDL statements) avoiding locking issues using multiversion concurrency control (MVCC), provides immunity to dirty reads and full serializability; handles complex SQL queries using many indexing methods that are not available in other databases; has updateable views and materialized views, triggers, foreign keys; supports functions and stored procedures, and other expandability, and has a large number of extensions written by third parties. In addition to the possibility of working with the major proprietary and open source databases, PostgreSQL supports migration from them, by its extensive standard SQL support and available migration tools. And if proprietary extensions had been used, by its extensibility that can emulate many through some built-in and third-party open source compatibility extensions, such as for Oracle.</p>
<p>To connect to PostreSQL :</p>
<p>docker run -it<br>
-e POSTGRES_USER=“root”<br>
-e POSTGRES_PASSWORD=“root”<br>
-e POSTGRES_DB=“ny_taxi”<br>
-v $(pwd)/ny_taxi_postgres_data:/var/lib/postgresql/data<br>
-p 5432:5432<br>
postgres:13</p>
<p>docker run -it # -it allows us to stop it postgres:13 # this is our IMAGE</p>
<p>Configure our environment using <code>-e</code> :</p>
<p>-e POSTGRES_USER=“root” &nbsp; # user name -e POSTGRES_PASSWORD=“root” &nbsp; # passwordcd -e POSTGRES_DB=“ny_taxi” &nbsp; # database name</p>
<p>Configure our VOLUME using <code>-v</code><br>
Note that because I am using Ununtu I need to map full path of existing directory using <code>$(pwd)</code> :</p>
<p>-v $(pwd)/ny_taxi_postgres_data:/var/lib/postgresql/data<br>
</p>
<p>Map a port on our host machine to a port on our CONTAINER using <code>-p</code> :</p>
<p>-p 5432:5432<br>
</p>
<p>If you get an error:</p>
<blockquote class="blockquote">
<p>initdb: error: directory “/var/lib/postgresql/data” exists but is not empty</p>
</blockquote>
<p>Remove the <code>ny_taxi_postgres_data</code> directory and run the command again.</p>
<p>In Visual Studio Code it looks like there are no files in the directory despite a succesful connection to postgres. But the files are actually just hidden - and can be accessed using the <code>sudo</code> command in Ununtu:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/54b35345-ab91-4a52-a39d-050f031b7899.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">sudo.JPG</figcaption><p></p>
</figure>
</div>
<section id="accessing-postgresql" class="level3">
<h3 class="anchored" data-anchor-id="accessing-postgresql">Accessing PostgreSQL</h3>
<p>Our way in to <code>PostgreSQL</code> is via the command line:</p>
<pre><code>pgcli -h localhost -p 5432 -u root -d ny_taxi</code></pre>
<p>-h = host<br>
-p = port<br>
-u = user<br>
-d = database</p>
<p>Check if a container is running:</p>
<p>docker ps</p>
<p>Kill the container :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>docker stop <span class="op">&lt;</span>CONTAINER ID<span class="op">&gt;</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="downloading-a-file" class="level3">
<h3 class="anchored" data-anchor-id="downloading-a-file">Downloading a file</h3>
<p>wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz</p>
<p>Unzipping a .gz file and retaining original :</p>
<p>gzip -dk &lt;file_name.csv.gz&gt;</p>
<p>Save to csv using <code>&gt;</code>:</p>
<p>head -n 100 yellow_tripdata_2021-01.csv &gt; yellow_head.csv</p>
</section>
<section id="copying-a-file-to-existing-directory-using" class="level3">
<h3 class="anchored" data-anchor-id="copying-a-file-to-existing-directory-using">Copying a file to existing directory using <code>~</code></h3>
<p>cp ~  .</p>
<p>Looking at a text data file from the command line:</p>
<p>less <file_name></file_name></p>
<p>Look at say first <code>n</code> rows :</p>
<p>head -n 100 <file_name></file_name></p>
<p>Count number of lines using <code>wc</code> (word count) <code>-l</code> (lines):</p>
<p>wc -l <file_name></file_name></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>pd.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>'1.5.0'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'Data/yellow_tripdata_2021-01.csv'</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_176/843851997.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv('Data/yellow_tripdata_2021-01.csv')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>VendorID</th>
      <th>tpep_pickup_datetime</th>
      <th>tpep_dropoff_datetime</th>
      <th>passenger_count</th>
      <th>trip_distance</th>
      <th>RatecodeID</th>
      <th>store_and_fwd_flag</th>
      <th>PULocationID</th>
      <th>DOLocationID</th>
      <th>payment_type</th>
      <th>fare_amount</th>
      <th>extra</th>
      <th>mta_tax</th>
      <th>tip_amount</th>
      <th>tolls_amount</th>
      <th>improvement_surcharge</th>
      <th>total_amount</th>
      <th>congestion_surcharge</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>2021-01-01 00:30:10</td>
      <td>2021-01-01 00:36:12</td>
      <td>1.0</td>
      <td>2.10</td>
      <td>1.0</td>
      <td>N</td>
      <td>142</td>
      <td>43</td>
      <td>2.0</td>
      <td>8.00</td>
      <td>3.00</td>
      <td>0.5</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>11.80</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>2021-01-01 00:51:20</td>
      <td>2021-01-01 00:52:19</td>
      <td>1.0</td>
      <td>0.20</td>
      <td>1.0</td>
      <td>N</td>
      <td>238</td>
      <td>151</td>
      <td>2.0</td>
      <td>3.00</td>
      <td>0.50</td>
      <td>0.5</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>4.30</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>2021-01-01 00:43:30</td>
      <td>2021-01-01 01:11:06</td>
      <td>1.0</td>
      <td>14.70</td>
      <td>1.0</td>
      <td>N</td>
      <td>132</td>
      <td>165</td>
      <td>1.0</td>
      <td>42.00</td>
      <td>0.50</td>
      <td>0.5</td>
      <td>8.65</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>51.95</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>2021-01-01 00:15:48</td>
      <td>2021-01-01 00:31:01</td>
      <td>0.0</td>
      <td>10.60</td>
      <td>1.0</td>
      <td>N</td>
      <td>138</td>
      <td>132</td>
      <td>1.0</td>
      <td>29.00</td>
      <td>0.50</td>
      <td>0.5</td>
      <td>6.05</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>36.35</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>2021-01-01 00:31:49</td>
      <td>2021-01-01 00:48:21</td>
      <td>1.0</td>
      <td>4.94</td>
      <td>1.0</td>
      <td>N</td>
      <td>68</td>
      <td>33</td>
      <td>1.0</td>
      <td>16.50</td>
      <td>0.50</td>
      <td>0.5</td>
      <td>4.06</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>24.36</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1369760</th>
      <td>NaN</td>
      <td>2021-01-25 08:32:04</td>
      <td>2021-01-25 08:49:32</td>
      <td>NaN</td>
      <td>8.80</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>135</td>
      <td>82</td>
      <td>NaN</td>
      <td>21.84</td>
      <td>2.75</td>
      <td>0.5</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>25.39</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1369761</th>
      <td>NaN</td>
      <td>2021-01-25 08:34:00</td>
      <td>2021-01-25 09:04:00</td>
      <td>NaN</td>
      <td>5.86</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>42</td>
      <td>161</td>
      <td>NaN</td>
      <td>26.67</td>
      <td>2.75</td>
      <td>0.5</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>30.22</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1369762</th>
      <td>NaN</td>
      <td>2021-01-25 08:37:00</td>
      <td>2021-01-25 08:53:00</td>
      <td>NaN</td>
      <td>4.45</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>14</td>
      <td>106</td>
      <td>NaN</td>
      <td>25.29</td>
      <td>2.75</td>
      <td>0.5</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>28.84</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1369763</th>
      <td>NaN</td>
      <td>2021-01-25 08:28:00</td>
      <td>2021-01-25 08:50:00</td>
      <td>NaN</td>
      <td>10.04</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>175</td>
      <td>216</td>
      <td>NaN</td>
      <td>28.24</td>
      <td>2.75</td>
      <td>0.5</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>31.79</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1369764</th>
      <td>NaN</td>
      <td>2021-01-25 08:38:00</td>
      <td>2021-01-25 08:50:00</td>
      <td>NaN</td>
      <td>4.93</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>248</td>
      <td>168</td>
      <td>NaN</td>
      <td>20.76</td>
      <td>2.75</td>
      <td>0.5</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>24.31</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>1369765 rows × 18 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df.dtypes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>VendorID                 float64
tpep_pickup_datetime      object
tpep_dropoff_datetime     object
passenger_count          float64
trip_distance            float64
RatecodeID               float64
store_and_fwd_flag        object
PULocationID               int64
DOLocationID               int64
payment_type             float64
fare_amount              float64
extra                    float64
mta_tax                  float64
tip_amount               float64
tolls_amount             float64
improvement_surcharge    float64
total_amount             float64
congestion_surcharge     float64
dtype: object</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">### Generate a schema for use within postgreSQL</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Module within pandas named <code>io</code> to convert to Data Definition Language (DDL) :</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.io.sql.get_schema(df, name<span class="op">=</span><span class="st">'yellow_taxi_data'</span>)) <span class="co"># name of Table</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CREATE TABLE "yellow_taxi_data" (
"VendorID" REAL,
  "tpep_pickup_datetime" TEXT,
  "tpep_dropoff_datetime" TEXT,
  "passenger_count" REAL,
  "trip_distance" REAL,
  "RatecodeID" REAL,
  "store_and_fwd_flag" TEXT,
  "PULocationID" INTEGER,
  "DOLocationID" INTEGER,
  "payment_type" REAL,
  "fare_amount" REAL,
  "extra" REAL,
  "mta_tax" REAL,
  "tip_amount" REAL,
  "tolls_amount" REAL,
  "improvement_surcharge" REAL,
  "total_amount" REAL,
  "congestion_surcharge" REAL
)</code></pre>
</div>
</div>
<p>We can see immmediately that pick up and drop off datatype is <code>TEXT</code> but needs to be converted (parsed) to <code>datetime</code>. We can do this using pandas <code>to_datetime</code>:</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>pd.to_datetime(df.tpep_pickup_datetime)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>0         2021-01-01 00:30:10
1         2021-01-01 00:51:20
2         2021-01-01 00:43:30
3         2021-01-01 00:15:48
4         2021-01-01 00:31:49
                  ...        
1369760   2021-01-25 08:32:04
1369761   2021-01-25 08:34:00
1369762   2021-01-25 08:37:00
1369763   2021-01-25 08:28:00
1369764   2021-01-25 08:38:00
Name: tpep_pickup_datetime, Length: 1369765, dtype: datetime64[ns]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>pd.to_datetime(df.tpep_dropoff_datetime)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>0         2021-01-01 00:36:12
1         2021-01-01 00:52:19
2         2021-01-01 01:11:06
3         2021-01-01 00:31:01
4         2021-01-01 00:48:21
                  ...        
1369760   2021-01-25 08:49:32
1369761   2021-01-25 09:04:00
1369762   2021-01-25 08:53:00
1369763   2021-01-25 08:50:00
1369764   2021-01-25 08:50:00
Name: tpep_dropoff_datetime, Length: 1369765, dtype: datetime64[ns]</code></pre>
</div>
</div>
<p>We now need to update our dataframe:</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>df.tpep_pickup_datetime <span class="op">=</span> pd.to_datetime(df.tpep_pickup_datetime)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>df.tpep_dropoff_datetime <span class="op">=</span> pd.to_datetime(df.tpep_dropoff_datetime)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.io.sql.get_schema(df, name<span class="op">=</span><span class="st">'yellow_taxi_data'</span>)) <span class="co"># name of Table</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CREATE TABLE "yellow_taxi_data" (
"VendorID" REAL,
  "tpep_pickup_datetime" TIMESTAMP,
  "tpep_dropoff_datetime" TIMESTAMP,
  "passenger_count" REAL,
  "trip_distance" REAL,
  "RatecodeID" REAL,
  "store_and_fwd_flag" TEXT,
  "PULocationID" INTEGER,
  "DOLocationID" INTEGER,
  "payment_type" REAL,
  "fare_amount" REAL,
  "extra" REAL,
  "mta_tax" REAL,
  "tip_amount" REAL,
  "tolls_amount" REAL,
  "improvement_surcharge" REAL,
  "total_amount" REAL,
  "congestion_surcharge" REAL
)</code></pre>
</div>
</div>
<p>Successfully updated our pick up and drop off to <code>Timestamp</code></p>
<p>Simply copying and pasting the above <em>might</em> work but we need to create the above statement in a way that postgreSQL will understand for sure. For that we need to tell pandas that we want to put this into postgres :</p>
</section>
</section>
<section id="sql-alchemy" class="level2">
<h2 class="anchored" data-anchor-id="sql-alchemy">SQL Alchemy</h2>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sqlalchemy <span class="im">import</span> create_engine</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>engine <span class="op">=</span> create_engine(<span class="st">'postgresql://root:root@localhost:5432/ny_taxi'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.io.sql.get_schema(df, name<span class="op">=</span><span class="st">'yellow_taxi_data'</span>,con<span class="op">=</span>engine)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
CREATE TABLE yellow_taxi_data (
    "VendorID" FLOAT(53), 
    tpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, 
    tpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, 
    passenger_count FLOAT(53), 
    trip_distance FLOAT(53), 
    "RatecodeID" FLOAT(53), 
    store_and_fwd_flag TEXT, 
    "PULocationID" BIGINT, 
    "DOLocationID" BIGINT, 
    payment_type FLOAT(53), 
    fare_amount FLOAT(53), 
    extra FLOAT(53), 
    mta_tax FLOAT(53), 
    tip_amount FLOAT(53), 
    tolls_amount FLOAT(53), 
    improvement_surcharge FLOAT(53), 
    total_amount FLOAT(53), 
    congestion_surcharge FLOAT(53)
)

</code></pre>
</div>
</div>
<p>Our dataframe has 1.3m + rows, so we can break this down into batches for passing into postgreSQL :</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>df_iter <span class="op">=</span> pd.read_csv(<span class="st">'Data/yellow_tripdata_2021-01.csv'</span>, iterator<span class="op">=</span><span class="va">True</span>, chunksize<span class="op">=</span><span class="dv">100000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> <span class="bu">next</span>(df_iter)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>100000</code></pre>
</div>
</div>
<p>We want to set up the data headers first and then insert the data in chunks later</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># To get our column names</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>df.head(n<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>VendorID</th>
      <th>tpep_pickup_datetime</th>
      <th>tpep_dropoff_datetime</th>
      <th>passenger_count</th>
      <th>trip_distance</th>
      <th>RatecodeID</th>
      <th>store_and_fwd_flag</th>
      <th>PULocationID</th>
      <th>DOLocationID</th>
      <th>payment_type</th>
      <th>fare_amount</th>
      <th>extra</th>
      <th>mta_tax</th>
      <th>tip_amount</th>
      <th>tolls_amount</th>
      <th>improvement_surcharge</th>
      <th>total_amount</th>
      <th>congestion_surcharge</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>
</div>
</div>
<p>Upload column headers to postgres :</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>df.head(n<span class="op">=</span><span class="dv">0</span>).to_sql(name<span class="op">=</span><span class="st">'yellow_taxi_data'</span>, </span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>                    con<span class="op">=</span>engine, </span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>                    if_exists<span class="op">=</span><span class="st">'replace'</span>)         <span class="co">#if a table name with yellow_taxi_data exists then replace</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>0</code></pre>
</div>
</div>
<p>Upload first chunk of 100000 rows to postgres :</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>time</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>df.to_sql(name<span class="op">=</span><span class="st">'yellow_taxi_data'</span>, </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>                    con<span class="op">=</span>engine, </span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>                    if_exists<span class="op">=</span><span class="st">'append'</span>)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 2 µs, sys: 0 ns, total: 2 µs
Wall time: 2.86 µs</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>1000</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> time</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Upload the rest of the dataframe:</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    t_start <span class="op">=</span> time() <span class="co"># returns current timestamp in seconds</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> <span class="bu">next</span>(df_iter) </span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    df.tpep_pickup_datetime <span class="op">=</span> pd.to_datetime(df.tpep_pickup_datetime)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    df.tpep_dropoff_datetime <span class="op">=</span> pd.to_datetime(df.tpep_dropoff_datetime)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    df.to_sql(name<span class="op">=</span><span class="st">'yellow_taxi_data'</span>, </span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>                    con<span class="op">=</span>engine, </span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>                    if_exists<span class="op">=</span><span class="st">'append'</span>)  </span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>    t_end <span class="op">=</span> time()</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (<span class="st">'inserted another chunk, took </span><span class="sc">%.3f</span><span class="st"> second'</span> <span class="op">%</span> (t_end <span class="op">-</span> t_start)) <span class="co"># .3f means to 3 decimal places - the % in the text is a variable defined by % outside the text</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>inserted another chunk, took 5.831 second
inserted another chunk, took 5.825 second
inserted another chunk, took 5.723 second
inserted another chunk, took 5.720 second
inserted another chunk, took 5.727 second
inserted another chunk, took 5.636 second
inserted another chunk, took 5.660 second
inserted another chunk, took 5.663 second
inserted another chunk, took 5.661 second
inserted another chunk, took 5.709 second
inserted another chunk, took 5.636 second</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_176/4268203882.py:4: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = next(df_iter)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>inserted another chunk, took 5.549 second
inserted another chunk, took 3.551 second</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>StopIteration: </code></pre>
</div>
</div>
<p>The above error can be ignored - it just means there are no more chunks to add our dataframe has been successfully uploaded in full to postgres. We can check that from the command line - our way in to <code>postgres</code> is to use:</p>
<pre><code>pgcli -h localhost -p 5432 -u root -d ny_taxi</code></pre>
<p>-h = host<br>
-p = port<br>
-u = user<br>
-d = database</p>
<p>….as previously defined in our Dockerfile</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/c8924381-9b22-45b0-9ec8-84889cb252a0.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">postgres_dataload.JPG</figcaption><p></p>
</figure>
</div>
<p>We can then run queries on our data from the command line:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/0e70240e-4fbe-49b3-a4ee-fcca3881aa25.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">postgres_query.JPG</figcaption><p></p>
</figure>
</div>
<p>This process works OK, but it is quite clumsy. Thankfully there is a better way than using SQL Alchemy.</p>
<section id="pgadmin" class="level3">
<h3 class="anchored" data-anchor-id="pgadmin">pgAdmin</h3>
<p>pgAdmin is the most popular and feature rich Open Source administration and development platform for PostgreSQL, the most advanced Open Source database in the world. pgAdmin may be used on Linux, Unix, macOS and Windows to manage PostgreSQL and EDB Advanced Server 10 and above.</p>
<p>Although this is a GUI and can be installed, we don’t need to - we have Docker! and so we can just pull it from there by running the folllowing from the command line :</p>
<p>docker run -it<br>
-e PGADMIN_DEFAULT_EMAIL=“admin@admin.com”<br>
-e PGADMIN_DEFAULT_PASSWORD=“root”<br>
-p 8080:80<br>
dpage/pgadmin4</p>
<p>We then go to our browser and type:</p>
<pre><code>localhost8080</code></pre>
<p>which takes us to the pgAdmin loginpage</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/27953808-ea70-4e3c-a9a2-b5b79ab316cb.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pgadmin.JPG</figcaption><p></p>
</figure>
</div>
<p>We then have to register a server:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/be9a5ee1-9cbb-4ec2-aece-f87eacb7c90d.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pgadmin_register_server.JPG</figcaption><p></p>
</figure>
</div>
<p>We can name it anything we like - let’s use <code>PostgreSQL</code></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/7b17cbd8-f748-4d7b-88f3-a292449d2fe0.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pgadmin_register_server.JPG</figcaption><p></p>
</figure>
</div>
<p>And then configure our connection as previously defined with postgres container IP address as <code>Connection Name</code> :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/660b5ba5-4912-4f10-9e89-47010700a38d.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pgadmin_connection.JPG</figcaption><p></p>
</figure>
</div>
</section>
<section id="connecting-pgadmin-and-postgres" class="level3">
<h3 class="anchored" data-anchor-id="connecting-pgadmin-and-postgres">1.2.3 Connecting pgAdmin and Postgres</h3>
<p>To do this we can refer to the <a href="https://docs.docker.com/engine/reference/commandline/network_create/">official docs</a>. First we can run the following from the command line :</p>
<p>docker network create pg-network</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/38e3647c-0e7c-481e-9fd8-84e6bb74f365.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">network.JPG</figcaption><p></p>
</figure>
</div>
<p>When we run postgres we need to specify that the container should be run in the above network - path <code>0967dbb30b4751b5cb7b4644b192229df8ab189c19c24226dc6e5ef6457e14da</code>.</p>
<p>Run postgres:</p>
<p>docker run -it<br>
-e POSTGRES_USER=“root”<br>
-e POSTGRES_PASSWORD=“root”<br>
-e POSTGRES_DB=“ny_taxi”<br>
-v <span class="math inline">\((pwd)/\)</span>ny_taxi_postgres_data:/var/lib/postgres/data<br>
-p 5432:5432<br>
–network=pg-network<br>
–name pg-database<br>
postgres:13</p>
<p>Run pgAdmin :</p>
<p>docker run -it<br>
-e PGADMIN_DEFAULT_EMAIL=“admin@admin.com”<br>
-e PGADMIN_DEFAULT_PASSWORD=“root”<br>
-p 8080:80<br>
–network=pg-network &nbsp;# specify network name –name pgadmin-2 &nbsp;# specify a pgadmin name dpage/pgadmin4</p>
<p>docker run -it<br>
-e PGADMIN_DEFAULT_EMAIL=“admin@admin.com”<br>
-e PGADMIN_DEFAULT_PASSWORD=“root”<br>
-p 8080:80<br>
–network=pg-network &nbsp; –name pgadmin-2 &nbsp; dpage/pgadmin4</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/2e2cf412-9978-4bba-9cec-5fe5001b889e.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pgadmin_2.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/9f58b529-bdd2-46f7-9e81-4fc1e86cd4d1.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pgadmin_connection_2.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/992b4877-3187-4a40-8fc2-98751a5a0277.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pg_admin_connected.JPG</figcaption><p></p>
</figure>
</div>
</section>
<section id="ingesting-data" class="level3">
<h3 class="anchored" data-anchor-id="ingesting-data">Ingesting data</h3>
<p>We can automate the data upload to postgres by creating a python script which first downloads the data, does some basic pre-processing, and then uploads in chunks to postgres :</p>
<p>#!/usr/bin/env python # coding: utf-8</p>
<p>import os import argparse</p>
<p>from time import time</p>
<p>import pandas as pd from sqlalchemy import create_engine</p>
<p>def main(params): user = params.user password = params.password host = params.host port = params.port db = params.db table_name = params.table_name url = params.url</p>
<pre><code># the backup files are gzipped, and it's important to keep the correct extension
# for pandas to be able to open the file
if url.endswith('.csv.gz'):
    csv_name = 'output.csv.gz'
else:
    csv_name = 'output.csv'

os.system(f"wget {url} -O {csv_name}")

engine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{db}')

df_iter = pd.read_csv(csv_name, iterator=True, chunksize=100000)

df = next(df_iter)

df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)
df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)

df.head(n=0).to_sql(name=table_name, con=engine, if_exists='replace')

df.to_sql(name=table_name, con=engine, if_exists='append')


while True: 

    try:
        t_start = time()
        
        df = next(df_iter)

        df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)
        df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)

        df.to_sql(name=table_name, con=engine, if_exists='append')

        t_end = time()

        print('inserted another chunk, took %.3f second' % (t_end - t_start))

    except StopIteration:
        print("Finished ingesting data into the postgres database")
        break</code></pre>
<p>if <strong>name</strong> == ‘<strong>main</strong>’: parser = argparse.ArgumentParser(description=‘Ingest CSV data to Postgres’)</p>
<pre><code>parser.add_argument('--user', required=True, help='user name for postgres')
parser.add_argument('--password', required=True, help='password for postgres')
parser.add_argument('--host', required=True, help='host for postgres')
parser.add_argument('--port', required=True, help='port for postgres')
parser.add_argument('--db', required=True, help='database name for postgres')
parser.add_argument('--table_name', required=True, help='name of the table where we will write the results to')
parser.add_argument('--url', required=True, help='url of the csv file')

args = parser.parse_args()

main(args)</code></pre>
<p>This command line prompt runs the python data ingest file :</p>
<p>URL=“https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz”</p>
<p>python ingest_data.py<br>
–user=root<br>
–password=root<br>
–host=localhost<br>
–port=5432<br>
–db=ny_taxi<br>
–table_name=yellow_taxi_trips<br>
–url=${URL}</p>
<p>As we can see that has successfully loaded the data to postgres :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/941af2eb-5a0c-4f53-9fe6-051acacc622b.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pg_admin_data_ingest.JPG</figcaption><p></p>
</figure>
</div>
</section>
<section id="dockerizing-our-data-ingestion-file" class="level3">
<h3 class="anchored" data-anchor-id="dockerizing-our-data-ingestion-file">1.2.4 Dockerizing our data ingestion file</h3>
<p>Create the following Dockerfile :</p>
<p>FROM python:3.9.1</p>
<p>RUN apt-get install wget<br>
RUN pip install pandas sqlalchemy psycopg2</p>
<p>WORKDIR /app COPY ingest_data.py ingest_data.py</p>
<p>ENTRYPOINT [ “python”, “ingest_data.py” ]</p>
<p>Then run the following command line prompts :</p>
<p>docker build -t taxi_ingest:v001 .</p>
<p>Running this throws up the following error:</p>
<pre><code>Docker - failed to solve with frontend dockerfile.v0: failed to read dockerfile: error from sender: open ny_taxi_postgres_data: permission denied.</code></pre>
<p>This happens on Ubuntu/Linux systems when trying to run the command to build the Docker container again. A folder is created to host the Docker files. When the build command is executed again to rebuild the pipeline or create a new one the error is raised as there are no permissions on this new folder. Grant permissions by running this command :</p>
<p>sudo chmod -R 755 ny_taxi_postgres_data</p>
<p>Now run the following from the command line:</p>
<p>URL=“https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz”</p>
<p>docker run -it<br>
–network=pg-network<br>
taxi_ingest:v001<br>
–user=root<br>
–password=root<br>
–host=pg-database<br>
–port=5432<br>
–db=ny_taxi<br>
–table_name=yellow_taxi_trips<br>
</p>
<pre><code>--url=${URL}</code></pre>
<p>To get all the files on a <code>localhost</code> directory we can run the following command:</p>
<p>python -m http.server</p>
<p>To get the IP address of your computer you can run :</p>
<p>ipconfig</p>
</section>
<section id="docker-compose" class="level3">
<h3 class="anchored" data-anchor-id="docker-compose">1.2.5 Docker Compose</h3>
<p>In the previous section we:</p>
<ul>
<li>ran postgres</li>
<li>ran pgAdmin</li>
</ul>
<p>in one network using two docker commands.</p>
<p>This works fine but there is a lot of configuration required. We can streamline the process by pooling everything together in one <code>yaml</code> file where we can configure multiple CONTAINERS. We can then run from the command line using <a href="https://docs.docker.com/compose/">docker-compose</a> :</p>
<p>Let’s try <code>docker-compose</code> from the command line :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/81983855-aa08-40da-b26c-e2f19a94ce0a.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">docker_compose.JPG</figcaption><p></p>
</figure>
</div>
<p>Docker Compose comes as part of Windows Docker Desktop, but if like me, you are running things in Linux from the Ubuntu command line, then you need to activate the WSL integration:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/a9cb290a-594d-47c3-b3b4-c17721acd275.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">docker_compose_ubuntu.JPG</figcaption><p></p>
</figure>
</div>
<p>Running <code>docker-compose</code> now works:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/9b6cf6ea-9441-4954-ac53-35f11e749e2e.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">docker_compose_wsl_integration.JPG</figcaption><p></p>
</figure>
</div>
<p>We can now create our <code>yaml</code> file named <code>docker-compose.yaml</code> :</p>
<p>services: pgdatabase: image: postgres:13 environment: - POSTGRES_USER=root - POSTGRES_PASSWORD=root - POSTGRES_DB=ny_taxi volumes: - “./ny_taxi_postgres_data:/var/lib/postgres/data:rw” ports: - “5432:5432” pgadmin: image: dpage/pgadmin4 environment: - PGADMIN_DEFAULT_EMAIL=admin@admin.com - PGADMIN_DEFAULT_PASSWORD=root ports: - “8080:80”</p>
<p>Ensure all existing containers, volumes and images are cleared and run using :</p>
<p>docker-compose up</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/f8839838-8838-4a0c-8327-d9bda26ec2a2.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">docker_compose_up.JPG</figcaption><p></p>
</figure>
</div>
<p>Then we go to localhost 8080 and use the pgAdmin login details configured in the yaml file. Unfortunately the yaml file is not configured to ensure persistent state for pgAdmin, so we have to register a server again.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/4db885ca-f843-40ca-9e3d-ccc77421df23.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">docker_localhost.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/2880bbff-8777-400e-bf9a-4d4dfda240b9.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pgdatabase.JPG</figcaption><p></p>
</figure>
</div>
<p>We can close the terminal using <code>CTRL + C</code> but then we should also run <code>docker-compose down</code>.</p>
<p>A better way is to run with <code>docker-compose up -d</code> runs in <em>detached mode</em> which then allows us to bypass <code>CTRL + C</code> and go straight to <code>docker-compose down</code>.</p>
</section>
<section id="sql-refresher" class="level3">
<h3 class="anchored" data-anchor-id="sql-refresher">1.2.6 - SQL Refresher</h3>
<p>Let’s download the taxi zone csv:</p>
<p>wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv</p>
<p>And load in:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>df_zones <span class="op">=</span> pd.read_csv(<span class="st">'Data/taxi_zone_lookup.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Take a look at the first 5 rows :</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>df_zones.head(<span class="dv">140</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>LocationID</th>
      <th>Borough</th>
      <th>Zone</th>
      <th>service_zone</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>EWR</td>
      <td>Newark Airport</td>
      <td>EWR</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Queens</td>
      <td>Jamaica Bay</td>
      <td>Boro Zone</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Bronx</td>
      <td>Allerton/Pelham Gardens</td>
      <td>Boro Zone</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Manhattan</td>
      <td>Alphabet City</td>
      <td>Yellow Zone</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Staten Island</td>
      <td>Arden Heights</td>
      <td>Boro Zone</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>135</th>
      <td>136</td>
      <td>Bronx</td>
      <td>Kingsbridge Heights</td>
      <td>Boro Zone</td>
    </tr>
    <tr>
      <th>136</th>
      <td>137</td>
      <td>Manhattan</td>
      <td>Kips Bay</td>
      <td>Yellow Zone</td>
    </tr>
    <tr>
      <th>137</th>
      <td>138</td>
      <td>Queens</td>
      <td>LaGuardia Airport</td>
      <td>Airports</td>
    </tr>
    <tr>
      <th>138</th>
      <td>139</td>
      <td>Queens</td>
      <td>Laurelton</td>
      <td>Boro Zone</td>
    </tr>
    <tr>
      <th>139</th>
      <td>140</td>
      <td>Manhattan</td>
      <td>Lenox Hill East</td>
      <td>Yellow Zone</td>
    </tr>
  </tbody>
</table>
<p>140 rows × 4 columns</p>
</div>
</div>
</div>
<p>Upload to postgres :</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>df_zones.to_sql(name<span class="op">=</span><span class="st">'zones'</span>, con<span class="op">=</span>engine, if_exists<span class="op">=</span><span class="st">'replace'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>265</code></pre>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/cf29acd3-607b-4d0a-9250-5770e97ede66.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">taxi_zones.JPG</figcaption><p></p>
</figure>
</div>
<p>Let’s now carry out some SQL queries on our tables:</p>
<ul>
<li>yellow_taxi_trips</li>
<li>zones</li>
</ul>
<section id="joining-tables-in-sql" class="level4">
<h4 class="anchored" data-anchor-id="joining-tables-in-sql">Joining tables in SQL</h4>
<p>It will be useful to join these tables. There are different ways to do this. First let’s look at query which returns specified columns which combine certain information common to both tables - in this case <code>LocationID</code> :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/22f7276f-0912-4b45-8b2b-24caebcf3b33.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">SQL_join_1.JPG</figcaption><p></p>
</figure>
</div>
<p>Another way to construct the query is to explicitly use the <code>JOIN</code> command:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/ca20d1e5-dc17-4a82-841e-82a1bf39aa3d.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">SQL_join_2.JPG</figcaption><p></p>
</figure>
</div>
<p>Both queries are equivalent.</p>
<p>Say, we wanted to check for pick up or drop off locations which are in one table but not the other:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/a29ec724-7b8c-4c01-8e82-154712b405d4.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pick_up.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/4f9029b2-c76f-4756-b78b-64c44ffc73ec.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">drop_off.JPG</figcaption><p></p>
</figure>
</div>
<p>Both queries return no records so that means that all the records have pick up and drop off locations and all the IDs in the zones table are present in the taxis table. In some cases there might not be fully matching records. In this case we can use other join methods :</p>
<p>For illustration purposes let’s remove a <code>LocationID</code> record from our <code>zones</code> table:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/2a9be0d1-0575-4085-93ea-e06f94de8181.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">delete.JPG</figcaption><p></p>
</figure>
</div>
<p>And now when we query records that don’t match :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/704fb677-99e5-4439-ab94-0a99813f1ab7.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">pulocation_unmatched.JPG</figcaption><p></p>
</figure>
</div>
<p>We can use <code>LEFT JOIN</code> which will still return a record even where <code>LocationID</code> is not available :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/6c687151-f6e9-4448-90f5-aa0f15ee8a78.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">left_join.JPG</figcaption><p></p>
</figure>
</div>
<p>There are also <code>RIGHT JOIN</code> and <code>OUTER JOIN</code> statements but these will be covered further in <em>Week 4</em> .</p>
</section>
<section id="working-with-dates" class="level4">
<h4 class="anchored" data-anchor-id="working-with-dates">Working with dates</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/4e0c2be2-5dbe-4fdf-a901-a807f131c607.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">day.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/7e892f2d-583f-4e91-80b0-dda1ec74d7cf.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">date.JPG</figcaption><p></p>
</figure>
</div>
</section>
<section id="aggregating-in-sql" class="level4">
<h4 class="anchored" data-anchor-id="aggregating-in-sql">Aggregating in SQL</h4>
<p>Say we wanted to find how many records there were for each day. We can build on our date parsing above and use a <code>GROUP BY</code> and <code>ORDER BY</code> query :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/2cf1bce5-0b8b-4a04-9dac-5c17ba50d9f6.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">group_order.JPG</figcaption><p></p>
</figure>
</div>
<p>If we wanted to see the day with the largest number of records we coud order by count:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/46bb5285-0315-4e57-842c-fcb4a240c4b1.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">order_count.JPG</figcaption><p></p>
</figure>
</div>
<p>We can use a variety of aggregation methods. Note that we can use numbers to reference the ordering of <code>GROUP BY</code> :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/d4addb62-1316-4dca-920d-9afc9b9091f6.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">group_by_number_ref.JPG</figcaption><p></p>
</figure>
</div>
<p>We can also include multiple conditions in our <code>ORDER BY</code> clause :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/08cfb2a3-f855-475b-b1c2-40ed505a59b3.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">order_by_multiple.JPG</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="google-cloud-platform-gcp" class="level3">
<h3 class="anchored" data-anchor-id="google-cloud-platform-gcp">Google Cloud Platform (GCP)</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/eef1da59-5bd3-4031-9171-03a19caef14f.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">GCP.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/92f28eee-37a5-4a8d-824e-0da7e6899a28.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">GCP_navigate.JPG</figcaption><p></p>
</figure>
</div>
</section>
<section id="gcp-pre-requisites" class="level3">
<h3 class="anchored" data-anchor-id="gcp-pre-requisites">GCP Pre-requisites</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/95ddf7dc-cfb4-43c1-85b5-f97b8a50501a.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">gcp_create_project.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/bf3a068b-5fd2-4a9e-9813-e5e26364d40e.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">gcp_service_accounts.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/f02202e0-2d8d-4b97-94ac-56b7406fe11c.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">gcp_manage_keys.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/0399e4d0-b8e8-45bf-adac-7dd07d8e8563.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">gcp_add_key.JPG</figcaption><p></p>
</figure>
</div>
<p>This will download a key in <code>json</code> format</p>
</section>
<section id="cloud-sdk" class="level3">
<h3 class="anchored" data-anchor-id="cloud-sdk">Cloud SDK</h3>
<p><a href="https://cloud.google.com/sdk">Cloud SDK</a> provides language-specific Cloud Client Libraries supporting each language’s natural conventions and styles. This makes it easier for you to interact with Google Cloud APIs in your language of choice. Client libraries also handle authentication, reduce the amount of necessary boilerplate code, and provide helper functions for pagination of large datasets and asynchronous handling of long-running operations.</p>
<p>To check if we have it installed we can run the following prompt at the command line :</p>
<pre><code>gloud -v</code></pre>
<p>I did not have it so need to install:</p>
<p>https://cloud.google.com/sdk/docs/install-sdk#deb</p>
</section>
<section id="installation-of-gcloud-cli" class="level3">
<h3 class="anchored" data-anchor-id="installation-of-gcloud-cli">Installation of gcloud CLI</h3>
<ol type="1">
<li>Add the gcloud CLI distribution URI as a package source. If your distribution supports the signed-by option, run the following command:</li>
</ol>
<p>echo “deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main” | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list</p>
<ol start="2" type="1">
<li>Import the Google Cloud public key. If your distribution’s apt-key command supports the –keyring argument, run the following command:</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>curl https:<span class="op">//</span>packages.cloud.google.com<span class="op">/</span>apt<span class="op">/</span>doc<span class="op">/</span>apt<span class="op">-</span>key.gpg <span class="op">|</span> sudo apt<span class="op">-</span>key <span class="op">--</span>keyring <span class="op">/</span>usr<span class="op">/</span>share<span class="op">/</span>keyrings<span class="op">/</span>cloud.google.gpg add <span class="op">-</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="3" type="1">
<li>Update and install the gcloud CLI:</li>
</ol>
<p>sudo apt-get update &amp;&amp; sudo apt-get install google-cloud-cli</p>
<ol start="4" type="1">
<li><p>(Optional) Install any of the <a href="https://cloud.google.com/sdk/docs/components#additional_components">additional components</a>.</p></li>
<li><p>Run gcloud init to get started:</p></li>
</ol>
<p>gcloud init</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/a4cf6088-dcaa-46f0-a008-4c560808ae08.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">gcloud_init.JPG</figcaption><p></p>
</figure>
</div>
<ol start="6" type="1">
<li><p>Say yes to the above, and then in your browser, log in to your Google user account when prompted and click Allow to grant permission to access Google Cloud resources. Copy the verification code to the awaiting command line prompt</p></li>
<li><p>At the command prompt, select a Google Cloud project from the list of projects where you have Owner, Editor or Viewer permissions:</p></li>
<li><p>If you have the Compute Engine API enabled, gcloud init allows you to choose a default Compute Engine zone:</p></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/8b2d4359-f2b3-4610-af82-4350a4207064.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">compute_engine_api.JPG</figcaption><p></p>
</figure>
</div>
<ol start="9" type="1">
<li>(Optional) To improve the screen reader experience, enable the accessibility/screen_reader property:</li>
</ol>
<p>gcloud config set accessibility/screen_reader true</p>
<p>Now we need to export our key credentials from the json file at the command line:</p>
<p>export GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/<json_file_name>.json</json_file_name></p>
<p>Finally, refresh token/session, and verify authentication:</p>
<p>gcloud auth application-default login</p>
<p>Then need to login from the browser to Google account once again and <code>Allow</code> and then copy verification code to terminal:</p>
</section>
<section id="terraform" class="level3">
<h3 class="anchored" data-anchor-id="terraform">Terraform</h3>
<p><a href="https://www.terraform.io/">Terraform</a> is an open-source infrastructure-as-code software tool created by HashiCorp. Users define and provide data center infrastructure using a declarative configuration language known as HashiCorp Configuration Language, or optionally JSON.</p>
<p>https://learn.hashicorp.com/collections/terraform/gcp-get-started</p>
<p><a href="https://developer.hashicorp.com/terraform/downloads">Terraform</a> can be installed using the following command line prompts in Ubuntu:</p>
<p>wget -O- https://apt.releases.hashicorp.com/gpg | gpg –dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg</p>
<p>echo “deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main” | sudo tee /etc/apt/sources.list.d/hashicorp.list</p>
<p>sudo apt update &amp;&amp; sudo apt install terraform</p>
<p>We are now going to set up the following infrastructures within Google Cloud Platform (GCP):</p>
<pre><code>- Google Cloud Storage (GCS): (a bucket in GCP environment where you can store files) Data Lake - raw data in organised fashion 
- Big Query: Data Warehouse</code></pre>
<p>We need to grant two additional service permissions:</p>
<ul>
<li>Storage Admin (the bucket itself) and Storage Object Admin (the objects within the bucket)</li>
<li>BigQuery Admin</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/259ea342-2eb8-4348-a7f5-6cfede25831b.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">gcp_additional_permissions.JPG</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>In production there would be custom created access parameters, restricting access by certain people to certain files.</p>
</blockquote>
<p>We still require to enable the APIs:</p>
<p>https://console.cloud.google.com/apis/library/iam.googleapis.com</p>
<p>https://console.cloud.google.com/apis/library/iamcredentials.googleapis.com</p>
</section>
<section id="creating-gcp-inftastructure-with-terraform" class="level3">
<h3 class="anchored" data-anchor-id="creating-gcp-inftastructure-with-terraform">1.3.2 Creating GCP Inftastructure with Terraform</h3>
<p>Now that we have everything set up within GCP let’s initialize Terraform.</p>
<p>First we need a <code>main.tf</code> file:</p>
<p>terraform { required_version = “&gt;= 1.0” backend “local” {} # Can change from “local” to “gcs” (for google) or “s3” (for aws), if you would like to preserve your tf-state online required_providers { google = { source = “hashicorp/google” } } }</p>
<p>provider “google” { project = var.project region = var.region // credentials = file(var.credentials) # Use this if you do not want to set env-var GOOGLE_APPLICATION_CREDENTIALS }</p>
</section>
</section>
<section id="data-lake-bucket" class="level1">
<h1>Data Lake Bucket</h1>
</section>
<section id="ref-httpsregistry.terraform.ioprovidershashicorpgooglelatestdocsresourcesstorage_bucket" class="level1">
<h1>Ref: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/storage_bucket</h1>
<p>resource “google_storage_bucket” “data-lake-bucket” { name = “<span class="math inline">\({local.data_lake_bucket}_\)</span>{var.project}” # Concatenating DL bucket &amp; Project name for unique naming location = var.region</p>
<p># Optional, but recommended settings: storage_class = var.storage_class uniform_bucket_level_access = true</p>
<p>versioning { enabled = true }</p>
<p>lifecycle_rule { action { type = “Delete” } condition { age = 30 // days } }</p>
<p>force_destroy = true }</p>
</section>
<section id="dwh" class="level1">
<h1>DWH</h1>
</section>
<section id="ref-httpsregistry.terraform.ioprovidershashicorpgooglelatestdocsresourcesbigquery_dataset" class="level1">
<h1>Ref: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset</h1>
<p>resource “google_bigquery_dataset” “dataset” { dataset_id = var.BQ_DATASET project = var.project location = var.region</p>
<p>We also need a <code>variables.tf</code> file :</p>
<p>locals { data_lake_bucket = “dtc_data_lake” }</p>
<p>variable “project” { description = “Your GCP Project ID” }</p>
<p>variable “region” { description = “Region for GCP resources. Choose as per your location: https://cloud.google.com/about/locations” default = “europe-west6” type = string }</p>
<p>variable “storage_class” { description = “Storage class type for your bucket. Check official docs for more info.” default = “STANDARD” }</p>
<p>variable “BQ_DATASET” { description = “BigQuery Dataset that raw data (from GCS) will be written to” type = string default = “trips_data_all”</p>
<p>Once we have configured the above Terraform files, there are only a few execution commands which makes it very convenient to work with.</p>
<p>terraform init: - Initializes &amp; configures the backend, installs plugins/providers, &amp; checks out an existing configuration from a version control</p>
<p>terraform plan: - Matches/previews local changes against a remote state, and proposes an Execution Plan.</p>
<p>terraform apply: - Asks for approval to the proposed plan, and applies changes to cloud</p>
<p>!!!terraform destroy!!! - Removes your stack from the Cloud</p>
<p>Let’s initialize state file (.tfstate) from the command line using</p>
<pre><code>terraform init</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/8bdadddb-1b0c-478b-a208-3cca846821d1.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">terraform_init.JPG</figcaption><p></p>
</figure>
</div>
<p>Next, propose an execution plan using</p>
<pre><code>terraform plan</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/75619ae1-56b6-43ea-8e0e-afca74eccfbe.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">terraform_plan.JPG</figcaption><p></p>
</figure>
</div>
<p>We need to enter our GCP Project ID at the command prompt to progress.</p>
<p>Now let’s ask for approval to the proposed plan, and apply the changes to cloud using</p>
<pre><code>terraform apply</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/8c4cef93-f00e-4d87-8e9e-f2973035a20b.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">terraform apply.JPG</figcaption><p></p>
</figure>
</div>
<p>Once again, we need to enter our GCP Project ID at the command prompt to progress:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/42c9c978-9780-4a14-a2c9-d6f62c201858.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">terraform apply_2.JPG</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/f2cf590d-b5d3-40c2-8379-0962dc57370c.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">terraform_apply_complete.JPG</figcaption><p></p>
</figure>
</div>
<p>We’re all set! Let’s return to our GCP account and confirm that we do now have a <code>data lake</code> bucket :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/26dc2ea6-fe83-4dcc-9a6d-30353e6a3fa3.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">gcp_bucket.JPG</figcaption><p></p>
</figure>
</div>
<p>And also check that we have our Big Query :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Data_Eng_Week_1_files/figure-html/5c3ee2a8-f6e1-4879-a6e4-3ba96f614d4e.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">big_query.JPG</figcaption><p></p>
</figure>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>