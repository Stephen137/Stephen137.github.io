<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Stephen Barrie">
<meta name="dcterms.date" content="2023-05-12">

<title>Into the Unknown - Biomedical Image Analysis in Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Into the Unknown</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">Stephen Barrie</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Stephen137" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com/in/sjbarrie" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Biomedical Image Analysis in Python</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Numpy</div>
                <div class="quarto-category">SciPy</div>
                <div class="quarto-category">Image</div>
                <div class="quarto-category">Biomedical</div>
                <div class="quarto-category">Segmentation</div>
                <div class="quarto-category">DataCamp</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Stephen Barrie </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 12, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#biomedical-image-analysis-in-python" id="toc-biomedical-image-analysis-in-python" class="nav-link active" data-scroll-target="#biomedical-image-analysis-in-python">Biomedical Image Analysis in Python</a>
  <ul class="collapse">
  <li><a href="#exploration" id="toc-exploration" class="nav-link" data-scroll-target="#exploration">1. Exploration</a>
  <ul class="collapse">
  <li><a href="#image-data" id="toc-image-data" class="nav-link" data-scroll-target="#image-data">1.1 Image data</a></li>
  <li><a href="#n-dimensional-images" id="toc-n-dimensional-images" class="nav-link" data-scroll-target="#n-dimensional-images">1.2 N-dimensional images</a></li>
  <li><a href="#advanced-plotting" id="toc-advanced-plotting" class="nav-link" data-scroll-target="#advanced-plotting">1.3 Advanced plotting</a></li>
  </ul></li>
  <li><a href="#masks-and-filters" id="toc-masks-and-filters" class="nav-link" data-scroll-target="#masks-and-filters">2. Masks and Filters</a>
  <ul class="collapse">
  <li><a href="#masks" id="toc-masks" class="nav-link" data-scroll-target="#masks">2.2 Masks</a></li>
  <li><a href="#filters" id="toc-filters" class="nav-link" data-scroll-target="#filters">2.3 Filters</a></li>
  <li><a href="#feature-detection" id="toc-feature-detection" class="nav-link" data-scroll-target="#feature-detection">2.4 Feature detection</a></li>
  </ul></li>
  <li><a href="#measurement" id="toc-measurement" class="nav-link" data-scroll-target="#measurement">3. Measurement</a>
  <ul class="collapse">
  <li><a href="#objects-and-labels" id="toc-objects-and-labels" class="nav-link" data-scroll-target="#objects-and-labels">3.1 Objects and labels</a></li>
  <li><a href="#measuring-intensity" id="toc-measuring-intensity" class="nav-link" data-scroll-target="#measuring-intensity">3.2 Measuring intensity</a></li>
  <li><a href="#measuring-morphology" id="toc-measuring-morphology" class="nav-link" data-scroll-target="#measuring-morphology">3.3 Measuring morphology</a></li>
  <li><a href="#measuring-in-time" id="toc-measuring-in-time" class="nav-link" data-scroll-target="#measuring-in-time">3.4 Measuring in time</a></li>
  </ul></li>
  <li><a href="#image-comparison" id="toc-image-comparison" class="nav-link" data-scroll-target="#image-comparison">4. Image Comparison</a>
  <ul class="collapse">
  <li><a href="#spatial-transformations" id="toc-spatial-transformations" class="nav-link" data-scroll-target="#spatial-transformations">4.1 Spatial transformations</a></li>
  <li><a href="#resampling-and-interpolation" id="toc-resampling-and-interpolation" class="nav-link" data-scroll-target="#resampling-and-interpolation">4.2 Resampling and interpolation</a></li>
  <li><a href="#comparing-images" id="toc-comparing-images" class="nav-link" data-scroll-target="#comparing-images">4.3 Comparing images</a></li>
  <li><a href="#normalizing-measurements" id="toc-normalizing-measurements" class="nav-link" data-scroll-target="#normalizing-measurements">4.4 Normalizing measurements</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements">Acknowledgements</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="biomedical-image-analysis-in-python" class="level1">
<h1>Biomedical Image Analysis in Python</h1>
<p>Since the first x-ray in 1895, medical imaging technology has advanced clinical care and opened up new fields of scientific investigation. The amount of imaging data is exploding: there was estimated to be more than three and a half billion terabytes of it in the U.S. alone in 2020. This has created amazing opportunities for analysis: measuring organ shape and size; creating detailed reconstructions of anatomy; analyzing tissue composition; predicting pathology, and so much more. The complexity and variety of the data can make it an intimidating field to jump into.</p>
<p>Fortunately, there are fantastic tools and a wealth of resources to support you. In this blog, we’ll focus on several principles underlying biomedical image analysis. We’ll learn how to explore multidimensional arrays, emphasize important features using masks and filters, extract specific measurements from objects, and compare multiple images or patients. While this only scratches the surface of the field, it will give us a firm foundation for advanced concepts like classification and segmentation. Throughout, we’ll rely on packages in Python’s core scientific computing ecosystem: ImageIO, NumPy, SciPy, and matplotlib. Let’s dive in.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/10713a20-7352-4426-8b4c-ced8007d0ee0-1-4e98677a-92a0-47ff-bbe8-5925e377ef2e.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">overview.PNG</figcaption>
</figure>
</div>
<section id="exploration" class="level2">
<h2 class="anchored" data-anchor-id="exploration">1. Exploration</h2>
<p>Prepare to conquer the Nth dimension! In this section, we’ll learn how to load, build and navigate N-dimensional images using a CT image of the human chest. We’ll also leverage the useful ImageIO package and hone our NumPy and matplotlib skills.</p>
<section id="image-data" class="level3">
<h3 class="anchored" data-anchor-id="image-data">1.1 Image data</h3>
<section id="load-images" class="level4">
<h4 class="anchored" data-anchor-id="load-images">1.1.1 Load images</h4>
<p>To warm up, let’s load and plot a single image. We can read in images using the ImageIO package. Its <code>imread()</code> function will take a single file and load it as an image object. One useful feature of ImageIO is that it can read DICOM files, the standard format for human medical imaging. The data is read in as an image object, which is a type of NumPy array.</p>
<p>To access specific values from our image, we can slice out a single value or a range of index values along each dimension.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/5b4ed307-9cbe-444a-a5f7-68f500d8672f-1-a8720703-7dba-441b-8321-c95b233e7361.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">loading_images.PNG</figcaption>
</figure>
</div>
<p>In this section, we’ll work with sections of a <a href="https://en.wikipedia.org/wiki/CT_scan">computed tomography (CT) scan</a> from <a href="http://www.cancerimagingarchive.net/about-the-cancer-imaging-archive-tcia/">The Cancer Imaging Archive</a>. CT uses a rotating X-ray tube to create a 3D image of the target area. The actual content of the image depends on the instrument used: photographs measure visible light, x-ray and CT measure radiation absorbance, and MRI scanners measure magnetic fields.</p>
<p>To warm up, use the <a href="https://imageio.readthedocs.io/en/stable/">imageio</a> package to load a single <a href="https://www.dicomstandard.org/about">DICOM</a> image from the scan volume and check out a few of its attributes.</p>
<p>Let’s grab the dataset we’ll be working with :</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget https:<span class="op">//</span>assets.datacamp.com<span class="op">/</span>production<span class="op">/</span>repositories<span class="op">/</span><span class="dv">2085</span><span class="op">/</span>datasets<span class="op">/</span>f44726fefae841afd24ddf83c58f34722212e67a<span class="op">/</span>tcia<span class="op">-</span>chest<span class="op">-</span>ct<span class="op">-</span>sample.<span class="bu">zip</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--2023-05-10 09:44:28--  https://assets.datacamp.com/production/repositories/2085/datasets/f44726fefae841afd24ddf83c58f34722212e67a/tcia-chest-ct-sample.zip
Resolving assets.datacamp.com (assets.datacamp.com)... 172.64.153.58, 104.18.34.198
Connecting to assets.datacamp.com (assets.datacamp.com)|172.64.153.58|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1141220 (1.1M)
Saving to: ‘tcia-chest-ct-sample.zip’

tcia-chest-ct-sampl 100%[===================&gt;]   1.09M  --.-KB/s    in 0.09s   

2023-05-10 09:44:29 (11.5 MB/s) - ‘tcia-chest-ct-sample.zip’ saved [1141220/1141220]
</code></pre>
</div>
</div>
<p>and unzip it :</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip tcia<span class="op">-</span>chest<span class="op">-</span>ct<span class="op">-</span>sample.<span class="bu">zip</span> <span class="op">-</span>d Data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Archive:  tcia-chest-ct-sample.zip
  inflating: Data/chest-220.dcm      
  inflating: Data/chest-221.dcm      
  inflating: Data/chest-222.dcm      
  inflating: Data/chest-224.dcm      
  inflating: Data/chest-225.dcm      </code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install imageio</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install imageio</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Import ImageIO</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> imageio.v2 <span class="im">as</span> imageio</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load "chest-220.dcm"</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> imageio.imread(<span class="st">'Data/chest-220.dcm'</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Print image attributes</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Image type:'</span>, <span class="bu">type</span>(im))</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Shape of image array:'</span>, im.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: imageio in /home/stephen137/mambaforge/lib/python3.10/site-packages (2.22.0)
Requirement already satisfied: pillow&gt;=8.3.2 in /home/stephen137/mambaforge/lib/python3.10/site-packages (from imageio) (9.2.0)
Requirement already satisfied: numpy in /home/stephen137/mambaforge/lib/python3.10/site-packages (from imageio) (1.22.4)
Image type: &lt;class 'imageio.core.util.Array'&gt;
Shape of image array: (512, 512)</code></pre>
</div>
</div>
<p><code>imageio</code> is a versatile package. It can read in a variety of image data, including JPEG, PNG, and TIFF. But it’s especially useful for its ability to handle DICOM files.</p>
</section>
<section id="metadata" class="level4">
<h4 class="anchored" data-anchor-id="metadata">1.1.2 Metadata</h4>
<p>Images are always acquired in a specific context. This information is often referred to as metadata. ImageIO loads available metadata into a dictionary, accessible through the meta attribute. This is especially important for DICOM files, which contain a lot of patient and acquisition information. Since meta is a Python dictionary, you can access specific information by indexing it with one of the available keys. This file, for example, includes a modality field. You can also call the keys method to list all of the available metadata.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/016b4c3f-e23c-4a99-b559-2d8d0f02feac-1-3e80685e-b400-47e4-95ad-8c447e0cdf6d.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">metadata.PNG</figcaption>
</figure>
</div>
<p>ImageIO reads in data as Image objects. These are standard NumPy arrays with a dictionary of metadata.</p>
<p>Metadata can be quite rich in medical images and can include:</p>
<ul>
<li><strong>Patient demographics:</strong> name, age, sex, clinical information</li>
<li><strong>Acquisition information:</strong> image shape, sampling rates, data type, modality (such as X-Ray, CT or MRI)</li>
</ul>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the available metadata fields</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(im.meta.keys())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>odict_keys(['TransferSyntaxUID', 'SOPClassUID', 'SOPInstanceUID', 'StudyDate', 'SeriesDate', 'ContentDate', 'StudyTime', 'SeriesTime', 'ContentTime', 'Modality', 'Manufacturer', 'StudyDescription', 'SeriesDescription', 'PatientName', 'PatientID', 'PatientBirthDate', 'PatientSex', 'PatientWeight', 'StudyInstanceUID', 'SeriesInstanceUID', 'SeriesNumber', 'AcquisitionNumber', 'InstanceNumber', 'ImagePositionPatient', 'ImageOrientationPatient', 'SamplesPerPixel', 'Rows', 'Columns', 'PixelSpacing', 'BitsAllocated', 'BitsStored', 'HighBit', 'PixelRepresentation', 'RescaleIntercept', 'RescaleSlope', 'PixelData', 'shape', 'sampling'])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the available metadata</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(im.meta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dict([('TransferSyntaxUID', '1.2.840.10008.1.2'), ('SOPClassUID', '1.2.840.10008.5.1.4.1.1.2'), ('SOPInstanceUID', '1.3.6.1.4.1.14519.5.2.1.5168.1900.290866807370146801046392918286'), ('StudyDate', '20040529'), ('SeriesDate', '20040515'), ('ContentDate', '20040515'), ('StudyTime', '115208'), ('SeriesTime', '115254'), ('ContentTime', '115325'), ('Modality', 'CT'), ('Manufacturer', 'GE MEDICAL SYSTEMS'), ('StudyDescription', 'PET CT with registered MR'), ('SeriesDescription', 'CT IMAGES - RESEARCH'), ('PatientName', 'STS_007'), ('PatientID', 'STS_007'), ('PatientBirthDate', ''), ('PatientSex', 'F '), ('PatientWeight', 82.0), ('StudyInstanceUID', '1.3.6.1.4.1.14519.5.2.1.5168.1900.381397737790414481604846607090'), ('SeriesInstanceUID', '1.3.6.1.4.1.14519.5.2.1.5168.1900.315477836840324582280843038439'), ('SeriesNumber', 2), ('AcquisitionNumber', 1), ('InstanceNumber', 57), ('ImagePositionPatient', (-250.0, -250.0, -180.62)), ('ImageOrientationPatient', (1.0, 0.0, 0.0, 0.0, 1.0, 0.0)), ('SamplesPerPixel', 1), ('Rows', 512), ('Columns', 512), ('PixelSpacing', (0.976562, 0.976562)), ('BitsAllocated', 16), ('BitsStored', 16), ('HighBit', 15), ('PixelRepresentation', 0), ('RescaleIntercept', -1024.0), ('RescaleSlope', 1.0), ('PixelData', b'Data converted to numpy array, raw data removed to preserve memory'), ('shape', (512, 512)), ('sampling', (0.976562, 0.976562))])</code></pre>
</div>
</div>
<p>DICOM files have rich information related to patient and acquisition information, but other image formats can have helpful information as well.</p>
</section>
<section id="plot-images" class="level4">
<h4 class="anchored" data-anchor-id="plot-images">1.1.3 Plot images</h4>
<p>Visualization is fundamental to image analysis, and we’ll rely heavily on matplotlib and its <code>imshow()</code> function throughout this course. To draw a simple plot of a 2D image, first, import the PyPlot module from matplotlib. Next, call <code>pyplot.imshow()</code> and pass in the 2D image. If the image does not have color, add <code>cmap="gray"</code> to plot it in grayscale. Next, to reduce clutter, it’s common to turn off the axis ticks, labels, and frame with pyplot. axis <code>off</code>. Finally, call <code>show()</code> to render the image. And, voila: the inside of a human being.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/ce8cc5c7-9ad9-4736-a767-16a482e8300f-1-36277219-755d-4b2d-820d-0a82978e2984.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">plotting_images.PNG</figcaption>
</figure>
</div>
<p>Perhaps the most critical principle of image analysis is: look at our images!</p>
<p>Matplotlib’s <code>imshow()</code> function gives us a simple way to do this. Knowing a few simple arguments will help:</p>
<ul>
<li><code>cmap</code> controls the color mappings for each value. The “gray” colormap is common, but <a href="https://matplotlib.org/users/colormaps.html">many others are available</a>.</li>
<li><code>vmin</code> and <code>vmax</code> control the color contrast between values. Changing these can reduce the influence of extreme values.</li>
<li><code>plt.axis('off')</code> removes axis and tick labels from the image.</li>
</ul>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw the image in grayscale</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(im, cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Render the image</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We can set <code>vmin=-200</code> and <code>vmax=200</code> to increase the contrast (i.e., the distance between the brightest and darkest colors is smaller than before, and remove the axis ticks and labels.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw the image with greater contrast</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(im,cmap<span class="op">=</span><span class="st">"gray"</span>,vmin<span class="op">=-</span><span class="dv">200</span>, vmax<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove axis ticks and labels</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Render the image</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="n-dimensional-images" class="level3">
<h3 class="anchored" data-anchor-id="n-dimensional-images">1.2 N-dimensional images</h3>
<p>Now that we can load and plot two-dimensional images let’s discuss higher dimensional datasets.</p>
<p>Images come in all shapes and sizes. This makes them versatile, but also complex. A standard grayscale image is the simplest type: it’s an array that can be indexed by rows and columns.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/db790c40-c455-45c3-aa2b-e3866de95ece-1-0d898fa3-2790-43db-9fd2-f2914da77929.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">array_slicing.PNG</figcaption>
</figure>
</div>
<p>3D images cover a volume of space rather than just a single plane. This volumetric data is useful because it can better capture the complexities of the human body, but it can be difficult to visualize because it can’t be summarized in a single plot.</p>
<p>Color images are also three dimensional. RGB images, for example, have three color channels that, when rendered by matplotlib or other image viewers, express a wide range of colors.</p>
<p>Movies, or time series data, include a temporal dimension, showing how each element changes over time. Like the planar dimension for 3D volumes, the temporal dimension is put first by convention.</p>
<section id="stack-images" class="level4">
<h4 class="anchored" data-anchor-id="stack-images">1.2.1 Stack images</h4>
<p>Just as a 2D image is a stack of 1-dimensional vectors, 3D, 4D and even higher-dimensional images can be thought of as stacks of simpler ones. Let’s illustrate this by creating a 3D volume from a few 2D images. First, we’ll load ImageIO and NumPy. Then, we’ll read in three slices of a chest CT scan. Each of these slices is an array with 512-row elements by 512 column elements. Now, we can feed a list of these three images into NumPy’s stack() function to create a 3D volume. If we look at our new “vol” array, we see that it contains a third dimension with three elements along it, but the row and column dimensions are the same as before</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/99b3d6fd-f056-4772-b875-8928fddccc86-1-2b3092bb-1e92-4238-9ad3-7736376554bc.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">array_stacks.PNG</figcaption>
</figure>
</div>
<p>We will use NumPy’s <code>stack()</code> function to combine several 2D arrays into a 3D volume. By convention, volumetric data should be stacked along the first dimension (axis=0): vol [plane, row, col].</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in each 2D image</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>im1 <span class="op">=</span> imageio.imread(<span class="st">'Data/chest-220.dcm'</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>im2 <span class="op">=</span> imageio.imread(<span class="st">'Data/chest-221.dcm'</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>im3 <span class="op">=</span> imageio.imread(<span class="st">'Data/chest-222.dcm'</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Stack images into a volume</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>vol <span class="op">=</span> np.stack([im1,im2,im3], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Volume dimensions:'</span>, vol.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Volume dimensions: (3, 512, 512)</code></pre>
</div>
</div>
<p>For large volumes, we can use a for loop to quickly generate our image list.</p>
</section>
<section id="load-volumes" class="level4">
<h4 class="anchored" data-anchor-id="load-volumes">1.2.2 Load volumes</h4>
<p>ImageIO’s <code>volread()</code> function is capable of reading volumes directly from disk, whether your images are stored in their own folder, or if the dataset is already multi-dimensional. In this example, we have a folder named “chest data,” which contains 50 slices of a 3D volume. We simply have to pass the folder name to <code>volread()</code>, and it will assemble the volume for us. Since these are DICOM images, the function actually checks the available metadata to make sure that the images are placed in the correct order. Otherwise, it will default to alphabetical order. Displaying the shape attribute shows us that we have 50 images stacked together.</p>
<p>For illustrative purposes let’s read in an entire volume of brain data from the “Data” folder, which contains 5 DICOM images.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># specify directory and file pattern</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>foldername <span class="op">=</span> <span class="st">'Data'</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> <span class="st">'*.dcm'</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the "Data" directory</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>vol <span class="op">=</span> imageio.volread(foldername, pattern)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Print image attributes</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Available metadata:'</span>, vol.meta.keys())</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Shape of image array:'</span>, vol.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Reading DICOM (examining files): 1/6 files (16.7%6/6 files (100.0%)
  Found 1 correct series.
Reading DICOM (loading data): 5/5  (100.0%)
Available metadata: odict_keys(['TransferSyntaxUID', 'SOPClassUID', 'SOPInstanceUID', 'StudyDate', 'SeriesDate', 'ContentDate', 'StudyTime', 'SeriesTime', 'ContentTime', 'Modality', 'Manufacturer', 'StudyDescription', 'SeriesDescription', 'PatientName', 'PatientID', 'PatientBirthDate', 'PatientSex', 'PatientWeight', 'StudyInstanceUID', 'SeriesInstanceUID', 'SeriesNumber', 'AcquisitionNumber', 'InstanceNumber', 'ImagePositionPatient', 'ImageOrientationPatient', 'SamplesPerPixel', 'Rows', 'Columns', 'PixelSpacing', 'BitsAllocated', 'BitsStored', 'HighBit', 'PixelRepresentation', 'RescaleIntercept', 'RescaleSlope', 'PixelData', 'shape', 'sampling'])
Shape of image array: (5, 512, 512)</code></pre>
</div>
</div>
<p>Using <code>volread()</code> to load image volumes can be faster and more reliable than loading them in image-by-image. It also preserves image metadata where possible.</p>
</section>
<section id="field-of-view" class="level4">
<h4 class="anchored" data-anchor-id="field-of-view">1.2.3 Field of view</h4>
<p>When analyzing images, keep in mind that the data is only a representation of real, physical space. The information in our images is limited to the number of elements in it. This is known as the array shape in NumPy and is always available as an attribute. The amount of space covered by each element is the sampling rate, and it can vary along each dimension. For DICOM images, the sampling rate is usually encoded in the metadata. For other types of image formats, such as JPEG and PNG, you may need to find it elsewhere. The field of view is the total amount of space covered along each axis. It is the product of the shape and sampling rate. Understanding the difference between these concepts is important, and we’ll return to it throughout this blog.</p>
<p>The amount of physical space covered by an image is its <strong>field of view</strong>, which is calculated from two properties:</p>
<ul>
<li><strong>Array shape,</strong> the number of data elements on each axis. Can be accessed with the shape attribute.</li>
<li><strong>Sampling resolution,</strong> the amount of physical space covered by each pixel (mm). Sometimes available in metadata (e.g., meta[‘sampling’]).</li>
</ul>
<p>Let’s have a go at calculating the <code>field of view</code> for our volume.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>vol.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>(5, 512, 512)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>vol.meta[<span class="st">'sampling'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>(3.269999999999996, 0.976562, 0.976562)</code></pre>
</div>
</div>
<p>Multiply the array shape and sampling resolution along each axis</p>
<pre><code>(5 x 3.269999999999996, 512 x 0.976562, 512 x 0.976562)</code></pre>
<p>which gives (16.35, 500, 500)</p>
</section>
</section>
<section id="advanced-plotting" class="level3">
<h3 class="anchored" data-anchor-id="advanced-plotting">1.3 Advanced plotting</h3>
<p>Efficiently and comprehensively visualizing your data is key to successful image analysis.</p>
<p><code>To plot N-dimensional data slice it!</code><br>
Consider this loaf of bread - it’s a 3D volume that looks absolutely delicious. But what’s inside the loaf? Is it bananas? Blueberries? Walnuts? This single 2D image cannot answer the question. Instead, you would have to slice it up and look at those pieces individually. The concept for 3D images is exactly the same: to explore your multidimensional array you must visualize many simpler slices of it.</p>
<section id="generate-subplots" class="level4">
<h4 class="anchored" data-anchor-id="generate-subplots">1.3.1 Generate subplots</h4>
<p>It’s inefficient to plot each of these slices one by one. A better way is to display many at once. To do this, we’ll leverage PyPlot’s <code>subplots()</code> function, which creates a grid of axis objects based on the number of rows and columns you specify. When you call <code>pyplot.subplots()</code>, it returns a figure object and an array of axis handles. In this case, the axes array has a shape of one by three. To draw images on each subplot, we will call the <code>imshow()</code> function directly from the axis object, rather than calling it through PyPlot. Here, we’re plotting the first slice of vol with a gray colormap. After the first slice is drawn, repeat the process for the other slices. Finally, we can clean up and render the figure. Just like before, we want to turn off the ticks and labels by calling the axis() method. However, since we will do the same thing to each subplot, a for loop is more efficient than writing down each command. If you had many images to draw, you could insert the drawing step into a for loop as well. Finally, we render the image using <code>pyplot.show()</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/585793b8-48df-423f-8710-0d004fcae56f-1-f8d78f85-64b8-41fb-aa00-53a3c39ffc3c.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">subplots.PNG</figcaption>
</figure>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize figure and axes grid</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, ncols<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw an image on each subplot</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im1, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(im2, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove ticks/labels and render</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>For even more rapid visualization, we can use a large number of subplots and loop through our axes and images.</p>
</section>
<section id="slice-3d-images" class="level4">
<h4 class="anchored" data-anchor-id="slice-3d-images">1.3.2 Slice 3D images</h4>
<p>The simplest way to plot 3D and 4D images by slicing them into many 2D frames. Plotting many slices sequentially can create a “fly-through” effect that helps you understand the image as a whole.</p>
<p>To select a 2D frame, pick a frame for the first axis and select all data from the remaining two: vol[0, :, :]</p>
<p>For this illustration, let’s use a for loop to plot every 2nd slice of <code>vol</code> on a separate subplot.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print image attributes</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Available metadata:'</span>, vol.meta.keys())</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Shape of image array:'</span>, vol.shape)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the images on a subplots array </span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through subplots and draw image</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ii <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    im <span class="op">=</span> vol[ii<span class="op">*</span><span class="dv">2</span>, :, :]</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    axes[ii].imshow(im, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    axes[ii].axis(<span class="st">'off'</span>)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Render the figure</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Available metadata: odict_keys(['TransferSyntaxUID', 'SOPClassUID', 'SOPInstanceUID', 'StudyDate', 'SeriesDate', 'ContentDate', 'StudyTime', 'SeriesTime', 'ContentTime', 'Modality', 'Manufacturer', 'StudyDescription', 'SeriesDescription', 'PatientName', 'PatientID', 'PatientBirthDate', 'PatientSex', 'PatientWeight', 'StudyInstanceUID', 'SeriesInstanceUID', 'SeriesNumber', 'AcquisitionNumber', 'InstanceNumber', 'ImagePositionPatient', 'ImageOrientationPatient', 'SamplesPerPixel', 'Rows', 'Columns', 'PixelSpacing', 'BitsAllocated', 'BitsStored', 'HighBit', 'PixelRepresentation', 'RescaleIntercept', 'RescaleSlope', 'PixelData', 'shape', 'sampling'])
Shape of image array: (5, 512, 512)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-15-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>When selecting frames, any trailing <code>:</code> symbols are implicitly selected. For example, vol[5] is the same as vol[5,:,:]. We will follow this simpler convention moving forward.</p>
</section>
<section id="plot-other-views" class="level4">
<h4 class="anchored" data-anchor-id="plot-other-views">1.3.3 Plot other views</h4>
<p>There are actually multiple ways you can slice a 3D volume into 2D images. The simplest way is to choose a frame along the first dimension and plot the second and third against each other.</p>
<p>If you instead selected a slice along the row dimension, you would get a second perspective. In this case, we are plotting head-to-toe versus left-to-right.</p>
<p>Finally, you could plot the first and second axes against each other, yielding a third view. When looking at human anatomy, these different views or <code>planes</code> have special names: - axial - coronal - sagittal</p>
<p>Knowing in which plane a dataset is stacked can help you navigate more efficiently.</p>
<p>Any two dimensions of an array can form an image, and slicing along different axes can provide a useful perspective. However, unequal sampling rates can create distorted images.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/9ca87b8c-27b2-457f-a8bb-5f873560d2b7-1-31c1c639-a8b8-410f-ab2a-db5777fae55b.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">distorted.PNG</figcaption>
</figure>
</div>
<p>Many datasets do not have equal sampling rates across all dimensions. In these cases, you will want to stretch the pixels along one side to account for the differences. The amount of stretching needed is determined by the aspect ratio. Here we’ve decided to plot a slice with data from the first and second dimensions. To determine the aspect ratio, we first get the sampling rates along each dimension from the metadata dictionary. Then, we divide the sampling rate of the first dimension by the sampling rate of the second. When we call imshow(), we pass this ratio to the aspect argument.</p>
<p>This results in a properly proportioned image. Failing to adjust the aspect would have resulted in a distorted image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/05f3322b-ecab-41e6-8261-e4fd06795aa2-1-e3714c9c-a6ec-4030-858b-bf154cb8ce70.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">aspect_ratio.PNG</figcaption>
</figure>
</div>
<p>To illustrate this, let’s plot images that slice along the second and third dimensions of <code>vol</code>, and explicitly set the aspect ratio to generate undistorted images.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>vol.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(5, 512, 512)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select frame from "vol"</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>im1 <span class="op">=</span> vol[:, <span class="dv">256</span>, :]</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>im2 <span class="op">=</span> vol[:, :, <span class="dv">256</span>]</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute aspect ratios</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>d0, d1, d2 <span class="op">=</span> vol.meta[<span class="st">'sampling'</span>]</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>asp1 <span class="op">=</span> d0 <span class="op">/</span> d2</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>asp2 <span class="op">=</span> d0 <span class="op">/</span> d1</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the images on a subplots array </span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, ncols<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im1, cmap<span class="op">=</span><span class="st">'gray'</span>, aspect<span class="op">=</span>asp1)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(im2, cmap<span class="op">=</span><span class="st">'gray'</span>, aspect<span class="op">=</span>asp2)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Next, we’ll begin to manipulate images and extract salient features from them.</p>
</section>
</section>
</section>
<section id="masks-and-filters" class="level2">
<h2 class="anchored" data-anchor-id="masks-and-filters">2. Masks and Filters</h2>
<p>In this section, we’ll discuss masks and filters, two techniques that emphasize important features in images. To leverage them well, we must have a thorough understanding of your data’s distribution of intensity values.</p>
<section id="intensity" class="level4">
<h4 class="anchored" data-anchor-id="intensity">2.1.1 Intensity</h4>
<p>In this section, we will work with a hand radiograph from a 2017 Radiological Society of North America competition. X-ray absorption is highest in dense tissue such as bone, so the resulting intensities should be high. Consequently, images like this can be used to predict “bone age” in children.</p>
<p><code>Pixels and voxels</code><br>
The building blocks of medical images are pixels and voxels. Each of these elements has two properties: an intensity value and a location in space. The meaning of the intensity value depends on the imaging modality. For example, pixels in this x-ray image, or radiograph, are brighter in dense tissue such as bone, because it absorbs more radiation than other types.</p>
<p><code>Data types and image size</code><br>
The range of values allowed in an image is determined by its data type. Generally, lower-bit integers are preferred for images, since memory usage increases dramatically for larger data types. If all values in the image are positive, then unsigned integers can cover the widest range of values while taking up the least amount of memory. You will commonly see images scaled by the value 255, which is the maximum value for 8-bit unsigned integers. You can see the difference in memory usage by calling the size attribute of the array. The foot x-ray we just saw is read by ImageIO as an 8-bit unsigned integer. It takes up about 153 kB. If we convert it to a 64-bit integer, however, the same information now takes up more than a megabyte of space.</p>
<p>To start, let’s load the image and check its intensity range.</p>
<p>The image datatype determines the range of possible intensities: e.g., 8-bit unsigned integers (uint8) can take values in the range of 0 to 255. A colorbar can be helpful for connecting these values to the visualized image.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># custom function</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_and_render_plot():</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Custom function to simplify common formatting operations for exercises. Operations include: </span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Turning off axis grids.</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Calling `plt.tight_layout` to improve subplot spacing.</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Calling `plt.show()` to render plot.'''</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.gcf()</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ax <span class="kw">in</span> fig.axes:</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">'off'</span>)    </span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the hand radiograph</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> imageio.imread(<span class="st">'Data/hand.png'</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Data type:'</span>, im.dtype)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Min. value:'</span>, im.<span class="bu">min</span>())</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Max value:'</span>, im.<span class="bu">max</span>())</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the tick interval</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.ticker <span class="im">as</span> ticker</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>min_val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>max_val <span class="op">=</span> np.<span class="bu">max</span>(im)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>tick_interval <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>tick_vals <span class="op">=</span> np.arange(min_val, max_val <span class="op">+</span> tick_interval, tick_interval)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the grayscale image</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>plt.imshow(im, vmin<span class="op">=</span><span class="dv">0</span>, vmax <span class="op">=</span> <span class="dv">255</span>, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>colorbar <span class="op">=</span> plt.colorbar()</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>colorbar.set_ticks(tick_vals)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data type: uint8
Min. value: 3
Max value: 224</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-19-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Although only a crude descriptor, the range of intensities can help you get a quick feel for your image’s content.</p>
</section>
<section id="histograms" class="level4">
<h4 class="anchored" data-anchor-id="histograms">2.1.2 Histograms</h4>
<p>Histograms summarize the distribution of intensity values in an image. They bin each pixel by its value and then count each bin. SciPy, and especially its Ndimage module, contain some essential tools for image analysis. We’ll dig deeper into SciPy throughout this blog. To generate a histogram for the foot x-ray, we first import <a href="https://docs.scipy.org/doc/scipy/reference/ndimage.html">SciPy’s Ndimage module</a> as ndi. Then, we call <code>ndimage.histogram()</code> and pass in our array. The <code>histogram()</code> function requires us to specify values for the minimum, maximum, and the number of bins. Since our image is an 8-bit unsigned integer, our range is from 0 to 255, with 256 possible values. This returns a 256 element vector with the count of pixels at each intensity value. Plotting the data as a line plot reveals a highly skewed distribution, with many low values and a wider range of high values.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/b0835649-370a-459d-ba54-220a90288383-1-e0d8c3b6-22ce-496a-98db-f592e236886d.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">histograms.PNG</figcaption>
</figure>
</div>
<p><code>Equalization</code><br>
Skewed distributions are common in medical images: background intensities are usually low and take up a lot of image space. There are ways to modify the intensity distribution. For example, histogram equalization redistributes values based on their abundance in the image. We can perform equalization with the aid of the cumulative distribution function, which shows the proportion of pixels that fall within a given range. Here, we can see that about half the pixels have values less than 32. To equalize the image, we could redistribute these intensity values until they are more evenly represented.</p>
<p>Equalizing the histogram is actually pretty straightforward. First, we generate the histogram. Then, we calculate the cumulative distribution function by taking the rolling sum of the histogram and dividing it by the total number of pixels. Then, we apply the function to our image and rescale by 255. Plotting the original and equalized image shows that we have increased the pixel intensities for several areas. This has made our foot stand out more clearly, but it has also given extra weight to some background areas. For biomedical applications, global equalization, such as this, should be done with caution, but the principle of redistributing intensity values is a useful one to keep in mind.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/2f17816e-f7a9-4c70-b719-92caddd75aa1-2-e3c474cd-c518-4f44-92c6-77d4048b4f5b.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">equalization.PNG</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/2f17816e-f7a9-4c70-b719-92caddd75aa1-1-9ccaf76a-18ac-422a-b54d-6c68f49e88ac.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">equalization_result.PNG</figcaption>
</figure>
</div>
<p>The area under a histogram is called the cumulative distribution function. It measures the frequency with which a given range of pixel intensities occurs.</p>
<p>To illustrate, let’s describe the intensity distribution in <code>im</code> by calculating the histogram and cumulative distribution function and displaying them together.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># custom functiob</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_and_render_plot():</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Custom function to simplify common formatting operations for exercises. Operations include: </span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Turning off axis grids.</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Calling `plt.tight_layout` to improve subplot spacing.</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Calling `plt.show()` to render plot.'''</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.gcf()</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ax <span class="kw">in</span> fig.axes:</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>        ax.legend(loc<span class="op">=</span><span class="st">'center right'</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Import SciPy's "ndimage" module</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.ndimage <span class="im">as</span> ndi </span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a histogram, binned at each possible value</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> ndi.histogram(im, <span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">255</span>, bins<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a cumulative distribution function</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>cdf <span class="op">=</span> hist.cumsum() <span class="op">/</span> hist.<span class="bu">sum</span>()</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the histogram and CDF</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(hist, label<span class="op">=</span><span class="st">'Histogram'</span>)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(cdf, label<span class="op">=</span><span class="st">'CDF'</span>)</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We can see the data is clumped into a few separate distributions, consisting of background noise, skin, bone, and artifacts. Sometimes we can separate these well with global thresholds (foreground/background); other times the distributions overlap quite a bit (skin/bone).</p>
</section>
<section id="masks" class="level3">
<h3 class="anchored" data-anchor-id="masks">2.2 Masks</h3>
<p>We can restrict our analysis to only the most important parts of an image by creating and applying image masks.</p>
<p>A mask is a Boolean array which serves as a screen to remove undesirable pixels. Masks must retain the same dimensions as the original image so that the two can be overlaid.</p>
<p><code>Creating masks</code> One way to create masks is to find all pixels in an image that satisfy a certain condition. For example, let’s create a three by three array of ascending values. If we test for values greater than 5, we will return a three by three array where the values are True when they greater than 5, and False when they are less. Logical operations include comparisons and tests of equivalence. We can also chain operations together to select a specific range of pixels.</p>
<p>Let’s look at this in action. Recall that the foot x-ray we have been working with has an intensity distribution like this. We see that there is a steep drop-off around 32, so let’s select values greater than this. This seems to do quite a good job highlighting the foot.</p>
<p>Bone is the highest intensity tissue in an x-ray, and if we increase our threshold to 64, we create a rough bone mask. Finally, we can create a mask of non-bone tissue by finding pixels that are in mask 1 and not in mask 2. The selected pixels are in the foot but are not part of the bone. They seem to be related to skin and other tissue.</p>
<p><code>Applying masks</code> Masks can be used to screen images, allowing the original values through except where the mask evaluates to False. NumPy’s where() function is useful for this purpose. where() applies a condition on each pixel, and instead of returning a Boolean, it returns x when True and y when False. Each of the arguments can be either arrays or single values, allowing for great flexibility. To see this in action, first import NumPy. Let’s try to filter out pixels that are not part of the bone. We’ll call “where im is greater than 64, return im, otherwise return 0”. Plotting the masked image shows that only the high-intensity values remain, and these are mostly bone.</p>
<p><code>Tuning masks</code> Data is noisy, so your masks will rarely be perfect. Fortunately, there are simple ways to improve them. To increase the size of your mask, you can add pixels around the edges, a process known as dilation. This can help when the edges are fuzzy or to make sure you don’t accidentally mask out pixels you actually care about. To do this, we call the binary_dilation() function, which converts all background pixels adjacent to the mask into mask pixels.</p>
<p>The opposite operation, “binary erosion” can be implemented in the same manner. Use it to cut the mask down to its more central pixels. You can perform these tuning operations many iterations to make your mask much larger or smaller. You can also combine the operations to open or close holes in your mask.</p>
<p>Masks are the primary method for removing or selecting specific parts of an image. They are binary arrays that indicate whether a value should be included in an analysis. Typically, masks are created by applying one or more logical operations to an image.</p>
<p>To illustrate, we will try to use a simple intensity threshold to differentiate between skin and bone in the hand radiograph.</p>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using loadtxt()</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>im_equalized <span class="op">=</span> np.loadtxt(<span class="st">"Data/hand_equalized.csv"</span>,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>                 delimiter<span class="op">=</span><span class="st">","</span>, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>display(im_equalized)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>array([[18., 18., 18., ..., 32., 32., 32.],
       [18., 18., 18., ..., 32., 32., 32.],
       [18., 18., 18., ..., 32., 32., 32.],
       ...,
       [17., 17., 17., ..., 21., 20., 19.],
       [16., 16., 16., ..., 21., 20., 19.],
       [16., 16., 16., ..., 21., 20., 19.]])</code></pre>
</div>
</div>
<section id="create-a-mask" class="level4">
<h4 class="anchored" data-anchor-id="create-a-mask">2.2.1 Create a mask</h4>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_and_render_plot():</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Custom function to simplify common formatting operations for exercises. Operations include: </span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Turning off axis grids.</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Calling `plt.tight_layout` to improve subplot spacing.</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Calling `plt.show()` to render plot.'''</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.gcf()</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ax <span class="kw">in</span> fig.axes:</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">'off'</span>)    </span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create skin and bone masks</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>mask_skin <span class="op">=</span> (im_equalized <span class="op">&gt;=</span> <span class="dv">45</span>) <span class="op">&amp;</span> (im_equalized <span class="op">&lt;</span> <span class="dv">145</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>mask_bone <span class="op">=</span> im_equalized <span class="op">&gt;=</span><span class="dv">145</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the skin (0) and bone (1) masks</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(mask_skin, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(mask_bone, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>It’s possible to chain logic together to make some quite complex masks.</p>
</section>
<section id="apply-a-mask" class="level4">
<h4 class="anchored" data-anchor-id="apply-a-mask">2.2.2 Apply a mask</h4>
<p>Although masks are binary, they can be applied to images to filter out pixels where the mask is False.</p>
<p>NumPy’s <code>where()</code> function is a flexible way of applying masks. It takes three arguments:</p>
<pre><code>np.where(condition, x, y)</code></pre>
<p>condition, x and y can be either arrays or single values. This allows you to pass through original image values while setting masked values to 0.</p>
<p>Let’s practice applying masks by selecting the bone-like pixels from the hand x-ray.</p>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># custom function</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_and_render_plot():</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Custom function to simplify common formatting operations for exercises. Operations include: </span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Turning off axis grids.</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Calling `plt.tight_layout` to improve subplot spacing.</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Calling `plt.show()` to render plot.'''</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.gcf()</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    fig.axes[<span class="dv">0</span>].axis(<span class="st">'off'</span>)   </span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Screen out non-bone pixels from "im"</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>mask_bone <span class="op">=</span> im_equalized <span class="op">&gt;=</span> <span class="dv">145</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>im_bone <span class="op">=</span> np.where(mask_bone, im_equalized, <span class="dv">0</span>)</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the histogram of bone intensities</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> ndi.histogram(im_bone, <span class="bu">min</span><span class="op">=</span><span class="dv">1</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">255</span>, bins<span class="op">=</span><span class="dv">255</span>)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot masked image and histogram</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im_bone, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(hist)</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Sometimes simpler methods for applying a mask such as multiplication (e.g., im * mask_bone) will meet your needs, but <code>np.where()</code> is an excellent tool to have in your arsenal.</p>
</section>
<section id="tune-a-mask" class="level4">
<h4 class="anchored" data-anchor-id="tune-a-mask">2.2.3 Tune a Mask</h4>
<p>Imperfect masks can be tuned through the addition and subtraction of pixels. SciPy includes several useful methods for accomplishing these ends. These include:</p>
<ul>
<li>binary_dilation: Add pixels along edges</li>
<li>binary_erosion: Remove pixels along edges</li>
<li>binary_opening: Erode then dilate, “opening” areas near edges</li>
<li>binary_closing: Dilate then erode, “filling in” holes</li>
</ul>
<p>To illustrate, we will create a bone mask then tune it to include additional pixels.</p>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and tune bone mask</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>mask_bone <span class="op">=</span> im_equalized <span class="op">&gt;=</span> <span class="dv">145</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>mask_dilate <span class="op">=</span> ndi.binary_dilation(mask_bone, iterations<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>mask_closed <span class="op">=</span> ndi.binary_closing(mask_bone, iterations<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot masked images</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(mask_bone, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(mask_dilate, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].imshow(mask_closed, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Dilation, erosion, and closing are useful techniques when you want to fine-tune your masks.</p>
</section>
</section>
<section id="filters" class="level3">
<h3 class="anchored" data-anchor-id="filters">2.3 Filters</h3>
<p>So far, we have only considered the images as a whole. However, we can combine intensity and spatial information by employing convolutional filters.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/aecafd93-1556-4af9-961e-e923834bed23-1-abdd4451-bef9-4a2a-a9e0-6b9bcf0bebec.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">filters.PNG</figcaption>
</figure>
</div>
<p><code>Filters</code><br>
Two common examples of filtering are <code>sharpening</code> and <code>smoothing</code>.</p>
<ul>
<li><p><code>Sharpening</code> sharp changes are enhanced, exaggerating the differences between pixels.</p></li>
<li><p><code>Smoothing</code> emphasizes large intensity patterns in an image by reducing variability between neighboring pixels. Essentially, it suppresses noise by blurring the image.</p></li>
</ul>
<p>Let’s look more closely at how this is accomplished.</p>
<section id="filter-convolutions" class="level4">
<h4 class="anchored" data-anchor-id="filter-convolutions">2.3.1 Filter convolutions</h4>
<p><code>Convolution with a sharpening filter</code></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/873d2554-43b0-41f9-9948-b189d1eabc27-1-45aa09e5-4a05-4ec1-a6e1-c14ed3d13530.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">sharpening.PNG</figcaption>
</figure>
</div>
<p>Here we have a five by five input array, where all the values are one except for the center value of 2. To get a sharpened value for the center pixel, we would first define a set of filter weights, also called a kernel. Then, we would select a window of input data of the same size as our kernel. In this case, the filter will highly weight the center pixel and down-weight the adjacent pixels.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/873d2554-43b0-41f9-9948-b189d1eabc27-3-8b0e911f-433a-4ce3-9ba5-43558d46040e.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">sharpening_result.PNG</figcaption>
</figure>
</div>
<p>To perform convolution, we multiply these two matrices element-wise, and then we sum them up. In the top-left corner, we have an input value of 1 times a weight of 0, an input value of 1 times a weight of negative 1, and so on. We then sum all these products to get a new, sharpened value for the center pixel of our input image. In this case, it’s been increased from two to six.</p>
<p>Let’s see how this works on a full-size image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/873d2554-43b0-41f9-9948-b189d1eabc27-2-7fcafb61-9970-459f-ae3c-d15d10e75175.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">CNN.PNG</figcaption>
</figure>
</div>
<p>On the left is a random 2D array; on the right, we have an empty output image that we will create. In between is the sharpening <code>kernel</code>.</p>
<p>Starting from the top-left corner of the input image, we select the values surrounding the origin pixel. We then multiply each element in this selection by the kernel weights and add them together to get the filtered value. We take one step over to the next element, multiply the input window by the kernel, and repeat the process for each pixel in the image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/873d2554-43b0-41f9-9948-b189d1eabc27-4-ab433b22-fd4b-4bad-bb52-33fcda4f1da6.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">kernel.PNG</figcaption>
</figure>
</div>
<p>This results, in this case, in a sharpened image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/873d2554-43b0-41f9-9948-b189d1eabc27-5-ebd1a9d0-5599-4460-bd8d-4956f731a47d.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">sharpened.PNG</figcaption>
</figure>
</div>
<p><code>Image convolution</code><br>
We can apply custom filters using the <code>convolve() function</code>. First, we import packages and load the foot x-ray. Next, we create the kernel. In this case, let’s average the center pixel with its neighbors to smooth out variability between pixels. After filtering, the major patterns will remain, but subtle variation between pixels will be dampened. Next, we call <code>ndimage.convolve()</code> and pass in the image and weights. This produces a smoothed output image of the same size as our input.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/2a6980f8-899d-43e1-bbd3-33b4586c6d17-1-a3866bdc-18a6-4cd1-b464-d67c93e5bd55.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image_convolution.PNG</figcaption>
</figure>
</div>
<p>To illustrate filter convolutions, let’s smooth the hand radiograph. First, specify the weights to be used. (These are called “footprints” and “kernels” as well.) Then, convolve the filter with im and plot the result.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> imageio.v2 <span class="im">as</span> imageio</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.ndimage <span class="im">as</span> ndi </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> imageio.imread(<span class="st">'Data/hand.png'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a three by three array of filter weights</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set each element to 0.11 to perform mean filtering (also called "uniform filtering")</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> [[<span class="fl">0.11</span>, <span class="fl">0.11</span>, <span class="fl">0.11</span>],</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>           [<span class="fl">0.11</span>, <span class="fl">0.11</span>, <span class="fl">0.11</span>], </span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>           [<span class="fl">0.11</span>, <span class="fl">0.11</span>, <span class="fl">0.11</span>]]</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Convolve the image with the filter</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>im_filt <span class="op">=</span> ndi.convolve(im, weights)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the images</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(im_filt, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The size and pattern of the filter weights control the effect it will have on our image.</p>
</section>
<section id="filter-functions" class="level4">
<h4 class="anchored" data-anchor-id="filter-functions">2.3.2 Filter functions</h4>
<p>Filtering can also employ <code>functions</code> other than convolutional kernels, such as the <code>mean</code>, <code>median</code>, and <code>maximum</code>. SciPy has several of these functions built-in. Filter kernels do not have to be 3 x 3; they can be as large as you want. Here, we apply a 10 x 10 median filter to the foot image. You can see it does quite a nice job of smoothing out the variations in intensity.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/07de78ea-df5e-4876-bbaf-4f3935582c84-1-853290c9-5274-4fa9-a0cc-d989a2d50b82.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">filtering_functions.PNG</figcaption>
</figure>
</div>
<p>The median filter will return the median value of the 3x3 neighborhood. Note that the values on the edges will vary based on the mode setting of your filter.</p>
</section>
<section id="smoothing" class="level4">
<h4 class="anchored" data-anchor-id="smoothing">2.3.3 Smoothing</h4>
<p><code>Gaussian filtering</code><br>
The Gaussian filter is useful for smoothing data across larger areas. It blurs activation based on a Gaussian, or normal, distribution around the filtered pixel. Basically, the filter weights dissipate in a circular pattern as you get further from the center. The width of the distribution is controlled by the <code>sigma</code> parameter. Applying a Gaussian filter can be a great way to reduce noise, but with very large sigma values, you’ll lose a lot of detail in your image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/e29e0f25-2127-4d63-93fb-977657f464df-1-1eeca773-4bb5-4583-87ce-097759fb64b6.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">gaussian.PNG</figcaption>
</figure>
</div>
<p>Let’s illustrate the effects of applying Gaussian filters to the foot x-ray before creating a bone mask.</p>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Smooth "im" with Gaussian filters</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>im_s1 <span class="op">=</span> ndi.gaussian_filter(im_equalized, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>im_s3 <span class="op">=</span> ndi.gaussian_filter(im_equalized, sigma<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw bone masks of each image</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im_equalized <span class="op">&gt;=</span> <span class="dv">145</span>, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(im_s1 <span class="op">&gt;=</span> <span class="dv">145</span>, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].imshow(im_s3 <span class="op">&gt;=</span> <span class="dv">145</span>, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Many analyses can benefit from an initial smoothing of the data.</p>
</section>
</section>
<section id="feature-detection" class="level3">
<h3 class="anchored" data-anchor-id="feature-detection">2.4 Feature detection</h3>
<p>Filters aren’t just useful for blurring and smoothing. They can also be used as detectors for features of interest, such as edges.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/bacc5904-e375-4379-84e1-9f209ed84260-1-76294b86-071b-4a85-b6a7-049e1f248152.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">edge_detector_kernel.PNG</figcaption>
</figure>
</div>
<p>If we want to construct a filter kernel that will emphasize edges, what should it look like?</p>
<p>Recall that when we perform convolution, it creates a new image that reflects what the filter looks like: a smoothing filter itself has a smooth gradient, whereas a sharpening filter has a sudden change in intensity. An edge is a change in intensity along an axis. Sharp edges, for example, between the skull and background in this MRI image, have very high contrast. The filter should reflect this.</p>
<section id="detect-edges" class="level4">
<h4 class="anchored" data-anchor-id="detect-edges">2.4.1 Detect edges</h4>
<p>Let’s see if we can make this work. We start by loading the foot x-ray. Next, we construct our kernel: to look for areas that have a change in intensity from top to bottom. We can weight the top row to positive 1 and the bottom row to negative 1.</p>
<p>Essentially, this filter calculates the difference between the top and bottom rows, returning values far from 0 when there is a sudden change in intensity. Then, we convolve the image with the filter using SciPy.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/5c28e30d-f392-4c1c-ae6d-5e69c78e1102-1-c0b9b670-202a-4c65-90ed-d6172fa2e4b0.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">edge_detector_convolution.PNG</figcaption>
</figure>
</div>
<p>Plotting the image, it’s clear that our detector has done a fine job of highlighting some edges. But note two things:</p>
<ol type="1">
<li><p>This is a horizontal edge detector because it is looking for differences between the top and bottom values at each point. If you look at the vertical edges in the filtered image, you’ll see that they have relatively low values compared to the top and bottom of the foot.</p></li>
<li><p>There are both positive and negative values. This happens because some edges have high-intensity values on top and low values on bottom, whereas others have the opposite. The direction of this difference determines whether the convolution yields a positive or negative value.</p></li>
</ol>
<p>To illustrate, let’s create a <code>vertical</code> edge detector and see how well it performs on the hand x-ray (im).</p>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_and_render_plot():</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Custom function to simplify common formatting operations for exercises. Operations include: </span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Turning off axis grids.</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Calling `plt.tight_layout` to improve subplot spacing.</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Calling `plt.show()` to render plot.'''</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.gcf()</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ax <span class="kw">in</span> fig.axes:</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">'off'</span>)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set weights to detect vertical edges</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> [[<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>], [<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>], [<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>]]</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convolve "im" with filter weights</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>edges <span class="op">=</span> ndi.convolve(im_equalized, weights)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw the image in color</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>plt.imshow(edges, cmap<span class="op">=</span><span class="st">'seismic'</span>, vmin<span class="op">=-</span><span class="dv">150</span>, vmax<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-30-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="sobel-filters" class="level4">
<h4 class="anchored" data-anchor-id="sobel-filters">2.4.2 Sobel filters</h4>
<p>There are many possible configurations for edge detectors. A very common one is the Sobel operator, which provides an extra weight to the center pixels of the kernel. The filter can be rotated to make it sensitive to either horizontal or vertical edges.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cdfc1330-5d9d-4789-be03-c3b9289d26cf-3-df33d284-8c5a-497c-9d45-85bd89f6c501.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">sobel_filters.PNG</figcaption>
</figure>
</div>
<p>Implementing the Sobel filter is just like implementing other filters: call <code>ndimage.sobel()</code>, then pass in the image and the orientation of the filter.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cdfc1330-5d9d-4789-be03-c3b9289d26cf-2-cece486c-22cf-4103-8ba8-e81ccbefd029.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">sobel_filters_ndi.PNG</figcaption>
</figure>
</div>
<p>To remedy the fact that we have multiple edge maps with positive and negative values, we can create a <code>composite edge map</code>. Recall the Pythagorean Theorem - when you have two perpendicular vectors, you can calculate their distance by taking the root of their squares.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cdfc1330-5d9d-4789-be03-c3b9289d26cf-1-58ffd6ea-3876-42d7-8b92-728d3b635127.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">sobel_filter_magnitude.PNG</figcaption>
</figure>
</div>
<p>This is useful in our situation: if we apply the Sobel filter along the first and second axes, we can then use these as input to the Pythagorean Theorem to get a composite, positively weighted edge image. This nicely highlights intensity changes in our image, and we can use these features for masking or object detection in later analysis steps.</p>
<p>Let’s improve upon our previous detection effort by merging the results of two Sobel-filtered images into a composite edge map.</p>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>hand_sobel <span class="op">=</span> np.loadtxt(<span class="st">'Data/hand_sobel.csv'</span>, delimiter <span class="op">=</span> <span class="st">','</span> , dtype<span class="op">=</span><span class="bu">float</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Sobel filter along both axes</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>sobel_ax0 <span class="op">=</span> ndi.sobel(hand_sobel, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>sobel_ax1 <span class="op">=</span> ndi.sobel(hand_sobel, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate edge magnitude </span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>edges <span class="op">=</span> np.sqrt(np.square(sobel_ax0) <span class="op">+</span> np.square(sobel_ax1))</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot edge magnitude</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>plt.imshow(edges, vmax<span class="op">=</span><span class="dv">75</span>, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-32-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Excellent. In this section we learned how to modify and extract parts of images based on their location and intensity. We are now ready to begin analyzing individual images!</p>
</section>
</section>
</section>
<section id="measurement" class="level2">
<h2 class="anchored" data-anchor-id="measurement">3. Measurement</h2>
<p>In this chapter, we’ll get to the heart of image analysis: object measurement. Using a 4D cardiac time series, we’ll determine if a patient is likely to have heart disease. Along the way, we’ll learn the fundamentals of image segmentation, object labeling, and morphological measurement.</p>
<section id="objects-and-labels" class="level3">
<h3 class="anchored" data-anchor-id="objects-and-labels">3.1 Objects and labels</h3>
<p>In this section, we’ll discuss how we can measure one or more component parts of our image. We’ll start by learning how to label objects.</p>
<p>Segmentation is the process of splitting an image into separate objects. Since whole careers can be spent developing segmentation techniques, we will focus mostly on how to analyze the resulting objects.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/d7c899e8-3fd6-43bd-a4d1-871886f50531-1-763fd8d1-0027-46a7-8eb9-15ead5f39e9b.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">segmentation.PNG</figcaption>
</figure>
</div>
<section id="segment-the-heart" class="level4">
<h4 class="anchored" data-anchor-id="segment-the-heart">3.1.1 Segment the heart</h4>
<p><code>Sunnybrook Cardiac Database</code><br>
We will analyze cardiac magnetic resonance imaging data from the <a href="https://www.cardiacatlas.org/sunnybrook-cardiac-data/">Sunnybrook Cardiac Database</a>. Each Sunnybrook dataset contains a 3D time series of a person’s heart over the course of a single heartbeat. The end goal is to measure the proportion of blood that’s pumped out of the left ventricle, a measure known as the <code>ejection fraction</code>.</p>
<p>In this image, the left ventricle is the circular cavity in the center. Abnormal ejection fractions can indicate urgent health issues.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/da8e13ff-2f94-4d27-bf5b-81198386ec40-1-88721af8-5087-4e77-8ff1-a558d6c44b4b.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">ejection_fraction.PNG</figcaption>
</figure>
</div>
<p>Our first step towards calculating the ejection fraction is to segment the left ventricle from the rest of the image. For these MRI data, fluid-filled areas have high-intensity values. So, one approach is to take the original image, filter it to reduce noise and smooth edges, then mask it to select pixels with relatively high values.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/83c3dd7c-677f-4643-a17b-57b79329e921-2-88e222aa-c023-46e3-a41d-a656adca7ea4.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">filter_and_mask.PNG</figcaption>
</figure>
</div>
<p>This does a good job of segmenting the left ventricle, but now we need to remove the pixels that are part of other objects.</p>
<p>We can do this using <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.label.html">SciPy’s <code>label()</code> function</a>. First, we’ll create the above mask by reading in the file, applying a small Gaussian filter, then masking pixels with intensities lower than 150. Next, we “label” the mask. The labeling algorithm treats 0 values as background pixels, and then it looks for all of the objects that are separated by background. It then returns an array where each object has been indexed, as well as the number of objects detected. It seems we have 14 distinct objects in this image. Plotting the labels with the rainbow colormap shows that the circular left ventricle region in the center has been assigned a unique label value.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/83c3dd7c-677f-4643-a17b-57b79329e921-1-1495402c-1eec-4faf-8dc5-804252c5b978.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">scipy_label.PNG</figcaption>
</figure>
</div>
<p><code>Image data</code></p>
<p>Let’s grab some MR imaging data from the <a href="https://www.cardiacatlas.org/sunnybrook-cardiac-data/">Sunnybrook Cardiac Database</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget https:<span class="op">//</span>assets.datacamp.com<span class="op">/</span>production<span class="op">/</span>repositories<span class="op">/</span><span class="dv">2085</span><span class="op">/</span>datasets<span class="op">/</span>fabaa1f1675549d624eb8f5d1bc94e0b11e30a8e<span class="op">/</span>sunnybrook<span class="op">-</span>cardiac<span class="op">-</span>mr.<span class="bu">zip</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip sunnybrook<span class="op">-</span>cardiac<span class="op">-</span>mr.<span class="bu">zip</span> <span class="op">-</span>d Data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> imageio.v2 <span class="im">as</span> imageio</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.ndimage <span class="im">as</span> ndi </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And, let’s focus on one particular image :</p>
<div class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load array from csv</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>heartbeat<span class="op">=</span> np.loadtxt(<span class="st">'Data/heartbeat.csv'</span>, delimiter <span class="op">=</span> <span class="st">','</span> , dtype<span class="op">=</span><span class="bu">float</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_and_render_plot():</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Custom function to simplify common formatting operations for exercises. Operations include: </span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Turning off axis grids.</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Calling `plt.tight_layout` to improve subplot spacing.</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Calling `plt.show()` to render plot.'''</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.gcf()</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the tick interval</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.ticker <span class="im">as</span> ticker</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>min_val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>max_val <span class="op">=</span> <span class="dv">160</span></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>tick_interval <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>tick_vals <span class="op">=</span> np.arange(min_val, max_val <span class="op">+</span> tick_interval, tick_interval)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the grayscale image</span></span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>plt.imshow(heartbeat, vmin<span class="op">=</span>min_val, vmax <span class="op">=</span> max_val, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>colorbar <span class="op">=</span> plt.colorbar()</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>colorbar.set_ticks(tick_vals)</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-37-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The full image is a 3D time series spanning a single heartbeat. These data are used by radiologists to measure the ejection fraction: the proportion of blood ejected from the left ventricle during each stroke.</p>
<p><code>Illustration</code></p>
<p>To begin, segment the left ventricle from a single slice of the volume (heartbeat). First, we’ll filter and mask the image; then we’ll label each object with <code>ndi.label()</code>.</p>
<p>Apply a median filter to im. Set the size to 3.</p>
<div class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Smooth intensity values</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>im_filt <span class="op">=</span> ndi.median_filter(heartbeat, size<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Create a mask of values greater than 60, then use <code>ndi.binary_closing()</code> to fill small holes in it.</p>
<div class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select high-intensity pixels</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>mask_start <span class="op">=</span> np.where(im_filt<span class="op">&gt;</span><span class="dv">60</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> ndi.binary_closing(mask_start)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Extract a labeled array and the number of labels using <code>ndi.label()</code>.</p>
<div class="cell" data-execution_count="131">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Label the objects in "mask"</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>labels, nlabels <span class="op">=</span> ndi.label(mask)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Num. Labels:'</span>, nlabels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Num. Labels: 26</code></pre>
</div>
</div>
<p>Plot the labels array on top of the original image. To create an overlay, use <code>np.where</code> to convert values of 0 to np.nan. Then, plot the overlay with the rainbow colormap and set alpha=0.75 to make it transparent.</p>
<div class="cell" data-execution_count="132">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a `labels` overlay</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>overlay <span class="op">=</span> np.where(labels<span class="op">!=</span><span class="dv">0</span>, labels, np.nan)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use imshow to plot the overlay</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>plt.imshow(overlay, cmap<span class="op">=</span><span class="st">'rainbow'</span>, alpha<span class="op">=</span><span class="fl">0.75</span>)</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-41-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Robust image segmentation is an entire research domain, but the simple principle is to leverage intensity and location information to differentiate objects of interest from the background. Once labeled, the objects can be manipulated easily.</p>
</section>
<section id="select-objects" class="level4">
<h4 class="anchored" data-anchor-id="select-objects">3.1.2 Select objects</h4>
<p>We can now select individual objects by referencing their index value. To select pixels in the first object, you would use “where labels is 1, return the value from im, else return 0”. Alternatively, you can select a number of labels meeting a condition. Calling “where labels is less than 3, return im, else 0” will select pixels from the first and second objects.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/371fe065-0c47-4bd3-8740-becfd6d3f84c-1-2d603989-29ee-4425-a07f-52b1a15a9712.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">label_selection.PNG</figcaption>
</figure>
</div>
<p>Labels are like object “handles” - they give you a way to pick up whole sets of pixels at a time. To select a particular object:</p>
<ul>
<li>Find the label value associated with the object.</li>
<li>Create a mask of matching pixels.</li>
</ul>
<p><code>Illustration</code></p>
<p>For this exercise, create a labeled array from the provided mask. Then, find the label value for the centrally-located left ventricle, and create a mask for it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>mask_provided <span class="op">=</span> np.loadtxt(<span class="st">'Data/mask_provided.csv'</span>, delimiter <span class="op">=</span> <span class="st">','</span> , dtype<span class="op">=</span><span class="bu">float</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Use <code>ndi.label()</code> to assign labels to each separate object in mask.</p>
<div class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Label the image "mask"</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>labels, nlabels <span class="op">=</span>ndi.label(mask_provided)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Find the index value for the left ventricle label by checking the center pixel (128, 128)</p>
<div class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select left ventricle pixels</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>lv_val <span class="op">=</span> labels[<span class="dv">128</span>, <span class="dv">128</span>]</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>lv_val</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="134">
<pre><code>5</code></pre>
</div>
</div>
<p>Create a mask of pixels matching the left ventricle label. Using <code>np.where</code>, set pixels labeled as lv_val to 1 and other values to np.nan.</p>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>lv_mask <span class="op">=</span> np.where(labels<span class="op">==</span>lv_val,<span class="dv">1</span>,np.nan )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Use <code>plt.imshow()</code> to overlay the selected label on the current plot.</p>
<div class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Overlay selected label</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(lv_mask, cmap<span class="op">=</span><span class="st">'rainbow'</span>)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-46-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>When running <code>ndi.label()</code>, the image is traversed from top-left to bottom right, so the generated label value could change depending on how many objects are detected. You may need to plot your labeled image to get the appropriate region.</p>
</section>
<section id="extract-objects" class="level4">
<h4 class="anchored" data-anchor-id="extract-objects">3.1.3 Extract objects</h4>
<p>A <code>bounding box</code>is the range of indices along each axis which completely enclose an object. You can use the bounding box to extract objects from the larger image. The <code>find_objects()</code> function can create these bounding boxes for you.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/bed85f9f-3556-4256-ac96-6c7d06c76b58-1-e89fa8e3-62fc-489d-ba4b-8d340d9347ad.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">bounding_box.PNG</figcaption>
</figure>
</div>
<p>When you run <code>find_objects()</code> on a labeled array, it will return a list of bounding boxes. Each item in the returned list is a tuple of index ranges - one slice for each dimension. Indexing the original image using one of these boxes will yield an image cropped to that object. You could then analyze each of these arrays individually.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cecf7b64-f467-4e82-81c4-6ea86cfe1537-1-3b08f3dc-ae6d-406e-ada1-a5ad2255af65.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">ndi_find_objects.PNG</figcaption>
</figure>
</div>
<p>Extracting objects from the original image eliminates unrelated pixels and provides new images that can be analyzed independently.</p>
<p>The key is to crop images so that they only include the object of interest. The range of pixel indices that encompass the object is the bounding box.</p>
<p><code>Illustration</code><br>
To illustrate, we will use <code>ndi.find_objects()</code> to create a new image containing only the left ventricle.</p>
<p>Create the labels array from mask, then create a mask left ventricle pixels. (Use the coordinates 128, 128 to find the left ventricle label value.)</p>
<div class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create left ventricle mask</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>labels, nlabels <span class="op">=</span> ndi.label(mask_provided)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>lv_val <span class="op">=</span> labels[<span class="dv">128</span>,<span class="dv">128</span>]</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>lv_mask <span class="op">=</span> np.where(labels<span class="op">==</span>lv_val, <span class="dv">1</span>, <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Find the bounding box indices for <code>lv_mask</code> Print the number of objects found and the values for the first box.</p>
<div class="cell" data-execution_count="138">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find bounding box of left ventricle</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>bboxes <span class="op">=</span>ndi.find_objects(lv_mask)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of objects:'</span>, <span class="bu">len</span>(bboxes))</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Indices for first box:'</span>, bboxes[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of objects: 1
Indices for first box: (slice(107, 149, None), slice(116, 162, None))</code></pre>
</div>
</div>
<p>Select the portion of <code>im</code> that is within the left ventricle bounding box, and plot the cropped image.</p>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Crop to the left ventricle (index 0)</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>im_lv <span class="op">=</span> im[bboxes[<span class="dv">0</span>]]</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the cropped image</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>plt.imshow(im_lv, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-49-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>di.find_objects()</code> becomes extremely useful when dealing with 3-dimensional objects that are harder to view at a glance.</p>
</section>
</section>
<section id="measuring-intensity" class="level3">
<h3 class="anchored" data-anchor-id="measuring-intensity">3.2 Measuring intensity</h3>
<p>Once objects have been segmented from the background, their properties can be efficiently measured using tools within SciPy.</p>
<p>For this section, we’ll step up to measuring a full three-dimensional volume.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/47afa256-505b-4818-92f0-0dd3a234e4a1-1-2b3e82d1-c391-492b-b406-ef80378ed346.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">cardiac_labels.PNG</figcaption>
</figure>
</div>
<p>We have segmented this volume into two parts:</p>
<ul>
<li><code>label 1</code> is the left ventricle, shown here in purple.</li>
<li><code>label 2</code> is a circular section from the middle of the image, which will be useful for comparison.</li>
</ul>
<section id="functions" class="level4">
<h4 class="anchored" data-anchor-id="functions">3.2.1 Functions</h4>
<p>SciPy has optimized many of the most common descriptive <strong>functions</strong> for image data, including the mean, median, and standard deviation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/7c100872-7665-42f9-8efb-3b5d807f07c4-1-7592c7d6-531e-498d-9a88-09bc21f37555.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">functions.PNG</figcaption>
</figure>
</div>
<p>These functions summarize the array across all dimensions of an image, whether it be 2D, 3D, 4D, or more. They are especially useful when you have a labeled image because you can apply the function to every object independently with a single call. For custom calculations, you can also use the <code>labeled_comprehension()</code> function to summarize your data.</p>
<p>Which arguments you specify when you call measurement functions determines the pixels used for the calculation.</p>
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/7c100872-7665-42f9-8efb-3b5d807f07c4-2-91a1fdae-0a3d-4d19-9bd5-423a670a5cd0.png" class="img-fluid" alt="download.png"><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/7c100872-7665-42f9-8efb-3b5d807f07c4-3-dd644a62-90dd-4d95-b525-5fb19583b7a2.PNG" class="img-fluid" alt="call_measure_functions.PNG"></p>
<p>Here, we have loaded the MRI volume and its corresponding labels. To get the mean intensity of the entire image, simply call <code>ndimage.mean()</code> with the original volume. If you provide a mask or a labeled array, you will restrict the analysis to all non-zero pixels. However, if you provide a set of labels and an index value, you can get the mean intensity for a single label. On the other hand, if you pass a list of values to the index argument, the function will return a list of mean values - one for each object specified.</p>
<p><code>Measure variance</code></p>
<p>SciPy measurement functions allow you to tailor measurements to specific sets of pixels:</p>
<ul>
<li>Specifying <code>labels</code> restricts the mask to non-zero pixels.</li>
<li>Specifying <code>index</code> value(s) returns a measure for each label value.</li>
</ul>
<p><code>Illustration</code><br>
For this exercise, we will calculate the intensity <strong>variance</strong> of <code>vol</code> with respect to different pixel sets. We have provided the 3D segmented image as labels: label 1 is the left ventricle and label 2 is a circular sample of tissue.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>vol <span class="op">=</span> np.asarray(</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Variance for all pixels</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>var_all <span class="op">=</span> ndi.variance(vol, labels<span class="op">=</span><span class="va">None</span>, index<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'All pixels:'</span>, var_all)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Variance for labeled pixels</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>var_labels <span class="op">=</span> ndi.variance(vol, labels)</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Labeled pixels:'</span>,var_labels)</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Variance for each object</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>var_objects <span class="op">=</span> ndi.variance(vol, labels, index<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">2</span>])</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Left ventricle:'</span>, var_objects[<span class="dv">0</span>])</span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Other tissue:'</span>, var_objects[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>&lt;script.py&gt; output: All pixels: 840.4457526156154 Labeled pixels: 2166.5887761076724 Left ventricle: 1123.4641972021984 Other tissue: 1972.7151849347783</p>
<p>Intensity values are based on tissue properties and the imaging modality. Areas that contain many types of tissue will have high variance because there are many different types sampled. Most of the background values have the same value. Even though we don’t care about these values, they make the “global variance” much lower than those encompassing in tissue.</p>
</section>
<section id="separate-histograms" class="level4">
<h4 class="anchored" data-anchor-id="separate-histograms">3.2.2 Separate histograms</h4>
<p>This technique can be applied to some other SciPy tools, including the histogram function. In the previous chapter, we simply passed in our image array and then specified the minimum value, maximum value, and the number of bins to use. However, if you also include a label array and indices, <code>ndimage.histogram()</code> will return distributions for each of the selected labels.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/a098777b-5f8a-4a6f-804e-4a8820b00827-2-615663dc-112f-4ce8-8be0-2a374cdf5ab1.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">object_histogram.PNG</figcaption>
</figure>
</div>
<p>Plotting these object-level histograms is a great way to evaluate your segmentation. If you see very wide distributions or multiple peaks and valleys in your histogram, your labeled object may include many different tissue types. On the other hand, if the histogram resembles a normal distribution, your segmentation may be doing a good job. This is because the physical properties that influence intensity values should be relatively uniform throughout a tissue. For example, we expect that the voxels in our left ventricle label are filled with blood. Although we expect some variation in their intensity, we also expect them to be centered on some mean value.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/a098777b-5f8a-4a6f-804e-4a8820b00827-1-2a2d6a37-a74c-4747-b8a7-ef48c6b25d01.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">separate_histograms.PNG</figcaption>
</figure>
</div>
<p>In this case, we can see that the majority of left ventricle intensity values are higher than the other labeled pixels. Although there are some low values, which are likely not part of the ventricle, the segmentation seems to do a good job overall.</p>
<p>A poor tissue segmentation includes multiple tissue types, leading to a wide distribution of intensity values and more variance.</p>
<p>On the other hand, a perfectly segmented left ventricle would contain only blood-related pixels, so the histogram of the segmented values should be roughly bell-shaped.</p>
<p><code>Illustration</code></p>
<p>For this exercise, compare the intensity distributions within vol for the listed sets of pixels. Use <code>ndi.histogram</code>, which also accepts labels and index arguments.</p>
<p>Use the labels and index arguments to extract a histogram for each of the following set of pixels in vol:</p>
<ul>
<li>All pixels</li>
<li>All labeled pixels</li>
<li>Left ventricle pixels (i.e., label 1)</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create histograms for selected pixels</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>hist1 <span class="op">=</span> ndi.histogram(vol, <span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">255</span>, bins<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>hist2 <span class="op">=</span> ndi.histogram(vol, <span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">256</span>, labels<span class="op">=</span>labels)</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>hist3 <span class="op">=</span> ndi.histogram(vol, <span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">256</span>, labels<span class="op">=</span>labels, index<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plot each histogram using <code>plt.plot()</code>. For each one, rescale by the total number of pixels to allow comparisons between them.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the histogram density</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>plt.plot(hist1 <span class="op">/</span> hist1.<span class="bu">sum</span>(), label<span class="op">=</span><span class="st">'All pixels'</span>)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>plt.plot(hist2 <span class="op">/</span> hist2.<span class="bu">sum</span>(), label<span class="op">=</span><span class="st">'All labeled pixels'</span>)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>plt.plot(hist3 <span class="op">/</span> hist3.<span class="bu">sum</span>(), label<span class="op">=</span><span class="st">'Left ventricle'</span>)</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/768c0ff8-6883-4ee8-9a9f-4b29166f3ccc-1-6a2797ba-eed2-445c-94fa-9bbae0be02fe.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">intensity_value.PNG</figcaption>
</figure>
</div>
<p>Notice how the left ventricle segmentation is more normally distributed than the other sets of pixels.</p>
</section>
</section>
<section id="measuring-morphology" class="level3">
<h3 class="anchored" data-anchor-id="measuring-morphology">3.3 Measuring morphology</h3>
<p>Measuring object “morphology,” or shape and size, is another principal aim of image analysis. For example, if a patient goes in for an MRI and they find out they have a brain tumor, a natural first question might be: “How big is it?”. Or, if they have been monitoring it for some time, they may want to know: “Has it grown?”</p>
<section id="calculate-volume" class="level4">
<h4 class="anchored" data-anchor-id="calculate-volume">3.3.1 Calculate volume</h4>
<p>To measure the amount of space occupied by an object, we need two quantities:</p>
<ul>
<li>the size of each element in the array; and</li>
<li>the number of those elements in the object.</li>
</ul>
<p>Let’s calculate the volume of the left ventricle in one of our cardiac images.</p>
<ol type="1">
<li><p>First, we establish the amount of real, physical space taken up by each voxel. Recall that in DICOM images, we can find this in the “sampling” field of the metadata dictionary. Multiplying the lengths of the first, second, and third dimensions will give us the total volume at each voxel. In this case, the measurements are in cubic millimeters.</p></li>
<li><p>Next, we want to count the number of voxels in the left ventricle. We can do this by passing a 1 as input to <code>ndimage.sum()</code> and then providing it with the labeled array and index of our object. The function will weight each left ventricle voxel with a value of 1 and sum them.</p></li>
<li><p>Finally, we multiply the number of voxels by their individual size to get the total volume of the object (in cubic millimeters).</p></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/f4d6cf7d-1c01-4532-8929-1173d74ab178-1-f68b718f-ca92-4bc7-b533-4bfec4dd519e.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">volume.PNG</figcaption>
</figure>
</div>
<p><code>Illustration</code></p>
<p>For this exercise, measure the volume of the left ventricle in one 3D image (vol).</p>
<p>First, count the number of voxels in the left ventricle (label value of 1). T</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>nvoxels <span class="op">=</span> ndi.<span class="bu">sum</span>(<span class="dv">1</span>, labels, index<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>nvoxels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>6459</p>
<p>Then, multiply it by the size of each voxel in <span class="math inline">\(mm^3\)</span>. (Check vol.meta for the sampling rate.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>d0, d1, d2 <span class="op">=</span> vol.meta[<span class="st">'sampling'</span>]</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>dvoxel <span class="op">=</span> d0 <span class="op">*</span> d1 <span class="op">*</span> d2</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>dvoxel</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>828113.0172042125</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>volume <span class="op">=</span> nvoxels <span class="op">*</span> dvoxel</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>120731.82353614898</p>
<p>The volume of the left ventricle is therefore circa 120,731 <span class="math inline">\(mm^3\)</span>.</p>
<p>Volume is a basic but useful measure, and it is a great “reality check” when evaluating your processes.</p>
</section>
<section id="calculate-distance" class="level4">
<h4 class="anchored" data-anchor-id="calculate-distance">3.3.2 Calculate distance</h4>
<p>Another useful morphological measure is the <strong>distance</strong> of each voxel to the nearest background value. This information can help you identify the most embedded points within objects or mask out edge areas. To perform a distance transformation on a mask or label array, use the <code>dist_transform_edt()</code> function. This will return a new array, where each non-zero voxel has been replaced with the distance to the nearest background voxel. The maximum value, in this case, reflects how far from the edge the most embedded point is. If you have access to the sampling rates for each dimension, you can include these to generate values that reflect physical distance. You can see here that the max distance is reduced because the sampling rate is less than one millimeter per pixel.</p>
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/8f6c1d19-f3e8-40db-8d55-ba55417d863a-1-9d3fb8d4-78fd-424c-87d7-7c848e1c505f.PNG" class="img-fluid" alt="distance.PNG"><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/8f6c1d19-f3e8-40db-8d55-ba55417d863a-2-9e8a80ad-01ed-4da4-ab04-eda3c74f730f.png" class="img-fluid" alt="download.png"></p>
<p><code>Illustration</code></p>
<p>A distance transformation calculates the distance from each pixel to a given point, usually the nearest background pixel. This allows us to determine which points in the object are more interior and which are closer to edges.</p>
<p>For this exercise, we will use the Euclidian distance transform on the left ventricle object in labels.</p>
<p>Create a mask of left ventricle pixels (Value of 1 in labels).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>lv <span class="op">=</span> np.where(labels<span class="op">==</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calculate the distance to background for each pixel using <code>ndi.distance_transform_edt()</code>. Supply pixel dimensions to the sampling argument.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>dists <span class="op">=</span> ndi.distance_transform_edt(lv,sampling<span class="op">=</span>vol.meta[<span class="st">'sampling'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Print out the maximum distance and its coordinates using ndi.maximum and ndi.maximum_position.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Max distance (mm):'</span>, ndi.maximum(dists))</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Max location:'</span>, ndi.maximum_position(dists))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Overlay a slice of the distance map on the original image.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot overlay of distances</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>overlay <span class="op">=</span> np.where(dists[<span class="dv">5</span>] <span class="op">&gt;</span> <span class="dv">0</span>, dists[<span class="dv">5</span>], np.nan) </span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(overlay, cmap<span class="op">=</span><span class="st">'hot'</span>)</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/16341d8b-94ef-4810-a624-63c7ce17832f-1-de42da55-752b-4c8d-8eea-7cdb34ae2217.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">distance_left_ventricle.PNG</figcaption>
</figure>
</div>
<p>We can make inferences about the shapes of objects by looking at the distribution of distances. For example, a circle will have a uniform distribution of distances along both dimensions.</p>
</section>
<section id="pinpoint-centre-of-mass" class="level4">
<h4 class="anchored" data-anchor-id="pinpoint-centre-of-mass">3.3.3 Pinpoint centre of mass</h4>
<p>A complementary measure is the <strong>center of mass</strong>, which you can calculate directly. Mass, in this case, refers to intensity values, with larger values pulling the center towards them. Just like with the intensity measures, the <code>center_of_mass()</code> function accepts “labels” and “index” arguments. The function returns a tuple of coordinates for each object specified. For our cardiac data, the center of mass for the left ventricle corresponds to the center of the volume in all three dimensions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/b14de83a-f025-42d7-bd4a-84e4cbed6e1d-1-af6e7136-858f-4fd1-b95e-7ef2452a6e66.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">center_of_mass.PNG</figcaption>
</figure>
</div>
<p><code>Illustration</code></p>
<p>The distance transformation reveals the most embedded portions of an object. On the other hand, <code>ndi.center_of_mass(</code>) returns the coordinates for the center of an object.</p>
<p>The “mass” corresponds to intensity values, with higher values pulling the center closer to it.</p>
<p>For this exercise, we will calculate the center of mass for the two labeled areas, then, plot them on top of the image.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract centers of mass for objects 1 and 2</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>coms <span class="op">=</span> ndi.center_of_mass(vol, labels, index<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">2</span>])</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Label 1 center:'</span>, coms[<span class="dv">0</span>])</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Label 2 center:'</span>, coms[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note: <code>ndi.center_of_mass()</code> returns [z, x, y] coordinates, rather than [pln, row, col]</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add marks to plot</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> c0, c1, c2 <span class="kw">in</span> coms:</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>    plt.scatter(c2, c1, s<span class="op">=</span><span class="dv">100</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/5f3367ec-61d4-4ee9-afb1-81534ba7426a-1-fd235a0b-c16d-4ed9-8ab5-64c371a3c20e.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">center_of_mass_plot.PNG</figcaption>
</figure>
</div>
<p>Some shapes, such as those with holes, may have a center of mass that is outside of them.</p>
</section>
</section>
<section id="measuring-in-time" class="level3">
<h3 class="anchored" data-anchor-id="measuring-in-time">3.4 Measuring in time</h3>
<p>If you recall, the proportion of blood that’s pumped out of the left ventricle, is a measure known as the <code>ejection fraction</code>.</p>
<p>To calculate the <strong>ejection fraction</strong>, we have to find the left ventricle’s volume when :</p>
<ul>
<li>it’s totally relaxed – its maximum; and</li>
<li>when it’s fully squeezed – its minimum.</li>
</ul>
<p>Taking the difference between these two volumes and dividing by the maximum yields the fraction of blood that is pumped out and into the rest of the circulatory system.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/321726fc-9a5a-4f53-83c0-3f1234f4d717-1-feabef6d-7e77-4768-a7c0-c788b44682f1.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">ejection_fraction_calc.PNG</figcaption>
</figure>
</div>
<section id="summarize-the-time-series" class="level4">
<h4 class="anchored" data-anchor-id="summarize-the-time-series">3.4.1 Summarize the time series</h4>
<p>One way to accomplish this is to:</p>
<ol type="1">
<li>Segment the left ventricle at each time point.</li>
<li>Calculate the volume at each time point sequentially, using a for loop.</li>
</ol>
<p>This results in a 1D time series from which we can extract our minimum and maximum values. Values in hand, we plug them into the ejection fraction equation.</p>
<p>Let’s assume that we have access to both the volumetric time series and the segmented left ventricle. The data are 4-dimensional, with time as the first dimension.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/ec83d3a3-2d2b-46c5-8477-ee14cfb806d2-2-9c39e1c0-9557-403f-8790-b8c90b0c848d.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">time.PNG</figcaption>
</figure>
</div>
<ol type="1">
<li><p>First, we calculate the volume of each individual voxel. We extract the sampling rate along each dimension, then multiply the spatial dimensions together to get the space occupied by each element.</p></li>
<li><p>Next, we instantiate an empty 1D array to record the volume at each time point.</p></li>
<li><p>We then loop through each time point, counting the number of voxels in the left ventricle.</p></li>
<li><p>Finally, we multiply the number of voxels by their volume and store the value in the time series array.</p></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/ec83d3a3-2d2b-46c5-8477-ee14cfb806d2-1-8667bcae-fa59-44f6-bc79-7f3c5836cf07.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">volume_vs_time.PNG</figcaption>
</figure>
</div>
<p>The plot of the data lines up with our expectations: in the first few time points, there is a squeezing action on the ventricle, followed by relaxation, where it fills up again.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/ec83d3a3-2d2b-46c5-8477-ee14cfb806d2-3-af054207-1e14-456f-80a0-ba19bef9bdb3.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">volume_time_plot.PNG</figcaption>
</figure>
</div>
<p><code>Illustration</code></p>
<p>The ejection fraction is the proportion of blood squeezed out of the left ventricle each heartbeat. To calculate it, radiologists have to identify the maximum volume <em>(systolic volume)</em> and the minimum volume <em>(diastolic volume)</em> of the ventricle.</p>
<p>Initialize an empty array with 20 elements :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty time series</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>ts <span class="op">=</span> np.zeros(<span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calculate the volume of each image voxel. (Consult the meta dictionary for sampling rates.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate volume at each voxel</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>d0, d1, d2, d3 <span class="op">=</span> vol_ts.meta[<span class="st">'sampling'</span>] <span class="co"># the first dimension is time</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>dvoxel <span class="op">=</span> d1 <span class="op">*</span> d2 <span class="op">*</span> d3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For each time point, count the pixels in labels, and update the time series array.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop over the labeled arrays</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>    nvoxels <span class="op">=</span> ndi.<span class="bu">sum</span>(<span class="dv">1</span>, labels[t], index<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>    ts[t] <span class="op">=</span> nvoxels <span class="op">*</span> dvoxel</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plot the time series using <code>plt.plot()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>plt.plot(ts)</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/38b7aa37-9a46-4ae3-b5c9-4e5e82def80b-1-e35eb0f9-9d79-42e1-acf7-c6fef3e16f02.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">timepoint_volume.PNG</figcaption>
</figure>
</div>
<p>We can see the pumping action of the left ventricle clearly from the time series plot - a sudden decrease followed by a refilling of the chamber.</p>
</section>
<section id="measure-ejection-fraction" class="level4">
<h4 class="anchored" data-anchor-id="measure-ejection-fraction">3.4.2 Measure ejection fraction</h4>
<p>Now, it’s simply a matter of selecting the lowest and highest values from the time series and calculating the ejection fraction. Since “ts” is a NumPy array, we can call the <code>min(</code>) and <code>max()</code> methods to retrieve these values.</p>
<p>Then, we find the difference and divide by the maximum volume.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/e0d703cb-13cd-4aef-8d72-f821e2637756-1-aba842c6-db4c-4643-ae39-388ac9d3b4d0.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">eject_fract_calc.PNG</figcaption>
</figure>
</div>
<p><code>Illustration</code></p>
<p>To close our investigation, plot slices from the maximum and minimum volumes by analyzing the volume time series (ts). Then, calculate the ejection fraction.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get index of max volume</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>tmax <span class="op">=</span> np.argmax(ts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>18</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get index of min volume</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>tmin <span class="op">=</span> np.argmin(ts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>5</p>
<p>Plot the extreme volumes (max and min) together. Display the images along the fifth plane, e.g.&nbsp;(vol_ts[t, 4]).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the largest and smallest volumes</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(vol_ts[tmax, <span class="dv">4</span>], vmax<span class="op">=</span><span class="dv">160</span>)</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(vol_ts[tmin, <span class="dv">4</span>], vmax<span class="op">=</span><span class="dv">160</span>)</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>format_and_render_plots()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/d113d48a-b40e-48bc-a955-0f4f839ac1d8-1-11b959cf-8669-45cf-8dcf-6a67ed22f35f.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">max_min.PNG</figcaption>
</figure>
</div>
<p>Calculate the ejection volume and fraction using the min() and max() methods of ts. Print these values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate ejection fraction</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>ej_vol <span class="op">=</span> ts.<span class="bu">max</span>() <span class="op">-</span> ts.<span class="bu">min</span>()</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>ej_frac <span class="op">=</span> ej_vol <span class="op">/</span> ts.<span class="bu">max</span>()</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Est. ejection volume (mm^3):'</span>,ej_vol )</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Est. ejection fraction:'</span>, ej_frac)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>&lt;script.py&gt; output: Est. ejection volume (mm^3): 31268.00536236538 Est. ejection fraction: 0.3202054794520548</p>
<p>After calculating the ejection fraction, review the chart below. Should this patient be concerned?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/f10954fa-9e6c-4078-b013-fc40d65a1638-1-c934f377-aae5-4370-8ba5-6082bf6640da.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">ejection_fraction_chart.PNG</figcaption>
</figure>
</div>
<p>The patient should be extremely concerned! An ejection fraction of below 0.35 is considered to be <strong><em>severely abnormal</em></strong> and the patient’s score is 0.32.</p>
<p>This patient has heart failure with infarction - a serious condition. This case study illustrates a typical image analysis workflow: a single, useful metric is the result of a lot of sophisticated preprocessing, segmentation and measurement techniques.</p>
<p>And that’s it! We’ve put together an estimate of the ejection fraction using SciPy - a process that would normally be done by hand by a radiologist. And we’ve done a pretty good job, even with the simple segmentation method: the expert’s estimate was 0.60, quite close to our value</p>
<p>Of course, this analysis was for a high-quality image of a single subject. Evaluating data from many subjects and images allows for more interesting insights about health and disease. We’ll discuss techniques and pitfalls of multi-image analysis in the next section.</p>
</section>
</section>
</section>
<section id="image-comparison" class="level2">
<h2 class="anchored" data-anchor-id="image-comparison">4. Image Comparison</h2>
<p>For the final section, we’ll need to use our brain… and hundreds of others! We’re going to look at brains from the <a href="https://www.oasis-brains.org/">Open Access Series of Imaging Studies</a>. To describe the effects of aging and dementia on the brain, the researchers gathered 3D MRI images of nearly 400 adults. The participants were between the ages of 18 and 80, and many of them had mild to severe Alzheimer’s disease.</p>
<section id="spatial-transformations" class="level3">
<h3 class="anchored" data-anchor-id="spatial-transformations">4.1 Spatial transformations</h3>
<p>Now that we’ve seen how we can measure a single image let’s turn our attention to questions that leverage many of them.</p>
<p>With a large imaging dataset, there is going to be variability and not just the kind that’s interesting. There will be differences in intensity scales, sampling ratios, object orientation, and object placement within the image window.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/2369bc00-d1e2-4f0c-8716-e57fd8b99d00-2-e791c105-d9ec-4524-8105-27c1c64eaae7.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">variability.PNG</figcaption>
</figure>
</div>
<p><code>Registration</code><br>
One way to address this is to register images to a pre-defined position and coordinate system. For example, you might make all images line up with a template image or atlas. The process of aligning two images together is called “registration.” Registration requires making multiple transformations to an image, such as shifting, rotating, and scaling it.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/2369bc00-d1e2-4f0c-8716-e57fd8b99d00-1-5a1b84d9-4e2c-47cb-b326-8963609b0c2e.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">registration.PNG</figcaption>
</figure>
</div>
<section id="translations" class="level4">
<h4 class="anchored" data-anchor-id="translations">4.1.1 Translations</h4>
<p>Let’s see how we can implement some of these transformations in SciPy.</p>
<p>Here we have an off-center brain that we want to move to the center of the image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/e40439af-96b4-4b5a-a8a5-73e148af1f5f-2-40352870-a316-4d9d-8860-e6f1233d8bcd.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">off_centre_brain.PNG</figcaption>
</figure>
</div>
<p>First, we’ll load the head slice using ImageIO. It has a shape of 256 by 256, so the center is at 128, 128.</p>
<p>Then we’ll get the head’s initial center of mass.</p>
<p>We next calculate the difference between the head’s current center of mass and the target center, for both the rows and the columns.</p>
<p>Finally, we call SciPy’s <code>shift()</code> function, passing in the image and the number of pixels we need to move along the first and second axes.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/e40439af-96b4-4b5a-a8a5-73e148af1f5f-1-1d88c308-b11a-4dee-bb5d-195f6e7f0490.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">translation.PNG</figcaption>
</figure>
</div>
<p><code>Illustration</code></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> imageio.v2 <span class="im">as</span> imageio</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.ndimage <span class="im">as</span> ndi</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using loadtxt()</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> np.loadtxt(<span class="st">"Data/NumpyData.csv"</span>,</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>                 delimiter<span class="op">=</span><span class="st">","</span>, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>display(im)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])</code></pre>
</div>
</div>
<p>Find the center-point of <code>im</code></p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find image center of mass</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>com <span class="op">=</span> ndi.center_of_mass(im)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calculate the distance from the image center (128, 128), along each axis.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate amount of shift needed</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>d0 <span class="op">=</span> <span class="dv">128</span> <span class="op">-</span> com[<span class="dv">0</span>]</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>d1 <span class="op">=</span> <span class="dv">128</span> <span class="op">-</span> com[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Use <code>ndi.shift()</code> to shift the data</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Translate the brain towards the center</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>xfm <span class="op">=</span> ndi.shift(im, shift<span class="op">=</span>[d0,d1])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plot the original and shifted data. First, create an array of subplots with two rows and one column. Then, draw <code>im</code> and <code>xfm</code> on the first and second subplots.</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_and_render_plot():</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Custom function to simplify common formatting operations for exercises. Operations include: </span></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Turning off axis grids.</span></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Calling `plt.tight_layout` to improve subplot spacing.</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Calling `plt.show()` to render plot.'''</span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.gcf()</span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    plt.show</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original and adjusted images</span></span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im,cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(xfm, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-76-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We can shift our image in as many directions as there are image dimensions.</p>
</section>
<section id="rotations" class="level4">
<h4 class="anchored" data-anchor-id="rotations">4.1.2 Rotations</h4>
<p>Rotations can be performed in a similar manner using the <code>rotate()</code> function.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/1e55b59d-3601-4f8c-a715-fadcada00463-2-fa634a0b-4f6f-4d24-83f7-68b36d79df0d.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">rotation.PNG</figcaption>
</figure>
</div>
<p>The angle of rotation is specified in degrees :</p>
<ul>
<li>with <code>positive numbers</code> indicating upward from the horizontal; and</li>
<li><code>negative numbers</code> downward.</li>
</ul>
<p>In two dimensions, we always rotate along the x-y plane, but in three dimensions, there are three rotational planes we could use.</p>
<p>One caveat with the <code>rotate()</code> function is that the default behavior preserves all the original data. This means that your rotated image may actually end up larger than your original. To keep your original image shape, pass <code>"reshape equals False"</code> to your function call.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/1e55b59d-3601-4f8c-a715-fadcada00463-1-7b9bc7cb-6195-481a-b06b-3e56fdf840de.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">rotation_preserve.PNG</figcaption>
</figure>
</div>
<p><code>Illustration</code></p>
<p>For this exercise, shift and rotate the brain image (im) so that it is roughly level and “facing” the right side of the image.</p>
<p>Shift im towards the center: 20 pixels left and 20 pixels up.</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Shift the image towards the center</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>xfm <span class="op">=</span> ndi.shift(im,shift<span class="op">=</span>[<span class="op">-</span><span class="dv">20</span>,<span class="op">-</span><span class="dv">20</span>]) <span class="co"># [left(-ve), up(-ve)]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Use ndi.rotate to turn xfm 30 degrees downward. Set <code>reshape=False</code> to prevent the image shape from changing.</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Rotate the shifted image</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>xfm <span class="op">=</span> ndi.rotate(xfm, angle<span class="op">=-</span><span class="dv">30</span>, reshape<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plot the original and transformed images.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original and rotated images</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(xfm, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-79-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The order of transformations makes a difference. Rotating the image first will alter the object center, changing the amount of shift needed.</p>
</section>
<section id="affine-transformation" class="level4">
<h4 class="anchored" data-anchor-id="affine-transformation">4.1.3 Affine transformation</h4>
<p>Affine transformations modify an image while preserving all of the points, straight lines, and planes. Shown here are four examples of affine transformations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/30891353-5d60-4118-bb1c-f1ccdf37c561-2-d764072c-c6eb-4c92-80b8-8c12d8c8bfec.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">affine.PNG</figcaption>
</figure>
</div>
<ul>
<li><p><code>Translation</code> is the shifting of an image along an axis. It can be used to center an object, for example.</p></li>
<li><p><code>Rotation</code>, on the other hand, will turn the image along a plane.</p></li>
<li><p><code>Scaling</code> increases or decreases the size of the image, and the shearing operation shifts the ends of an axis away from each other.</p></li>
</ul>
<p><code>Transformation matrix</code><br>
For complex registrations, it can be useful to compute a transformation matrix between the original and target space. Essentially, the elements of a transformation matrix encode instructions for the operations we have discussed: translation, rotation, scaling, and shearing. We cannot cover methods for calculating these matrices, but let’s see how they can be used to simplify the registration process.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/30891353-5d60-4118-bb1c-f1ccdf37c561-1-a3e9eb30-5a55-419f-b8ce-1d72ce17e8b2.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">transformation_matrix.PNG</figcaption>
</figure>
</div>
<p><code>Applying a transformation matrix</code><br>
First, we create the transformation matrix. Let’s first use the <code>identity matrix</code>, which has ones along the diagonal and zeros off it. We can apply it by passing the image and matrix to the <code>affine_transform()</code> function. The resulting image is identical to the original.</p>
<p>Next, let’s manipulate the matrix values that encode shifting and rescaling. When we apply this new matrix and plot the result, you can see that the image has been centered and made larger.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/30891353-5d60-4118-bb1c-f1ccdf37c561-3-f662f0d7-f0b2-4bc7-9a22-d87d5c0231a6.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">transform_matrix_apply.PNG</figcaption>
</figure>
</div>
<p><code>Illustration</code></p>
<p>Let’s use <code>ndi.affine_transform()</code> to explore the impact of applying the following registration matrices to <code>im</code>. Which one does the best job of centering, leveling and enlarging the original image?</p>
</section>
<section id="transformation-1" class="level4">
<h4 class="anchored" data-anchor-id="transformation-1">Transformation 1</h4>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create identity matrix</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>mat_1 <span class="op">=</span> np.identity(<span class="dv">3</span>)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>mat_1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>xfm_1 <span class="op">=</span> ndi.affine_transform(im,mat_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original and rotated images</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(xfm_1, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-82-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>As expected, this leaves the original image unchanged.</p>
</section>
<section id="transformation-2" class="level4">
<h4 class="anchored" data-anchor-id="transformation-2">Transformation 2</h4>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>mat_2 <span class="op">=</span> np.array([[<span class="fl">1.5</span>,<span class="op">-</span><span class="fl">0.8</span>,<span class="dv">60</span>],[<span class="fl">0.8</span>,<span class="fl">1.5</span>,<span class="op">-</span><span class="dv">140</span>],[<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>]])</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>mat_2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>array([[   1.5,   -0.8,   60. ],
       [   0.8,    1.5, -140. ],
       [   0. ,    0. ,    1. ]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>xfm_2 <span class="op">=</span> ndi.affine_transform(im,mat_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original and rotated images</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(xfm_2, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-85-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>Explanation of transformations :</code></p>
<p><code>Translation</code> T_x = +60 T_y = -140</p>
<p><code>Scale</code> S_x = +1.5, S_y = +1.5</p>
<p><code>Shear</code> Sh_x = -0.8, Sh_y = +0.8</p>
</section>
<section id="transformation-3" class="level4">
<h4 class="anchored" data-anchor-id="transformation-3">Transformation 3</h4>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>mat_3 <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="op">-</span><span class="fl">0.3</span>,<span class="dv">60</span>],[<span class="op">-</span><span class="fl">0.3</span>,<span class="dv">1</span>,<span class="dv">60</span>],[<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>]])</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>mat_3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>array([[ 1. , -0.3, 60. ],
       [-0.3,  1. , 60. ],
       [ 0. ,  0. ,  1. ]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>xfm_3 <span class="op">=</span> ndi.affine_transform(im,mat_3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original and rotated images</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(xfm_3, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-88-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>Explanation of transformations :</code></p>
<p><code>Translation</code> T_x = +60, T_y = +60</p>
<p><code>Shear</code> Sh_x = -0.3, Sh_y = -0.3</p>
</section>
<section id="transformation-4" class="level4">
<h4 class="anchored" data-anchor-id="transformation-4">Transformation 4</h4>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>mat_4 <span class="op">=</span> np.array([[<span class="fl">0.8</span>,<span class="op">-</span><span class="fl">0.4</span>,<span class="dv">90</span>],[<span class="fl">0.4</span>,<span class="fl">0.8</span>,<span class="op">-</span><span class="dv">6</span>],[<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>]])</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>mat_4</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>array([[ 0.8, -0.4, 90. ],
       [ 0.4,  0.8, -6. ],
       [ 0. ,  0. ,  1. ]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>xfm_4 <span class="op">=</span> ndi.affine_transform(im,mat_4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original and rotated images</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(xfm_4, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-91-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>Explanation of transformations :</code></p>
<p><code>Translation</code> T_x = +90, T_y = -6</p>
<p><code>Scale</code> S_x = +0.8, S_y = +0.8</p>
<p><code>Shear</code> Sh_x = -0.4, Sh_y = +0.4</p>
<p>To implement matrix transformations in your workflow, you will likely want to use more advanced tools, such as those in scikit-image. The package’s website has some <a href="https://scikit-image.org/docs/stable/user_guide/tutorials.html">nice tutorials</a>. Also, note that 3D images require different size transformation matrices.</p>
</section>
</section>
<section id="resampling-and-interpolation" class="level3">
<h3 class="anchored" data-anchor-id="resampling-and-interpolation">4.2 Resampling and interpolation</h3>
<p>When comparing images, differences in array shape and sampling rates can pose hurdles to analysis. Resampling is one way to address this issue.</p>
<section id="resampling" class="level4">
<h4 class="anchored" data-anchor-id="resampling">4.2.1 Resampling</h4>
<p>Resampling is the process of slicing your data onto a different array. It’s distinct from cropping in that the field of view does not change. Instead, the amount of space sampled by each pixel is increased or decreased, which in turn changes the shape of the array.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/eac3b556-f92f-4cc0-8a84-17c50874fbe5-2-e25ce1fd-3bf7-4828-9e73-19f6477cd320.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">resampling.PNG</figcaption>
</figure>
</div>
<p>One useful application is <code>downsampling</code> in which information is merged across multiple pixels to reduce the image size.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/eac3b556-f92f-4cc0-8a84-17c50874fbe5-1-d0533b91-5288-4bf4-8098-c45a5acb04ac.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">downsampling.PNG</figcaption>
</figure>
</div>
<p>Here we have loaded a brain volume from the OASIS dataset. Originally, it has 256 elements along each dimension. We’ll halve this grid size using SciPy’s <code>zoom()</code> function. <code>zoom()</code> adjusts the number of elements along each axis by a given factor. We pass in the volume and specify a zoom of 0.5. This reduces the number of elements on each axis by half so that it is 128 by 128 by 128. Plotting the image reveals that it now has less detail than before, but it also takes up half the amount of memory.</p>
<p>It’s also possible to <code>upsample</code> onto denser grids. But note that this does not result in a true increase in resolution. Even though you are putting more pixels into your image, you are not adding new information that wasn’t there previously. One useful application of upsampling is to make sampling rates along different dimensions equal, for example, to make voxels cubic.</p>
<p>To upsample an image, we call the <code>zoom()</code> function and specify a larger zoom factor. Passing in “2” will double the width of each axis.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/eac3b556-f92f-4cc0-8a84-17c50874fbe5-3-e3c3a8dc-5a23-4b3c-845e-63626efe4882.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">upsampling.PNG</figcaption>
</figure>
</div>
<p><code>Illustration</code></p>
<p>Images can be collected in a variety of shapes and sizes. Resampling is a useful tool when these shapes need to be made consistent. For this exercise, we will transform and then resample the brain image (im) to see how it affects image shape.</p>
<p>Shift <code>im</code> 20 pixels left and 20 pixels up, i.e.&nbsp;(-20, -20). Then, rotate it 35 degrees downward. Remember to specify a value for reshape.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Center and level image</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>xfm <span class="op">=</span> ndi.shift(im, shift<span class="op">=</span>[<span class="op">-</span><span class="dv">20</span>,<span class="op">-</span><span class="dv">20</span>]) <span class="co"># +ve direction is right and up</span></span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>xfm <span class="op">=</span> ndi.rotate(xfm, angle<span class="op">=-</span><span class="dv">35</span>, reshape<span class="op">=</span><span class="va">False</span>) <span class="co"># +ve direction is up</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Use <code>ndi.zoom()</code> to downsample the image from (256, 256) to (64, 64).</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Resample image - reduce by factor of 4 </span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>im_dn <span class="op">=</span> ndi.zoom(xfm, zoom<span class="op">=</span><span class="fl">0.25</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Use <code>ndi.zoom()</code> to upsample the image from (256, 256) to (1024, 1024).</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Resample image - increase by factor of 4 </span></span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>im_up <span class="op">=</span> ndi.zoom(xfm, zoom<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plot the resampled images.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># custom function</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_and_render_plot():</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Custom function to simplify common formatting operations for exercises. Operations include: </span></span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Turning off axis grids.</span></span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Calling `plt.tight_layout` to improve subplot spacing.</span></span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Calling `plt.show()` to render plot.'''</span></span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.gcf()</span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb117-10"><a href="#cb117-10" aria-hidden="true" tabindex="-1"></a>    plt.show</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the images</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(im_dn, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(im_up, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-96-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="interpolation" class="level4">
<h4 class="anchored" data-anchor-id="interpolation">4.2.2 Interpolation</h4>
<p>Resampling actually creates a brand new image that’s based on the old one. And in most cases, filling out this new image requires estimating data that wasn’t originally there. This estimation process is called interpolation.</p>
<p>For example, here we have a simple 10 point dataset :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/b536f022-d87a-4a33-94f0-ff0ea61438c7-1-2584d85e-1333-4988-8ed8-c8f09ec98c5c.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">ten_point.PNG</figcaption>
</figure>
</div>
<p>If we want to upsample it to include 100 points, we have to estimate what the values should be between each of these original points.</p>
<p>One approach is to use the nearest original value, <code>nearest-neighbour</code>, for each new point. This a zero-order interpolation, because we aren’t modeling any relationship between the original values.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/b536f022-d87a-4a33-94f0-ff0ea61438c7-3-8561964e-5a2b-4cdd-9cca-b1a50f996cfd.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">interpol_1.PNG</figcaption>
</figure>
</div>
<p>For higher-order estimation, SciPy uses <code>B-spline</code> interpolation, which uses a set of functions to model the space between points. The order controls how complex these functions can be:</p>
<ul>
<li>an order of 1 is linear</li>
<li>an order of 2 is quadratic, and so on.</li>
</ul>
<p>In the example, we can see that cubic interpolation (order of 3) creates a smooth curve between points :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/b536f022-d87a-4a33-94f0-ff0ea61438c7-2-6777ae79-8e98-4110-ac78-4c527c7f2725.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">cubic_interpol.PNG</figcaption>
</figure>
</div>
<p>Here we’ve created a ten by ten toy image of ascending values. If we resample it onto a 100 by 100 grid, changing the order will affect the “smoothness” of the resulting image. With an order of 0, we return essentially the original image on a new grid. At higher orders, though, we can see a smoother gradient of change along each axis.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/b536f022-d87a-4a33-94f0-ff0ea61438c7-4-d927116b-441e-4334-906d-ae0bc8ed2e67.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">interpol_2.PNG</figcaption>
</figure>
</div>
<p>The principal trade-off with lower and higher-order interpolation is in the computational time: fifth-order interpolation for a 3D volume can take a very long time to calculate!</p>
<p><code>Illustration</code></p>
<p>For this exercise, upsample im and investigate the effect of different interpolation orders on the resulting image.</p>
<p>Use <code>ndi.zoom()</code> to upsample <code>im</code> from a shape of 128, 128 to 512, 512 twice. First, use an interpolation order of 0, then set order to 5.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>im.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>(256, 256)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Upsample "im" by a factor of 4</span></span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>up <span class="op">=</span> ndi.zoom(im, zoom<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>up0 <span class="op">=</span> ndi.zoom(up, zoom<span class="op">=</span><span class="dv">4</span>, order<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>up5 <span class="op">=</span> ndi.zoom(up, zoom<span class="op">=</span><span class="dv">4</span>, order<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Print the array shapes of <code>up</code> and <code>up0</code>.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print original and new shape</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Original shape:'</span>, up.shape)</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Upsampled shape:'</span>, up0.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original shape: (128, 128)
Upsampled shape: (512, 512)</code></pre>
</div>
</div>
<p>Plot close-ups of the images. Use the index range 128:256 along each axis.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot close-ups of the new images</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(up0[<span class="dv">128</span>:<span class="dv">256</span>, <span class="dv">128</span>:<span class="dv">256</span>],cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(up5[<span class="dv">128</span>:<span class="dv">256</span>, <span class="dv">128</span>:<span class="dv">256</span>],cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-100-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The key trade-off is that more complex interpolation methods require greater computational resources. This can take a heavy toll when analyzing 3D volumes.</p>
</section>
</section>
<section id="comparing-images" class="level3">
<h3 class="anchored" data-anchor-id="comparing-images">4.3 Comparing images</h3>
<p>How do you tell if your images are registered well? How would you compare an automatically segmented image with a hand-labeled one? To directly compare two arrays, we have to generate measures of image similarity.</p>
<p>Here are two slices of the same person’s brain, taken on separate occasions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/1cab3f66-380a-4f18-91a9-72da495e5b1d-1-79a2817d-9a06-4df2-808f-b638ca7712c3.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">brain_compare.PNG</figcaption>
</figure>
</div>
<p>You can see that they are similar objects but not aligned with each other. To quantify exactly how imperfect this alignment is, we need to apply a function that will compare the two images.</p>
<p>At the pixel level, there can be thousands and thousands of comparison points between two images. Our need is to summarize all of these comparisons into a <strong>single number</strong>. As with other areas of data science, such as machine learning, there are many ways to evaluate our data. There are cost functions, such as the <code>mean absolute error</code> or <code>mean squared error</code>, which should be <em>minimized</em>.</p>
<p>Objective functions, such as the <code>intersection of the union</code>, are supposed to be <em>maximized</em>.</p>
<section id="mean-absolute-error" class="level4">
<h4 class="anchored" data-anchor-id="mean-absolute-error">4.3.1 Mean absolute error</h4>
<p>Let’s return to our two images, and calculate similarity using a cost function: the <code>mean absolute error</code>.</p>
<p>First, we read in the images. Then, we find the error at each pixel by subtracting im2 from im1. Next, we take the <strong>absolute</strong> value of the error, because we care about whether the images differ from each other in any way, not whether one is larger than the other. Finally, we take the mean of the entire error image to get a single summary measure of similarity.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/7d904b8a-1063-4ddc-8409-18a25bcc7f75-2-17f564fe-c5b5-4788-8143-6151030ff915.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">mean_abs_error.PNG</figcaption>
</figure>
</div>
<p>The goal is <strong>not</strong> to achieve a mean absolute error of zero. In fact, that would mean the images were identical, which is not the case. Instead, you want to minimize the cost function by altering one or both images.</p>
<p>Let’s shift and rotate the first image, then re-compute the cost. We calculate the mean absolute error in the same way as before, using our new image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/7d904b8a-1063-4ddc-8409-18a25bcc7f75-1-13da3af7-5207-47a0-99e0-2676e79d1e4c.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">mean_abs_error_2.PNG</figcaption>
</figure>
</div>
<p>The new cost <code>13.0376</code> is lower than the previous one <code>29.8570</code>, suggesting that the two are better aligned than before.</p>
<p><code>Illustration</code></p>
<p>The mean absolute error (MAE), for example, summarizes intensity differences between two images, with higher values indicating greater divergence.</p>
<p>For this exercise, calculate the mean absolute error between im1 and im2 step-by-step.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> imageio.v2 <span class="im">as</span> imageio</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.ndimage <span class="im">as</span> ndi</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>im1 <span class="op">=</span> np.loadtxt(<span class="st">'Data/im1.csv'</span>, delimiter <span class="op">=</span> <span class="st">','</span> , dtype<span class="op">=</span><span class="bu">float</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>im2 <span class="op">=</span> np.loadtxt(<span class="st">'Data/im2.csv'</span>, delimiter <span class="op">=</span> <span class="st">','</span> , dtype<span class="op">=</span><span class="bu">float</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calculate the difference between im1 and im2.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate image difference</span></span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>err <span class="op">=</span> im1 <span class="op">-</span> im2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plot err with the seismic colormap. To center the colormap at 0, set vmin=-200 and vmax=200.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="co"># custom function</span></span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_and_render_plot():</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Custom function to simplify common formatting operations for exercises. Operations include: </span></span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Turning off axis grids.</span></span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Calling `plt.tight_layout` to improve subplot spacing.</span></span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Calling `plt.show()` to render plot.'''</span></span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.gcf()</span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb129-9"><a href="#cb129-9" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb129-10"><a href="#cb129-10" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb129-11"><a href="#cb129-11" aria-hidden="true" tabindex="-1"></a>    plt.show</span>
<span id="cb129-12"><a href="#cb129-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-13"><a href="#cb129-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the difference</span></span>
<span id="cb129-14"><a href="#cb129-14" aria-hidden="true" tabindex="-1"></a>plt.imshow(err, cmap<span class="op">=</span><span class="st">'seismic'</span>, vmin<span class="op">=-</span><span class="dv">200</span>, vmax<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb129-15"><a href="#cb129-15" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-105-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Compute the absolute error of the difference.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate absolute image difference</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>abs_err <span class="op">=</span> np.<span class="bu">abs</span>(im1 <span class="op">-</span> im2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Use <code>np.abs()</code>. Plot the image.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the difference</span></span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(abs_err, cmap<span class="op">=</span><span class="st">'seismic'</span>, vmin<span class="op">=-</span><span class="dv">200</span>, vmax<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a>format_and_render_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-107-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Find the cost value using <code>np.mean()</code></p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean absolute error</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>mean_abs_err <span class="op">=</span> np.mean(np.<span class="bu">abs</span>(im1 <span class="op">-</span> im2))</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'MAE:'</span>, mean_abs_err)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MAE: 9.2608642578125</code></pre>
</div>
</div>
<p>The MAE metric allows for variations in weighting throughout the image, which gives areas with high pixel intensities more influence on the cost calculation than others.</p>
</section>
<section id="intersection-of-the-union" class="level4">
<h4 class="anchored" data-anchor-id="intersection-of-the-union">4.3.2 Intersection of the union</h4>
<p>One issue with the mean absolute error approach is that tissues with high-intensity values will contribute more towards the error than other types. One remedy is to compare the <strong>image masks</strong>. The <code>intersection of the union</code> is a measure particularly well-suited to this. It is calculated by dividing the number of shared pixels between two masks by the total number of masked pixels :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/90030f0d-0fc0-439a-ad1d-88ba6eec8955-2-8f5f678b-f183-47aa-be6f-922d8c847d44.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">IOU.PNG</figcaption>
</figure>
</div>
<ul>
<li>First, we create image masks by selecting pixels greater than 0.</li>
<li>Second, we take the intersection of the two masks: that is, the pixels that appear in both masks.</li>
<li>Next, we find the union: the pixels that appear in either mask.</li>
<li>Finally, we divide the sum of the intersection by the sum of the union.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/90030f0d-0fc0-439a-ad1d-88ba6eec8955-1-7f85cc2b-1d43-44db-9d85-27506ef6d509.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">IOU_score.PNG</figcaption>
</figure>
</div>
<p>The result is a number between 0 and 1, with <code>0</code> representing no shared mask pixels, and <code>1</code> representing perfect agreement.</p>
<p>The principle here is that summarizing image similarity with a single number gives you something to optimize when processing your images.</p>
<p><code>Illustration</code></p>
<p>For this exercise, using the following function, determine how best to transform <code>im1</code> to maximize the IOU cost function with <code>im2</code></p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> intersection_of_union(im1, im2):</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> np.logical_and(im1, im2)</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> np.logical_or(im1, im2)</span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> i.<span class="bu">sum</span>() <span class="op">/</span> u.<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>intersection_of_union(im1, im2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>0.7171385659453746</code></pre>
</div>
</div>
<p><code>Tranformation 1</code><br>
Shift (-10, 10), rotate -15 deg</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>im1_transform_1 <span class="op">=</span> ndi.shift(im1,(<span class="op">-</span><span class="dv">10</span>,<span class="op">-</span><span class="dv">10</span>)) <span class="co"># [left(-ve), up(-ve)]</span></span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>im1_transform_1 <span class="op">=</span> ndi.rotate(im1_transform_1, <span class="op">-</span><span class="dv">15</span>, reshape<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb137-3"><a href="#cb137-3" aria-hidden="true" tabindex="-1"></a>intersection_of_union(im1_transform_1, im2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>0.8913414634146342</p>
<p><code>Tranformation 2</code><br>
Shift (+10, +10), rotate -15 deg</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>im1_transform_2 <span class="op">=</span> ndi.shift(im1, (<span class="dv">10</span>,<span class="dv">10</span>)) <span class="co"># [left(-ve), up(-ve)]</span></span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>im1_transform_2 <span class="op">=</span> ndi.rotate(im1_transform_2, <span class="op">-</span><span class="dv">15</span>, reshape<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>intersection_of_union(im1_transform_2, im2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>0.6069298200114114</p>
<p><code>Tranformation 3</code><br>
Shift (+10, +10), rotate +15 deg</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>im1_transform_3 <span class="op">=</span> ndi.shift(im1,(<span class="dv">10</span>,<span class="dv">10</span>)) <span class="co"># [left(-ve), up(-ve)]</span></span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>im1_transform_3 <span class="op">=</span> ndi.rotate(im1_transform_3, <span class="dv">15</span>, reshape<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>intersection_of_union(im1_transform_3, im2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>0.5206319611402777</p>
<p><code>Tranformation 4</code><br>
Shift (-10, 10), rotate +15 deg</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>im1_transform_4 <span class="op">=</span> ndi.shift(im1,shift<span class="op">=</span>(<span class="op">-</span><span class="dv">10</span>,<span class="op">-</span><span class="dv">10</span>)) <span class="co"># [left(-ve), up(-ve)]</span></span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>im1_transform_4 <span class="op">=</span> ndi.rotate(im1_transform_4, <span class="dv">15</span>, reshape<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>intersection_of_union(im1_transform_4, im2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>0.7081703487411162</p>
<p>So, out of the four transformations, Transformation 1, Shift (-10, 10), rotate -15 deg, maximizes the IOU cost function.</p>
<p>Remember, the core principle is that a cost function must produce a single summary value across all elements in the image. MAE and IOU are just two of the many possible ways you might compare images.</p>
</section>
</section>
<section id="normalizing-measurements" class="level3">
<h3 class="anchored" data-anchor-id="normalizing-measurements">4.4 Normalizing measurements</h3>
<p>To round out this blog, let’s discuss the importance of accounting for confounds when comparing images.</p>
<p><code>Analysis workflow</code></p>
<p>Shown here is a common multi-subject workflow, in which each subject has a raw image that we process, measure, and store in a common group dataset.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/4ada1c56-f6ea-435f-8247-c7251b31f94a-1-6fb9528f-6361-403b-9bfd-3a5a798d45ed.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">workflow.PNG</figcaption>
</figure>
</div>
<p>In this model, each image is treated independently, but you are extracting the same metrics from each subject.</p>
<p><code>OASIS population</code></p>
<p>For this lesson, let’s assume that we have measured the brain volumes for all 400 images in the OASIS dataset and stored them in a pandas DataFrame. Displaying a few random rows shows that we have information such as age, sex, brain volume, and skull volume available.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/683a38fd-2b23-43f3-9517-e6fce88faad0-1-605547c4-c6e8-4c14-9b8e-942212f17291.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">oasis_df.PNG</figcaption>
</figure>
</div>
<p><code>Hypothesis testing</code></p>
<p>With this data, we want to answer a crucial question: are the brains of men and women different? How would we test this?</p>
<p>For this question, we can use a two-sample t-test. We will test the null hypothesis that the mean brain volumes of men and women are the same. The likelihood of the null hypothesis being true is assessed by calculating the t-statistic. If the magnitude of t is very far from 0, then we can reject the null hypothesis that the groups are the same. Fortunately, this function is already implemented in SciPy and is simple to evaluate.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/5f8dfdd9-8bb6-4a9c-8727-39d64c536f9d-1-b6e8f856-b69a-4f1c-9196-7efccd517c54.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">hypothesis_testing.PNG</figcaption>
</figure>
</div>
<p>To run the t-test, we need the brain volumes for all of the males and females in our sample.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/585ef09b-9c7e-47e2-a7c3-56ceefbe59c7-1-8ac9e0dc-6f9c-48fd-abcf-aa431bc04256.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">t_stat_p_value.PNG</figcaption>
</figure>
</div>
<p>Select the male values with <code>df.loc</code>, then specifying the rows where “sex is male” and the column with “brain volume” values. For females, we change the selected sex to “female.”</p>
<p>To run the t-test, import the <code>ttest_ind()</code> function from SciPy’s stats module. Then, pass the two vectors as our first and second populations. The results object contains the test statistic, which is quite high, and the p-value. The p-value corresponds to the probability that the null hypothesis is true. In this case, we have a large t-statistic and a low p-value, which suggests that there’s a significant difference in gender brain size! Should we start writing it up?</p>
<p><code>Correlated measurements</code></p>
<p>Not so fast. We need to consider the context in which this measurement is acquired. Brains fill up skulls, and skulls are proportional to body size. If we compare brain and skull volumes, we find that they have quite a large correlation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/83d718b0-6408-4984-a0b9-f15b92f8e815-1-d09d98f4-1522-41b5-8c39-c1c61dd77143.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">correlation.PNG</figcaption>
</figure>
</div>
<p>Accounting for this shared variation is important if we want to state that there’s something different about the brains of men and women and not just their body size.</p>
<p><code>Normalization</code></p>
<p>To account for this potential confound, we can normalize brain volume with respect to skull size by calculating the brain to skull ratio. We can then repeat our t-test using the normalized values for males and females. Reviewing the results leads to disappointment: our amazing finding was likely related simply to the fact that large people have larger brains, and there are more large men than large women.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/c96bc801-9c81-4f4c-a686-a11afd2eb143-1-f24999d0-0dfc-456a-8bbe-bc3698780d61.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">normalization.PNG</figcaption>
</figure>
</div>
<p><code>Potential confounds in imaging</code></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/d7cb50cc-68c4-4873-badf-3978b4705e56-1-cf56a58b-f96f-4c96-968e-956de43da67e.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">confounds.PNG</figcaption>
</figure>
</div>
<p>Confounds are omnipresent in data science but can be especially pervasive in image analyses. If you are pooling data across multiple hospitals or sites, you must consider how image acquisition, digital storage, clinical protocols, and subject populations might be biased towards a particular result. In short, you may employ extremely sophisticated image analysis techniques, but if your analytical thinking is faulty, then your conclusions will be too!</p>
<section id="identifying-potential-confounds" class="level4">
<h4 class="anchored" data-anchor-id="identifying-potential-confounds">4.4.1 Identifying potential confounds</h4>
<p>Once measures have been extracted, double-check for dependencies within your data. This is especially true if any image parameters (sampling rate, field of view) might differ between subjects, or you pull multiple measures from a single image.</p>
<p>For the final exercises, we have combined demographic and brain volume measures into a pandas DataFrame (df).</p>
<p>First, we will explore the table and available variables. Then, we will check for correlations between the data.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'Data/oasis_all_volumes.csv'</span>)</span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop([<span class="st">'gray_matter_vol'</span>,<span class="st">'white_matter_vol'</span>,<span class="st">'csf_vol'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb141-4"><a href="#cb141-4" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 425 entries, 0 to 424
Data columns (total 6 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   ID          425 non-null    object 
 1   age         425 non-null    int64  
 2   sex         425 non-null    object 
 3   alzheimers  425 non-null    bool   
 4   brain_vol   425 non-null    float64
 5   skull_vol   425 non-null    float64
dtypes: bool(1), float64(2), int64(1), object(2)
memory usage: 17.1+ KB</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print 3 random rows</span></span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.sample(<span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                ID  age sex  alzheimers  brain_vol    skull_vol
388  OAS1_0441_MR1   81   M        True    971.016  1583.689763
181  OAS1_0202_MR1   23   F       False   1213.242  1434.512143
9    OAS1_0011_MR1   52   F       False    920.874  1330.603431</code></pre>
</div>
</div>
<p>Print the unique number of individuals with Alzheimer’s disease patients.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.alzheimers.value_counts())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>False    332
True      93
Name: alzheimers, dtype: int64</code></pre>
</div>
</div>
<p>Print the correlation table between each variable.</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.corr())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 age  alzheimers  brain_vol  skull_vol
age         1.000000    0.542463  -0.719211  -0.141576
alzheimers  0.542463    1.000000  -0.446771   0.014222
brain_vol  -0.719211   -0.446771   1.000000   0.654829
skull_vol  -0.141576    0.014222   0.654829   1.000000</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_94/4212406737.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  print(df.corr())</code></pre>
</div>
</div>
<p>There is a high correlation - nearly 0.7 - between the <code>brain_vol</code> and <code>skull_vol</code>. We should be wary of this (and other highly correlated variables) when interpreting results.</p>
</section>
<section id="testing-group-differences" class="level4">
<h4 class="anchored" data-anchor-id="testing-group-differences">4.4.2 Testing group differences</h4>
<p>Let’s test the hypothesis that Alzheimer’s Disease is characterized by reduced brain volume.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/486a7763-28e4-45f3-a27c-fe35bd3f949e-1-4a997869-0861-41aa-91ba-a7158df72be2.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">alzheimers.PNG</figcaption>
</figure>
</div>
<p>We can perform a two-sample t-test between the brain volumes of elderly adults with and without Alzheimer’s Disease. In this case, the two population samples are independent from each other because they are all separate subjects.</p>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import independent two-sample t-test</span></span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> ttest_ind</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Create a vector of ‘brain_vol’ values for each of the Alzheimer’s Disease and Typical Elderly groups.</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select data from "alzheimers" and "typical" groups</span></span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>brain_alz <span class="op">=</span> df.loc[df.alzheimers <span class="op">==</span> <span class="va">True</span>, <span class="st">'brain_vol'</span>]</span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>brain_typ <span class="op">=</span> df.loc[df.alzheimers <span class="op">==</span> <span class="va">False</span>, <span class="st">'brain_vol'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Use <code>ttest_ind()</code> to test for differences between the two groups’ ‘gray_vol’ metrics. Print the results.</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform t-test of "alz" &gt; "typ"</span></span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> ttest_ind(brain_alz, brain_typ)</span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'t = '</span>, results.statistic)</span>
<span id="cb152-4"><a href="#cb152-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p = '</span>, results.pvalue)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>t =  -10.27076306169677
p =  3.043550344658516e-22</code></pre>
</div>
</div>
<p>Visualize the ‘brain_vol’ measures using the <code>boxplot()</code> method of df. Group the variables by their disease classification by setting by=‘alzheimers’.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show boxplot of brain_vol differences</span></span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>df.boxplot(column<span class="op">=</span><span class="st">'brain_vol'</span>, by<span class="op">=</span><span class="st">'alzheimers'</span>)</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Biomedical_Image_Analysis_in_Python_files/figure-html/cell-122-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>There is some evidence for decreased brain volume in individuals with Alzheimer’s Disease. Since the p-value for this t-test is greater than 0.05, we would not reject the null hypothesis that states the two.</p>
</section>
<section id="normalizing-metrics" class="level4">
<h4 class="anchored" data-anchor-id="normalizing-metrics">4.4.3 Normalizing metrics</h4>
<p>We previously saw that there was not a significant difference between the brain volumes of elderly individuals with and without Alzheimer’s Disease. But could a correlated measure, such as “skull volume” be masking the differences?</p>
<p>For this exercise, calculate a new test statistic for the comparison of brain volume between groups, after adjusting for the subject’s skull size.</p>
<p>Using <code>results.statistic</code> and <code>results.pvalue</code> as oour guide, answer the question: Is there strong evidence that Alzheimer’s Disease is marked by smaller brain size, relative to skull size?</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import independent two-sample t-test</span></span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> ttest_ind</span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Divide `df.brain_vol` by `df.skull_vol`</span></span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'adj_brain_vol'</span>] <span class="op">=</span> df.brain_vol <span class="op">/</span> df.skull_vol</span>
<span id="cb155-6"><a href="#cb155-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-7"><a href="#cb155-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Select brain measures by Alzheimers group</span></span>
<span id="cb155-8"><a href="#cb155-8" aria-hidden="true" tabindex="-1"></a>brain_alz <span class="op">=</span> df.loc[df.alzheimers <span class="op">==</span> <span class="va">True</span>, <span class="st">'adj_brain_vol'</span>]</span>
<span id="cb155-9"><a href="#cb155-9" aria-hidden="true" tabindex="-1"></a>brain_typ <span class="op">=</span> df.loc[df.alzheimers <span class="op">==</span> <span class="va">False</span>, <span class="st">'adj_brain_vol'</span>]</span>
<span id="cb155-10"><a href="#cb155-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-11"><a href="#cb155-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate null hypothesis</span></span>
<span id="cb155-12"><a href="#cb155-12" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> ttest_ind(brain_alz, brain_typ)</span>
<span id="cb155-13"><a href="#cb155-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'t = '</span>, results.statistic)</span>
<span id="cb155-14"><a href="#cb155-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p = '</span>, results.pvalue)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>t =  -15.311391823926579
p =  2.019286086120867e-42</code></pre>
</div>
</div>
<p><code>Interpretation of results</code></p>
<p>The “t” value of -15.31 represents the t-statistic calculated from a statistical test, such as a t-test, comparing the mean brain size to skull size ratio between two groups: one with Alzheimer’s Disease and one without. A negative t-value suggests that the group with Alzheimer’s Disease had a smaller mean brain size to skull size ratio than the group without Alzheimer’s Disease.</p>
<p>The “p” value of 2.019e-42 (or approximately 0) represents the probability of obtaining such an extreme or more extreme t-value under the null hypothesis that there is no difference in the mean brain size to skull size ratio between the two groups. A p-value of less than 0.05 (or 0.01, depending on the level of significance chosen) is generally considered statistically significant and indicates strong evidence against the null hypothesis. In this case, the extremely low p-value suggests that it is highly unlikely that the observed difference in the mean brain size to skull size ratio between the two groups is due to chance.</p>
<p><strong>Therefore, there is strong evidence to suggest that Alzheimer’s Disease is marked by smaller brain size, relative to skull size.</strong></p>
<p>We’ve worked our way through several levels of biomedical image analysis and are well-prepared for tackling new datasets and problems.</p>
<p>For more advanced tools, check out <a href="https://scikit-image.org/docs/stable/user_guide.html">scikit-image</a>, which extends the capabilities of scipy for image processing.</p>
</section>
</section>
<section id="acknowledgements" class="level3">
<h3 class="anchored" data-anchor-id="acknowledgements">Acknowledgements</h3>
<p>I really enjoyed this course. It was a good NumPy refresher for me, and I was pleased to see Affine Transformations, t-tests, and p-values, outside of the abstraction of my Maths &amp; Statistics degree! I hope to explore image analysis further.</p>
<p>I sometimes feel like I excelled in mathematics a generation too early! Twenty years or so ago, I don’t recall there being much in the way of commercial or industry application of mathematics. Although I worked in data analytics for over 20 years as a chartered accountant, it never quite satisfied my passion for mathematics. As I transition into data science / machine learning, hopefully I can get my teeth into something challenging but rewarding, at the intersection of business, mathematics and statistics.</p>
<p>Thanks to <a href="https://www.datacamp.com/instructors/stkbailey">Stephen Bailey</a> for leading the course in collaboration with DataCamp.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>